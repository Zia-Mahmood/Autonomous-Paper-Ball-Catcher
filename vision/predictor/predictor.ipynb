{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe06f144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kreo1] Ball Thread started.\n",
      "[kreo1] Tag Thread started.\n",
      "[kreo2] Ball Thread started.\n",
      "[kreo2] Tag Thread started.\n",
      "[System] Decoupled Detection Started. Logging to ../../data/prediction_free_fall_logs/log_1764156623.csv\n",
      "[INFO] Loaded calibrated camera parameters\n",
      "[Calib] kreo1 extrinsics locked using Tag 2\n",
      "[INFO] Loaded calibrated camera parameters\n",
      "[Calib] kreo2 extrinsics locked using Tag 1\n",
      "\n",
      "Clean exit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BALL-ERR-kreo2] \n"
     ]
    }
   ],
   "source": [
    "import cv2, zmq, numpy as np, time, threading, queue, traceback, sys, os, csv, copy\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ---------- Config ----------\n",
    "ZMQ_ADDR = \"tcp://localhost:5555\"\n",
    "PUB_ADDR = \"tcp://*:5566\"\n",
    "SUB_TOPICS = [b\"kreo1\", b\"kreo2\"]\n",
    "FPS_WINDOW = 1.0        \n",
    "DISPLAY_FPS = 30        \n",
    "VISUALIZE = False        \n",
    "\n",
    "# SCALING CONFIG\n",
    "BALL_DETECTION_SCALE = 0.5  # Downscale for speed (Ball)\n",
    "TAG_DETECTION_SCALE = 1.0   # Full res for accuracy (Tags)\n",
    "\n",
    "LOG_DIR = \"../../data/prediction_free_fall_logs\"\n",
    "LOG_FILENAME = f\"{LOG_DIR}/log_{int(time.time())}.csv\"\n",
    "CALIB_DIR = \"../calibration/\"\n",
    "\n",
    "# HSV Config\n",
    "HSV_CONFIG = {\n",
    "    \"kreo1\": { \"orange\": {'hmin': 0, 'smin': 116, 'vmin': 160, 'hmax': 12, 'smax': 197, 'vmax': 255} },\n",
    "    \"kreo2\": { \"orange\": {'hmin': 0, 'smin': 110, 'vmin': 181, 'hmax': 10, 'smax': 255, 'vmax': 255} }\n",
    "}\n",
    "DEFAULT_HSV = {'hmin': 0, 'smin': 100, 'vmin': 100, 'hmax': 25, 'smax': 255, 'vmax': 255}\n",
    "\n",
    "# Detector parameters\n",
    "BASE_MIN_AREA = 100    \n",
    "BASE_MAX_AREA = 20000  \n",
    "CIRCULARITY_MIN = 0.5\n",
    "ASPECT_RATIO_MIN = 0.6 \n",
    "ASPECT_RATIO_MAX = 1.6   \n",
    "MAX_DETECTIONS_PER_CAM = 5 \n",
    "\n",
    "# 3D / TRIANGULATION CONFIG\n",
    "STATIC_TAG_IDS = [0,1,2,3]\n",
    "TAG_POSITIONS = {\n",
    "    0: np.array([0.9, 0.0, 0.0], dtype=float),\n",
    "    1: np.array([0.0, 0.0, 0.0], dtype=float),\n",
    "    2: np.array([0.9, 0.9, 0.0], dtype=float),\n",
    "    3: np.array([0.0, 0.9, 0.0], dtype=float)\n",
    "}\n",
    "TAG_SIZES = {0: 0.099, 1: 0.096, 2: 0.096, 3: 0.096, 4: 0.096, 5: 0.096}\n",
    "CALIB_FRAMES = 30\n",
    "MAX_TIME_DIFF = 0.05  # Max ms diff for triangulation pairing\n",
    "\n",
    "# AprilTag Config\n",
    "DICT_TYPE = cv2.aruco.DICT_APRILTAG_36h11\n",
    "def create_april_detector():\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(DICT_TYPE)\n",
    "    params = cv2.aruco.DetectorParameters()\n",
    "    params.adaptiveThreshWinSizeMin = 3\n",
    "    params.adaptiveThreshWinSizeMax = 35\n",
    "    params.adaptiveThreshWinSizeStep = 2\n",
    "    params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    params.cornerRefinementWinSize = 7\n",
    "    params.cornerRefinementMaxIterations = 50\n",
    "    params.cornerRefinementMinAccuracy = 0.01\n",
    "    params.minMarkerPerimeterRate = 0.02\n",
    "    params.maxMarkerPerimeterRate = 6.0\n",
    "    params.polygonalApproxAccuracyRate = 0.02\n",
    "    params.adaptiveThreshConstant = 7\n",
    "    return cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "\n",
    "class StaticCalibrator:\n",
    "    def __init__(self, tag_world_map, tag_size_map):\n",
    "        self.tag_world_map = tag_world_map\n",
    "        self.tag_size_map = tag_size_map\n",
    "        self.obs = defaultdict(list)\n",
    "        self.extrinsics = {}\n",
    "        self.frame_count = defaultdict(int)\n",
    "        self.P_cache = {}              # cam_name -> projection matrix K@[R|t]\n",
    "        self.K_cache = {}\n",
    "        self.dist_cache = {}\n",
    "\n",
    "    def load_intrinsics(self, cam_name):\n",
    "        if cam_name in self.K_cache: return self.K_cache[cam_name], self.dist_cache[cam_name]\n",
    "        camera_matrix, dist_coeffs = load_camera_calib(cam_name)\n",
    "        self.K_cache[cam_name] = camera_matrix\n",
    "        self.dist_cache[cam_name] = dist_coeffs\n",
    "        return camera_matrix, dist_coeffs\n",
    "\n",
    "    def add_detection(self, cam_name, ids, corners, ts):\n",
    "        if ids is None: return\n",
    "        self.frame_count[cam_name] += 1\n",
    "        for i, idarr in enumerate(ids):\n",
    "            tid = int(idarr[0])\n",
    "            if tid in STATIC_TAG_IDS:\n",
    "                c = np.array(corners[i]).reshape(4,2).astype(np.float64)\n",
    "                self.obs[cam_name].append((tid, c, ts))\n",
    "\n",
    "    def try_compute_extrinsic(self, cam_name):\n",
    "        if cam_name in self.extrinsics: return True\n",
    "        if self.frame_count.get(cam_name, 0) < CALIB_FRAMES: return False\n",
    "\n",
    "        target_tag = None\n",
    "        if cam_name == \"kreo1\":\n",
    "            target_tag = 2\n",
    "        elif cam_name == \"kreo2\":\n",
    "            target_tag = 1\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        obs_list = list(reversed(self.obs.get(cam_name, [])))\n",
    "        \n",
    "        use_corners = None\n",
    "\n",
    "        for (tid, corners, ts) in obs_list:\n",
    "            if int(tid) == int(target_tag):\n",
    "                use_corners = corners.reshape(4,2).astype(np.float64)\n",
    "                break \n",
    "        \n",
    "        if use_corners is None: return False \n",
    "\n",
    "        try: K, dist = self.load_intrinsics(cam_name)\n",
    "        except: return False\n",
    "\n",
    "        obj_corners = np.array(self.tag_world_map[target_tag], dtype=np.float64)\n",
    "        ok, rvec, tvec = cv2.solvePnP(obj_corners, use_corners, K, dist, flags=cv2.SOLVEPNP_IPPE_SQUARE)\n",
    "        if not ok: return False\n",
    "\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        tvec = tvec.reshape(3,1)\n",
    "        self.extrinsics[cam_name] = {\"rvec\": rvec, \"tvec\": tvec, \"R\": R}\n",
    "        P = np.hstack((R, tvec))\n",
    "        self.P_cache[cam_name] = P\n",
    "        print(f\"[Calib] {cam_name} extrinsics locked using Tag {target_tag}\")\n",
    "        return True\n",
    "\n",
    "    def cam_to_world(self, cam_name, X_cam):\n",
    "        e = self.extrinsics.get(cam_name)\n",
    "        if e is None: raise RuntimeError(\"Calibrator: extrinsic not ready for \" + cam_name)\n",
    "        R = e['R']; t = e['tvec']\n",
    "        X = np.asarray(X_cam, dtype=np.float64)\n",
    "        if X.ndim == 1 and X.shape[0] == 3:\n",
    "            Xc = X.reshape(3,1)\n",
    "            Xw = R.T @ (Xc - t)\n",
    "            return Xw[:,0]\n",
    "        if X.ndim == 2 and X.shape[1] == 3:\n",
    "            Xc = X.T  # 3xN\n",
    "            Xw = R.T @ (Xc - t)\n",
    "            return Xw.T\n",
    "        if X.ndim == 2 and X.shape[0] == 3:\n",
    "            Xc = X\n",
    "            Xw = R.T @ (Xc - t)\n",
    "            return Xw.T\n",
    "        raise ValueError(\"Invalid X_cam shape: \" + str(X.shape))\n",
    "\n",
    "    def get_norm_projection_matrix(self, cam_name):\n",
    "        return self.P_cache.get(cam_name, None)\n",
    "\n",
    "\n",
    "# ---------- Logging Setup ----------\n",
    "if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)\n",
    "log_queue = queue.Queue()\n",
    "\n",
    "def logger_worker():\n",
    "    try:\n",
    "        with open(LOG_FILENAME, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                \"timestamp\",\"camera\", \n",
    "                \"ball_2d_x\", \"ball_2d_y\", \"ball_2d_area\",\n",
    "                \"ball_3d_x\", \"ball_3d_y\", \"ball_3d_z\",\n",
    "                \"tag4_x\", \"tag4_y\", \"tag4_z\",\n",
    "                \"tag5_x\", \"tag5_y\", \"tag5_z\",\n",
    "                \"detected_kreo1\", \"detected_kreo2\"\n",
    "            ])\n",
    "            while True:\n",
    "                entry = log_queue.get()\n",
    "                if entry is None: break\n",
    "                writer.writerow(entry)\n",
    "                log_queue.task_done()\n",
    "    except Exception as e: print(f\"[LOGGER ERROR] {e}\")\n",
    "\n",
    "log_thread = threading.Thread(target=logger_worker, daemon=True)\n",
    "log_thread.start()\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def fmt_ts(ts):\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(ts)) + f\".{int((ts%1)*1000):03d}\"\n",
    "\n",
    "def tag_to_msg(tag_entry):\n",
    "    if tag_entry is None:\n",
    "        return {\"pos\": None, \"yaw\": None, \"valid\": False}\n",
    "    return {\"pos\": tag_entry[\"pos\"], \"yaw\": float(tag_entry[\"yaw\"]), \"valid\": True}\n",
    "\n",
    "def recv_latest(sub):\n",
    "    msg = None\n",
    "    while True:\n",
    "        try:\n",
    "            msg = sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        except zmq.Again:\n",
    "            break\n",
    "    return msg\n",
    "\n",
    "def update_fps(camera, cam_ts):\n",
    "    dq = fps_windows[camera]\n",
    "    dq.append(cam_ts)\n",
    "    # pop older than window\n",
    "    while dq and (cam_ts - dq[0]) > FPS_WINDOW:\n",
    "        dq.popleft()\n",
    "    fps = len(dq) / FPS_WINDOW\n",
    "    return fps\n",
    "\n",
    "def load_camera_calib(cam_name):\n",
    "    path = os.path.join(CALIB_DIR, f'camera_calibration_{cam_name}.npz')\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    calib = np.load(path)\n",
    "    camera_matrix = calib[\"cameraMatrix\"]\n",
    "    dist_coeffs = calib['distCoeffs']\n",
    "    print(\"[INFO] Loaded calibrated camera parameters\")\n",
    "    return camera_matrix, dist_coeffs\n",
    "\n",
    "def build_tag_world_map_from_centers(tag_centers, tag_sizes):\n",
    "    out = {}\n",
    "    for tid, center in tag_centers.items():\n",
    "        size = tag_sizes.get(tid, tag_sizes.get(1))\n",
    "        half = float(size) / 2.0\n",
    "        local = np.array([\n",
    "            [-half,  half, 0.0],\n",
    "            [ half,  half, 0.0],\n",
    "            [ half, -half, 0.0],\n",
    "            [-half, -half, 0.0],\n",
    "        ], dtype=np.float64)\n",
    "        corners_world = (local + center.reshape(1,3)).astype(np.float64)\n",
    "        out[tid] = corners_world\n",
    "    return out\n",
    "\n",
    "TAG_WORLD_MAP = build_tag_world_map_from_centers(TAG_POSITIONS, TAG_SIZES)\n",
    "\n",
    "def estimate_pose_apriltag(corners, tag_size, cam_mtx, cam_dist):\n",
    "    half = tag_size / 2.0\n",
    "    objp = np.array([\n",
    "        [-half,  half, 0.0],\n",
    "        [ half,  half, 0.0],\n",
    "        [ half, -half, 0.0],\n",
    "        [-half, -half, 0.0]\n",
    "    ], dtype=np.float32)\n",
    "    imgp = corners.reshape(4,2).astype(np.float32)\n",
    "    ok, rvec, tvec = cv2.solvePnP(objp, imgp, cam_mtx, cam_dist, flags=cv2.SOLVEPNP_IPPE_SQUARE)\n",
    "    if not ok: raise RuntimeError(\"solvePnP failed\")\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    T = np.eye(4); T[:3, :3] = R; T[:3, 3] = tvec.reshape(3)\n",
    "    return T\n",
    "\n",
    "def get_orange_mask(bgr_img, hsv_dict):\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([hsv_dict['hmin'], hsv_dict['smin'], hsv_dict['vmin']], dtype=np.uint8)\n",
    "    upper = np.array([hsv_dict['hmax'], hsv_dict['smax'], hsv_dict['vmax']], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    return cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "\n",
    "def find_ball_contours(mask, min_area, max_area):\n",
    "    if mask is None: return []\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < min_area or area > max_area: continue\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect = float(w)/float(h) if h > 0 else 0\n",
    "        if ASPECT_RATIO_MIN>aspect or aspect > ASPECT_RATIO_MAX: continue\n",
    "        perim = cv2.arcLength(c, True)\n",
    "        if perim == 0: continue\n",
    "        circularity = 4 * np.pi * area / (perim * perim)\n",
    "        if circularity >= CIRCULARITY_MIN:\n",
    "            candidates.append({\"bbox\": (x,y,w,h), \"area\": area, \"centroid\": (x+w//2, y+h//2)})\n",
    "    candidates.sort(key=lambda d: d[\"area\"], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "# ---------- Shared Data (Thread Safe) ----------\n",
    "# Stores the latest tag detection result for each camera\n",
    "shared_tag_data = {\n",
    "    \"kreo1\": {\"tag4\": {\"detected\": False, \"x\":\"\", \"y\":\"\"}, \"tag5\": {\"detected\": False, \"x\":\"\", \"y\":\"\"}, \"viz\": []},\n",
    "    \"kreo2\": {\"tag4\": {\"detected\": False, \"x\":\"\", \"y\":\"\"}, \"tag5\": {\"detected\": False, \"x\":\"\", \"y\":\"\"}, \"viz\": []}\n",
    "}\n",
    "# 3D Data (Populated by Threads and Main Loop)\n",
    "shared_3d_poses = {\n",
    "    \"ball\": None, # (x, y, z)\n",
    "    4: None,      # (x, y, z)\n",
    "    5: None       # (x, y, z)\n",
    "}\n",
    "\n",
    "# Candidates for Ball Triangulation (Written by BallThread, Read by Main)\n",
    "shared_ball_candidates = defaultdict(list)\n",
    "shared_ball_status = {\"kreo1\": False, \"kreo2\": False}\n",
    "shared_ball_history = {\n",
    "    \"kreo1\": deque(maxlen=30),   # ~ 30 recent candidates\n",
    "    \"kreo2\": deque(maxlen=30)\n",
    "}\n",
    "shared_data_lock = threading.Lock()\n",
    "viz_cache = {}\n",
    "viz_lock = threading.Lock()\n",
    "# Global Calibrator Instance\n",
    "calibrator = StaticCalibrator(TAG_WORLD_MAP, TAG_SIZES)\n",
    "\n",
    "# ---------- THREAD 1: TAG DETECTOR (Slower, High Accuracy) ----------\n",
    "class TagDetectorThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.aruco_detector = create_april_detector()\n",
    "        self.stop_flag = False\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] Tag Thread started.\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                # Get raw bytes (Tag thread decodes independently to avoid blocking Ball thread)\n",
    "                jpg_bytes, cam_ts = self.frame_queue.get(timeout=0.1)\n",
    "                \n",
    "                # Decode\n",
    "                frame = cv2.imdecode(np.frombuffer(jpg_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "                if frame is None: continue\n",
    "\n",
    "                # Detect (Full Res)\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                corners, ids, _ = self.aruco_detector.detectMarkers(gray)\n",
    "                \n",
    "                viz_tags = []\n",
    "                local_tag4_det = False\n",
    "                local_tag5_det = False\n",
    "\n",
    "                if ids is not None:\n",
    "                    calibrator.add_detection(self.cam_name, ids, corners, cam_ts)\n",
    "                    calibrator.try_compute_extrinsic(self.cam_name)\n",
    "\n",
    "                    ids_flat = ids.flatten()\n",
    "                    for i, tag_id in enumerate(ids_flat):\n",
    "                        viz_tags.append({\"id\": tag_id, \"corners\": corners[i]})\n",
    "                        \n",
    "                        # 2. Compute 3D for Moving Tags (4 & 5)\n",
    "                        # Only if extrinsic is locked\n",
    "                        if tag_id in [4, 5] and self.cam_name in calibrator.extrinsics:\n",
    "                            try:\n",
    "                                K, dist = calibrator.load_intrinsics(self.cam_name)\n",
    "                                c_corners = np.array(corners[i]).reshape(4,2)\n",
    "                                T_tag_cam = estimate_pose_apriltag(c_corners, TAG_SIZES[tag_id], K, dist)\n",
    "                                ext = calibrator.extrinsics.get(self.cam_name)\n",
    "                                if ext is None:\n",
    "                                    continue\n",
    "                                R_wc = ext['R']                   # world->cam rotation\n",
    "                                t_wc = ext['tvec'].reshape(3)     # world->cam translation\n",
    "\n",
    "                                # camera->world (inverse)\n",
    "                                R_cw = R_wc.T\n",
    "                                t_cw = -R_cw @ t_wc\n",
    "                                T_cam2world = np.eye(4, dtype=np.float64)\n",
    "                                T_cam2world[:3,:3] = R_cw\n",
    "                                T_cam2world[:3,3]  = t_cw\n",
    "\n",
    "                                # Transform tag pose into world: T_tag_world = T_cam2world @ T_tag_cam\n",
    "                                T_tag_world = T_cam2world @ T_tag_cam\n",
    "\n",
    "                                # Extract position (x,y,z)\n",
    "                                pos = T_tag_world[:3, 3].astype(float)  # numpy array [x,y,z]\n",
    "\n",
    "                                # Extract yaw (rotation around Z) from rotation matrix\n",
    "                                Rtw = T_tag_world[:3, :3]\n",
    "                                # yaw = atan2(r21, r11) (standard)\n",
    "                                yaw = float(np.arctan2(Rtw[1,0], Rtw[0,0]))\n",
    "\n",
    "                                # Store full pose dictionary (pos & yaw)\n",
    "                                with shared_data_lock:\n",
    "                                    shared_3d_poses[tag_id] = {\"pos\": [float(pos[0]), float(pos[1]), float(pos[2])], \"yaw\": yaw}\n",
    "                                    if tag_id == 4: local_tag4_det = True\n",
    "                                    if tag_id == 5: local_tag5_det = True\n",
    "                            except Exception as e:\n",
    "                                pass # Pose estimation failed for this frame\n",
    "                \n",
    "                # Update 2D Shared\n",
    "                with shared_data_lock:\n",
    "                    shared_tag_data[self.cam_name] = {\n",
    "                        \"tag4\": {\"detected\": local_tag4_det},\n",
    "                        \"tag5\": {\"detected\": local_tag5_det},\n",
    "                        \"viz\": viz_tags\n",
    "                    }\n",
    "            except queue.Empty:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(f\"[TAG-ERR-{self.cam_name}]\", e)\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "# ---------- THREAD 2: BALL DETECTOR (Fast, Low Latency) ----------\n",
    "class BallDetectorThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.min_area_scaled = BASE_MIN_AREA * (BALL_DETECTION_SCALE**2)\n",
    "        self.max_area_scaled = BASE_MAX_AREA * (BALL_DETECTION_SCALE**2)\n",
    "        self.hsv_vals = HSV_CONFIG.get(cam_name, {}).get(\"orange\", DEFAULT_HSV)\n",
    "        self.stop_flag = False\n",
    "        self.fps_dq = deque()\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] Ball Thread started.\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                jpg_bytes, cam_ts = self.frame_queue.get(timeout=0.1)\n",
    "                \n",
    "                # Decode\n",
    "                frame = cv2.imdecode(np.frombuffer(jpg_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "                if frame is None: continue\n",
    "\n",
    "                # Resize for Speed\n",
    "                if BALL_DETECTION_SCALE != 1.0:\n",
    "                    frame_small = cv2.resize(frame, None, fx=BALL_DETECTION_SCALE, fy=BALL_DETECTION_SCALE, interpolation=cv2.INTER_NEAREST)\n",
    "                else:\n",
    "                    frame_small = frame\n",
    "\n",
    "                # Detect Ball\n",
    "                mask = get_orange_mask(frame_small, self.hsv_vals)\n",
    "                balls = find_ball_contours(mask, self.min_area_scaled, self.max_area_scaled)\n",
    "                \n",
    "                ball_data = {\"detected\": False, \"x\": \"\", \"y\": \"\", \"area\": \"\"}\n",
    "                viz_ball = None\n",
    "                candidates_for_triangulation = []\n",
    "\n",
    "                if balls:\n",
    "                    b = balls[0] \n",
    "                    scale_inv = 1.0 / BALL_DETECTION_SCALE\n",
    "                    bx, by, bw, bh = b[\"bbox\"]\n",
    "                    real_x = int(bx * scale_inv); real_y = int(by * scale_inv)\n",
    "                    real_w = int(bw * scale_inv); real_h = int(bh * scale_inv)\n",
    "                    real_area = int(b[\"area\"] * (scale_inv**2))\n",
    "                    cx, cy = real_x + real_w//2, real_y + real_h//2\n",
    "                    \n",
    "                    ball_data = {\"detected\": True, \"x\": cx, \"y\": cy, \"area\": real_area}\n",
    "                    viz_ball = {\"bbox\": (real_x, real_y, real_w, real_h), \"centroid\": (cx, cy)}\n",
    "                    \n",
    "                    # Prepare data for match_and_triangulate\n",
    "                    candidates_for_triangulation.append({\n",
    "                        \"centroid\": (cx, cy),\n",
    "                        \"area\": real_area,\n",
    "                        \"color\": \"orange\",\n",
    "                        \"ts\": cam_ts\n",
    "                    })\n",
    "                # Update Shared Memory\n",
    "                with shared_data_lock:\n",
    "                    # Update candidates for this camera\n",
    "                    shared_ball_candidates[self.cam_name] = candidates_for_triangulation\n",
    "                    shared_ball_status[self.cam_name] = ball_data[\"detected\"]\n",
    "                    if candidates_for_triangulation:\n",
    "                        # store a lightweight record: (ts, centroid, area, color)\n",
    "                        for c in candidates_for_triangulation:\n",
    "                            shared_ball_history[self.cam_name].append({\n",
    "                                \"ts\": c[\"ts\"],\n",
    "                                \"centroid\": c[\"centroid\"],\n",
    "                                \"area\": c.get(\"area\", 0),\n",
    "                                \"color\": c.get(\"color\", \"\")\n",
    "                            })\n",
    "                    \n",
    "                    # Read GLOBAL 3D Data (Calculated by Main Loop or Tag Thread)\n",
    "                    # Note: There might be a 1-frame delay for Ball 3D, which is acceptable for decoupled logging\n",
    "                    ball_3d = shared_3d_poses.get(\"ball\")\n",
    "                    tag4_3d = shared_3d_poses.get(4)\n",
    "                    tag5_3d = shared_3d_poses.get(5)\n",
    "                    tags_viz = shared_tag_data[self.cam_name][\"viz\"]\n",
    "                    \n",
    "                    # Read detection status of OTHER camera for logging\n",
    "                    det_k1 = shared_ball_status[\"kreo1\"]\n",
    "                    det_k2 = shared_ball_status[\"kreo2\"]\n",
    "                \n",
    "                # --- LOGGING (Driven by this thread) ---\n",
    "                b3d = ball_3d if ball_3d is not None else [\"\", \"\", \"\"]\n",
    "                t4d = tag4_3d[\"pos\"] if tag4_3d is not None else [\"\", \"\", \"\"]\n",
    "                t5d = tag5_3d[\"pos\"] if tag5_3d is not None else [\"\", \"\", \"\"]\n",
    "\n",
    "                log_queue.put([\n",
    "                    f\"{cam_ts:.3f}\", self.cam_name,\n",
    "                    ball_data[\"x\"], ball_data[\"y\"], ball_data[\"area\"],\n",
    "                    b3d[0], b3d[1], b3d[2],\n",
    "                    t4d[0], t4d[1], t4d[2],\n",
    "                    t5d[0], t5d[1], t5d[2],\n",
    "                    det_k1, det_k2\n",
    "                ])\n",
    "\n",
    "                # FPS Calc\n",
    "                self.fps_dq.append(time.time())\n",
    "                while self.fps_dq and (self.fps_dq[-1] - self.fps_dq[0]) > FPS_WINDOW:\n",
    "                    self.fps_dq.popleft()\n",
    "                fps = len(self.fps_dq) / FPS_WINDOW\n",
    "\n",
    "                if VISUALIZE:\n",
    "                    with viz_lock:\n",
    "                        viz_cache[self.cam_name] = {\n",
    "                            \"img\": frame,\n",
    "                            \"ball\": viz_ball,\n",
    "                            \"tags\": tags_viz,\n",
    "                            \"fps\": fps\n",
    "                        }\n",
    "            except Exception as e:\n",
    "                print(f\"[BALL-ERR-{self.cam_name}]\", e)\n",
    "    \n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "def match_and_triangulate(camera_candidates, calibrator, reproj_thresh_px=15.0):\n",
    "    cams = list(camera_candidates.keys())\n",
    "    if len(cams) < 2: return []\n",
    "    \n",
    "    pair = ('kreo1', 'kreo2') if 'kreo1' in cams and 'kreo2' in cams else (cams[0], cams[1])\n",
    "    c1, c2 = pair\n",
    "    \n",
    "    # # Filter candidates (sort by area)\n",
    "    # cand1 = sorted(camera_candidates[c1], key=lambda x: -x.get('area',1))[:8]\n",
    "    # cand2 = sorted(camera_candidates[c2], key=lambda x: -x.get('area',1))[:8]\n",
    "\n",
    "    # Get Calibration Data\n",
    "    if c1 not in calibrator.extrinsics or c2 not in calibrator.extrinsics: return []\n",
    "    \n",
    "    K1, D1 = calibrator.load_intrinsics(c1)\n",
    "    K2, D2 = calibrator.load_intrinsics(c2)\n",
    "    P1_norm = calibrator.get_norm_projection_matrix(c1) # [R1|t1]\n",
    "    P2_norm = calibrator.get_norm_projection_matrix(c2) # [R2|t2]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    with shared_data_lock:\n",
    "        hist1 = list(shared_ball_history[c1])\n",
    "        hist2 = list(shared_ball_history[c2])\n",
    "    \n",
    "    for a in hist1:\n",
    "        # for each candidate in hist1 find candidates in hist2 within MAX_TIME_DIFF\n",
    "        closest = None\n",
    "        best_dt = 1e9\n",
    "        for b in hist2:\n",
    "            if a['color'] != b['color']: \n",
    "                continue\n",
    "            dt = abs(a['ts'] - b['ts'])\n",
    "            if dt <= MAX_TIME_DIFF and dt < best_dt:\n",
    "                best_dt = dt\n",
    "                closest = b\n",
    "        if closest is None:\n",
    "            continue\n",
    "\n",
    "        pt1_in = np.array(a['centroid'], dtype=float).reshape(-1,1,2)\n",
    "        pt2_in = np.array(closest['centroid'], dtype=float).reshape(-1,1,2)\n",
    "            \n",
    "            # Undistort to Normalized Coordinates (x, y) where z=1\n",
    "        pt1_norm = cv2.undistortPoints(pt1_in, K1, D1, P=None)\n",
    "        pt2_norm = cv2.undistortPoints(pt2_in, K2, D2, P=None)\n",
    "\n",
    "        pt1_norm = pt1_norm.reshape(-1, 2).T  \n",
    "        pt2_norm = pt2_norm.reshape(-1, 2).T \n",
    "\n",
    "        # Triangulate in World Frame\n",
    "        Xh = cv2.triangulatePoints(P1_norm, P2_norm, pt1_norm, pt2_norm)\n",
    "        w = Xh[3]\n",
    "        if abs(w) < 1e-6: continue\n",
    "        Xw = (Xh[:3] / w).flatten()\n",
    "\n",
    "        # Reproject to verify\n",
    "        img_pt1, _ = cv2.projectPoints(Xw.reshape(1,3), calibrator.extrinsics[c1]['rvec'], calibrator.extrinsics[c1]['tvec'], K1, D1)\n",
    "        img_pt2, _ = cv2.projectPoints(Xw.reshape(1,3), calibrator.extrinsics[c2]['rvec'], calibrator.extrinsics[c2]['tvec'], K2, D2)\n",
    "\n",
    "        err1 = np.linalg.norm(img_pt1.flatten() - np.array(a['centroid']))\n",
    "        err2 = np.linalg.norm(img_pt2.flatten() - np.array(b['centroid']))\n",
    "        tot_err = err1 + err2\n",
    "\n",
    "        if tot_err < reproj_thresh_px:\n",
    "            results.append({\n",
    "                'pt': Xw, \n",
    "                'reproj_err': tot_err, \n",
    "                'ts': max(a['ts'], b['ts']) \n",
    "            })\n",
    "    results.sort(key=lambda r: r['reproj_err'])\n",
    "    return results\n",
    "\n",
    "# ---------- Main Execution ----------\n",
    "\n",
    "ctx = zmq.Context()\n",
    "pub = ctx.socket(zmq.PUB)\n",
    "pub.setsockopt(zmq.SNDHWM,4)\n",
    "pub.setsockopt(zmq.LINGER,0)\n",
    "pub.bind(PUB_ADDR)\n",
    "time.sleep(0.05)\n",
    "\n",
    "sub = ctx.socket(zmq.SUB)\n",
    "sub.connect(ZMQ_ADDR)\n",
    "sub.setsockopt(zmq.RCVHWM, 4)\n",
    "sub.setsockopt(zmq.CONFLATE, 1) \n",
    "sub.setsockopt(zmq.LINGER, 0)\n",
    "for t in SUB_TOPICS: sub.setsockopt(zmq.SUBSCRIBE, t)\n",
    "\n",
    "\n",
    "\n",
    "# Init Queues (2 per camera: 1 for Ball, 1 for Tag)\n",
    "queues = {\n",
    "    \"kreo1\": {\"ball\": queue.Queue(maxsize=1), \"tag\": queue.Queue(maxsize=1)},\n",
    "    \"kreo2\": {\"ball\": queue.Queue(maxsize=1), \"tag\": queue.Queue(maxsize=1)}\n",
    "}\n",
    "\n",
    "threads = []\n",
    "# Spin up threads\n",
    "for cam in [\"kreo1\", \"kreo2\"]:\n",
    "    # Ball Thread\n",
    "    bt = BallDetectorThread(cam, queues[cam][\"ball\"])\n",
    "    bt.start()\n",
    "    threads.append(bt)\n",
    "    \n",
    "    # Tag Thread\n",
    "    tt = TagDetectorThread(cam, queues[cam][\"tag\"])\n",
    "    tt.start()\n",
    "    threads.append(tt)\n",
    "\n",
    "print(f\"[System] Decoupled Detection Started. Logging to {LOG_FILENAME}\")\n",
    "\n",
    "last_show = time.time()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # High Speed Ingestion Loop\n",
    "        try:\n",
    "            parts = recv_latest(sub)\n",
    "            if parts is None: continue\n",
    "            topic = parts[0]\n",
    "            cam = topic.decode()\n",
    "            ts_part = parts[1] if len(parts) >= 3 else None\n",
    "            jpg_part = parts[2] if len(parts) >= 3 else parts[1]\n",
    "            try: cam_ts = float(ts_part.decode()) if ts_part else time.time()\n",
    "            except: cam_ts = time.time()\n",
    "            \n",
    "            qs = queues.get(cam)\n",
    "            if qs:\n",
    "                try: qs[\"ball\"].put_nowait((jpg_part, cam_ts))\n",
    "                except queue.Full: pass\n",
    "                try: qs[\"tag\"].put_nowait((jpg_part, cam_ts))\n",
    "                except queue.Full: pass\n",
    "        except zmq.Again:\n",
    "            time.sleep(0.0001)\n",
    "        with shared_data_lock:\n",
    "            ready = all(c in calibrator.extrinsics for c in [t.decode() for t in SUB_TOPICS])\n",
    "        if not ready: continue\n",
    "        # ----------------------------------------------------\n",
    "        #  3D BALL CALCULATION & LOGGING\n",
    "        # ----------------------------------------------------\n",
    "        # We periodically check shared candidates to triangulate\n",
    "        with shared_data_lock:\n",
    "            current_ball_candidates = dict(shared_ball_candidates)\n",
    "\n",
    "        # Perform Triangulation\n",
    "        tri_results = match_and_triangulate(current_ball_candidates, calibrator)\n",
    "        \n",
    "        with shared_data_lock:\n",
    "            if len(tri_results) > 0:\n",
    "                res = tri_results[0]\n",
    "                shared_3d_poses[\"ball\"] = res['pt']\n",
    "            else:\n",
    "                # Optional: Decay old data or keep last known position? \n",
    "                # Keeping last known for now to avoid flickering, or set to None\n",
    "                shared_3d_poses[\"ball\"] = None\n",
    "            ball = shared_3d_poses.get(\"ball\")\n",
    "            tag4 = shared_3d_poses.get(4)\n",
    "            tag5 = shared_3d_poses.get(5)\n",
    "\n",
    "        payload = {\n",
    "            \"ts\": time.time(),\n",
    "            \"ball\": {\n",
    "                \"x\": float(ball[0]) if (ball is not None) else None,\n",
    "                \"y\": float(ball[1]) if (ball is not None) else None,\n",
    "                \"z\": float(ball[2]) if (ball is not None) else None,\n",
    "                \"valid\": bool(ball is not None)\n",
    "            },\n",
    "            \"tag4\": tag_to_msg(tag4),\n",
    "            \"tag5\": tag_to_msg(tag5)\n",
    "        }\n",
    "        try:\n",
    "            # topicless PUB; planner will subscribe and read raw JSON bytes\n",
    "            pub.send_json(payload)\n",
    "        except Exception as e:\n",
    "            # don't crash detection loop for one send failure\n",
    "            print(\"[PUB-ERR]\", e)\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        #  VISUALIZATION\n",
    "        # ----------------------------------------------------\n",
    "        curr_time = time.time()\n",
    "        if VISUALIZE and (curr_time - last_show) > (1.0/DISPLAY_FPS):\n",
    "            last_show = curr_time\n",
    "            with viz_lock:\n",
    "                has_data = all(c in viz_cache for c in [\"kreo1\", \"kreo2\"])\n",
    "                if has_data:\n",
    "                    def draw(cam_key):\n",
    "                        d = viz_cache[cam_key]\n",
    "                        im = d[\"img\"].copy()\n",
    "                        \n",
    "                        if d[\"ball\"]:\n",
    "                            bx,by,bw,bh = d[\"ball\"][\"bbox\"]\n",
    "                            cx,cy = d[\"ball\"][\"centroid\"]\n",
    "                            cv2.rectangle(im, (bx,by), (bx+bw, by+bh), (0,165,255), 2)\n",
    "                            cv2.circle(im, (cx,cy), 5, (0,0,255), -1)\n",
    "                        \n",
    "                        for tag in d[\"tags\"]:\n",
    "                             cv2.aruco.drawDetectedMarkers(im, [tag[\"corners\"].astype(int)], np.array([[tag[\"id\"]]]))\n",
    "                        \n",
    "                        # 3D Text Overlay\n",
    "                        y_off = 60\n",
    "                        if shared_3d_poses[\"ball\"] is not None:\n",
    "                            bp = shared_3d_poses[\"ball\"]\n",
    "                            cv2.putText(im, f\"Ball 3D: {bp[0]:.2f}, {bp[1]:.2f}, {bp[2]:.2f}\", (10, y_off), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "                            y_off += 25\n",
    "                        \n",
    "                        for tid in [4, 5]:\n",
    "                            if shared_3d_poses[tid] is not None:\n",
    "                                tp = shared_3d_poses[tid][\"pos\"]\n",
    "                                cv2.putText(im, f\"Tag {tid} 3D: {tp[0]:.2f}, {tp[1]:.2f}, {tp[2]:.2f}\", (10, y_off), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "                                y_off += 25\n",
    "                        \n",
    "                        if cam_key not in calibrator.extrinsics:\n",
    "                             cv2.putText(im, f\"CALIBRATING... {calibrator.frame_count.get(cam_key,0)}/{CALIB_FRAMES}\", \n",
    "                                         (10, y_off), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
    "\n",
    "                        cv2.putText(im, f\"FPS: {d['fps']:.1f}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                        return im\n",
    "\n",
    "                    l_im = draw(\"kreo1\")\n",
    "                    r_im = draw(\"kreo2\")\n",
    "                    \n",
    "                    h = min(l_im.shape[0], r_im.shape[0])\n",
    "                    if l_im.shape[0] != h: l_im = cv2.resize(l_im, (int(l_im.shape[1]*h/l_im.shape[0]), h))\n",
    "                    if r_im.shape[0] != h: r_im = cv2.resize(r_im, (int(r_im.shape[1]*h/r_im.shape[0]), h))\n",
    "                    \n",
    "                    cv2.imshow(\"Decoupled 3D\", np.hstack([l_im, r_im]))\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    for t in threads: t.stop()\n",
    "    log_queue.put(None)\n",
    "    log_thread.join()\n",
    "    cv2.destroyAllWindows()\n",
    "    sub.close()\n",
    "    pub.close()\n",
    "    ctx.term()\n",
    "    print(\"\\nClean exit.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
