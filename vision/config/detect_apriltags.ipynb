{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32054501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: {'cam0': 36, 'cam1': 36}\n",
      "FPS: {'cam0': 60, 'cam1': 60}\n",
      "FPS: {'cam0': 61, 'cam1': 61}\n",
      "FPS: {'cam0': 60, 'cam1': 60}\n",
      "FPS: {'cam0': 61, 'cam1': 61}\n",
      "FPS: {'cam0': 61, 'cam1': 61}\n",
      "FPS: {'cam0': 60, 'cam1': 60}\n",
      "FPS: {'cam0': 61, 'cam1': 61}\n",
      "FPS: {'cam0': 61, 'cam1': 61}\n",
      "FPS: {'cam0': 61, 'cam1': 61}\n"
     ]
    }
   ],
   "source": [
    "import cv2, time, threading\n",
    "\n",
    "caps = {\n",
    "    \"cam0\": cv2.VideoCapture(3,cv2.CAP_V4L2),\n",
    "    \"cam1\": cv2.VideoCapture(5,cv2.CAP_V4L2)\n",
    "}\n",
    "\n",
    "for c in caps.values():\n",
    "    c.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "    c.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    c.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    c.set(cv2.CAP_PROP_FPS, 60)\n",
    "\n",
    "last = time.time()\n",
    "cnt = {\"cam0\":0, \"cam1\":0}\n",
    "i = 0\n",
    "while i<10:\n",
    "    for name, cap in caps.items():\n",
    "        ret, frame = cap.read()\n",
    "        #cv2.imshow(\"testing\",frame)\n",
    "        if ret:\n",
    "            cnt[name]+=1\n",
    "\n",
    "    now = time.time()\n",
    "    if now - last >= 1:\n",
    "        print(\"FPS:\", cnt)\n",
    "        cnt = {\"cam0\":0, \"cam1\":0}\n",
    "        i+=1\n",
    "        last = now\n",
    "for c in caps.values():\n",
    "    c.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b81f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multi-Camera Live View Setup ===\n",
      "Select cameras to open (comma separated):\n",
      "1. Kreo Webcam #1\n",
      "2. Kreo Webcam #2\n",
      "3. Mobile IP Webcam\n",
      "Example: 1,2 or 1,3 or 1,2,3\n",
      "[INFO] Preview without fine tuning. Press ESC to exit preview windows.\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np, time, os, sys, threading, subprocess\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DICT_TYPE = cv2.aruco.DICT_APRILTAG_36h11\n",
    "\n",
    "CAM_SOURCES = {\n",
    "    \"Mobile\":\"http://192.168.137.110:8080/video\",\n",
    "    \"Kreo1\": 3,\n",
    "    \"Kreo2\": 5\n",
    "}\n",
    "\n",
    "def create_detector():\n",
    "    \"\"\"Setup AprilTag detector with tuned parameters.\"\"\"\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(DICT_TYPE)\n",
    "    params = cv2.aruco.DetectorParameters()\n",
    "    params.adaptiveThreshWinSizeMin = 3\n",
    "    params.adaptiveThreshWinSizeMax = 35\n",
    "    params.adaptiveThreshWinSizeStep = 2\n",
    "    params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    params.cornerRefinementWinSize = 5\n",
    "    params.cornerRefinementMaxIterations = 50\n",
    "    params.cornerRefinementMinAccuracy = 0.01\n",
    "    params.minMarkerPerimeterRate = 0.02\n",
    "    params.maxMarkerPerimeterRate = 4.0\n",
    "    params.polygonalApproxAccuracyRate = 0.02\n",
    "    params.adaptiveThreshConstant = 7\n",
    "    return cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "\n",
    "class CameraWorker(threading.Thread):\n",
    "    def __init__(self, name, src, detector):\n",
    "        super().__init__(daemon=True)\n",
    "        self.name = name\n",
    "        self.src = src\n",
    "        self.cap = cv2.VideoCapture(src, cv2.CAP_V4L2)\n",
    "\n",
    "        try:\n",
    "            self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        except Exception:\n",
    "            pass\n",
    "        if isinstance(src, int):\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "            self.cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "        self.detector = detector\n",
    "        self.lock = threading.Lock()\n",
    "        self.latest_frame = None\n",
    "        self.latest_ts = 0.0\n",
    "        self.running = True\n",
    "        self.opened = self.cap.isOpened()\n",
    "        if not self.opened:\n",
    "            print(f\"[{self.name}] Error cannot open source {src}\")\n",
    "\n",
    "    def run(self):\n",
    "        while self.running and self.opened:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            ts = time.time()\n",
    "            with self.lock:\n",
    "                self.latest_frame = frame\n",
    "                self.latest_ts = ts\n",
    "            time.sleep(0.001)\n",
    "\n",
    "    def read_latest(self):\n",
    "        with self.lock:\n",
    "            if self.latest_frame is None:\n",
    "                return None, 0.0\n",
    "            return self.latest_frame.copy(), self.latest_ts\n",
    "    \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        try: self.cap.release()\n",
    "        except: pass\n",
    "\n",
    "\n",
    "def get_camera_selection():\n",
    "    print(\"\\n=== Multi-Camera Live View Setup ===\")\n",
    "    print(\"Select cameras to open (comma separated):\")\n",
    "    print(\"1. Kreo Webcam #1\")\n",
    "    print(\"2. Kreo Webcam #2\")\n",
    "    print(\"3. Mobile IP Webcam\")\n",
    "    print(\"Example: 1,2 or 1,3 or 1,2,3\")\n",
    "    user_in = input(\"Cameras to open: \").strip()\n",
    "    choices = [x.strip() for x in user_in.split(\",\") if x.strip()]\n",
    "    selected = []\n",
    "    for c in choices:\n",
    "        if c == \"1\":\n",
    "            selected.append((\"Kreo1\", CAM_SOURCES[\"Kreo1\"]))\n",
    "        elif c == \"2\":\n",
    "            selected.append((\"Kreo2\", CAM_SOURCES[\"Kreo2\"]))\n",
    "        elif c == \"3\":\n",
    "            selected.append((\"Mobile\", CAM_SOURCES[\"Mobile\"]))\n",
    "        else:\n",
    "            print(f\"[WARN] Ignoring invalid entry: {c}\")\n",
    "    if not selected:\n",
    "        print(\"[ERROR] No valid cameras selected. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    return selected\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    selected = get_camera_selection()\n",
    "\n",
    "    workers = {}\n",
    "    for name, src in selected:\n",
    "        w = CameraWorker(name, src, create_detector())\n",
    "        w.start()\n",
    "        workers[name] = w\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    # After tuning show live preview with settings applied\n",
    "    print(\"[INFO] Preview without fine tuning. Press ESC to exit preview windows.\")\n",
    "    last_ts = {name: 0.0 for name in workers}\n",
    "    fps_counter = {name: 0 for name in workers}\n",
    "    fps = {name: 0.0 for name in workers}\n",
    "    last_fps_update = time.time()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            now = time.time()\n",
    "            timestamps = {}\n",
    "\n",
    "            # --- Collect frames from all cameras ---\n",
    "            for name, w in workers.items():\n",
    "                frame, ts = w.read_latest()\n",
    "                if frame is None:\n",
    "                    continue\n",
    "                timestamps[name] = ts\n",
    "\n",
    "                # --- FPS update ---\n",
    "                if ts != last_ts[name]:\n",
    "                    fps_counter[name] += 1\n",
    "                    last_ts[name] = ts\n",
    "\n",
    "                if now - last_fps_update >= 1.0:\n",
    "                    fps[name] = fps_counter[name]\n",
    "                    fps_counter[name] = 0\n",
    "\n",
    "            if now - last_fps_update >= 1.0:\n",
    "                last_fps_update = now\n",
    "\n",
    "            # --- Drift calculation ---\n",
    "            if len(timestamps) > 1:\n",
    "                tvals = np.array(list(timestamps.values()))\n",
    "                drift_ms = (tvals.max() - tvals.min()) * 1000.0\n",
    "            else:\n",
    "                drift_ms = 0.0\n",
    "\n",
    "            # --- Draw every camera independently ---\n",
    "            for name, w in workers.items():\n",
    "                frame, ts = w.read_latest()\n",
    "                if frame is None:\n",
    "                    continue\n",
    "                # AprilTag overlay\n",
    "                corners, ids, _ = w.detector.detectMarkers(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "                if ids is not None and len(ids) > 0:\n",
    "                    cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "                # resolution text\n",
    "                h, wid = frame.shape[:2]\n",
    "                cv2.putText(frame, f\"{name} {wid}x{h}\", (10, 25),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200,200,0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"FPS: {fps[name]:.0f}\", (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200,200,0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"Drift: {drift_ms:.1f} ms\", (10, 75),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "\n",
    "                cv2.imshow(f\"Tuned - {name}\", frame)\n",
    "\n",
    "            # Exit on ESC\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "            time.sleep(0.001)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        for w in workers.values():\n",
    "            w.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d232d9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multi-Camera Live View Setup ===\n",
      "Select cameras to open (comma separated):\n",
      "1. Kreo Webcam #1\n",
      "2. Kreo Webcam #2\n",
      "3. Mobile IP Webcam\n",
      "Example: 1,2 or 1,3 or 1,2,3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@460.112] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@460.208] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@460.259] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video4): can't open camera by index\n",
      "[ERROR:0@460.260] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Kreo1] Error cannot open source 0\n",
      "[Kreo2] Error cannot open source 4\n",
      "[INFO] Warmup for 1.2 seconds to let cameras settle...\n",
      "[Kreo1] Starting auto-tune (this may take a few minutes)...\n",
      "[Kreo1] Test 768/768 exp=300 focus=360 gain=18 bright=24 ...\n",
      "[Kreo1] Best found: exposure=80 focus=80 gain=0 brightness=0\n",
      "[Kreo1] stats: avg_tags=0.00, fps=0.0, std=0.00\n",
      "[Kreo1] Best settings saved -> ./camera_tune_results/best_camera_settings_Kreo1.json\n",
      "[Kreo2] Starting auto-tune (this may take a few minutes)...\n",
      "[Kreo2] Test 43/768 exp=80 focus=160 gain=12 bright=16 ...\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 244\u001b[39m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Invalid device index for tuning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw.src\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    243\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     best = \u001b[43mtune_camera\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    246\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Not a local device; skipping tuning.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 164\u001b[39m, in \u001b[36mtune_camera\u001b[39m\u001b[34m(dev_idx, worker, brief_name)\u001b[39m\n\u001b[32m    162\u001b[39m it += \u001b[32m1\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrief_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Test \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_iters\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m exp=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m focus=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m gain=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m bright=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m stats = \u001b[43mevaluate_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# scoring: primary = average tags detected, secondary = fps, penalize variance\u001b[39;00m\n\u001b[32m    166\u001b[39m score = stats[\u001b[33m\"\u001b[39m\u001b[33mavg_tags\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[32m100.0\u001b[39m + stats[\u001b[33m\"\u001b[39m\u001b[33mfps\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[32m0.2\u001b[39m - stats[\u001b[33m\"\u001b[39m\u001b[33mstd_tags\u001b[39m\u001b[33m\"\u001b[39m]*\u001b[32m10.0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36mevaluate_setting\u001b[39m\u001b[34m(worker, sample_duration)\u001b[39m\n\u001b[32m    117\u001b[39m frame, ts = worker.read_latest()\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     time.sleep(SAMPLE_SLEEP)\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    121\u001b[39m frames += \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2, time, threading, subprocess, json, os, numpy as np, sys\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DICT_TYPE = cv2.aruco.DICT_APRILTAG_36h11\n",
    "\n",
    "CAM_SOURCES = {\n",
    "    \"Mobile\":\"http://192.168.137.110:8080/video\",\n",
    "    \"Kreo1\": 0,\n",
    "    \"Kreo2\": 4\n",
    "}\n",
    "\n",
    "# parameter grids. Tweak if needed\n",
    "EXPOSURES = [80, 120, 160, 200, 240, 300]\n",
    "FOCUSES = [80, 120, 160, 200, 240, 280, 320, 360]\n",
    "GAINS = [0, 6, 12, 18]\n",
    "BRIGHTNESSES = [0, 8, 16, 24]\n",
    "\n",
    "# evaluation parameters\n",
    "EVAL_SECONDS = 1\n",
    "SAMPLE_SLEEP = 0.02\n",
    "\n",
    "OUTPUT_DIR = \"./camera_tune_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# AprilTag detector setup\n",
    "def create_detector():\n",
    "    \"\"\"Setup AprilTag detector with tuned parameters.\"\"\"\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(DICT_TYPE)\n",
    "    params = cv2.aruco.DetectorParameters()\n",
    "    params.adaptiveThreshWinSizeMin = 3\n",
    "    params.adaptiveThreshWinSizeMax = 35\n",
    "    params.adaptiveThreshWinSizeStep = 2\n",
    "    params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    params.cornerRefinementWinSize = 5\n",
    "    params.cornerRefinementMaxIterations = 50\n",
    "    params.cornerRefinementMinAccuracy = 0.01\n",
    "    params.minMarkerPerimeterRate = 0.02\n",
    "    params.maxMarkerPerimeterRate = 4.0\n",
    "    params.polygonalApproxAccuracyRate = 0.02\n",
    "    params.adaptiveThreshConstant = 7\n",
    "    return cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "\n",
    "class CameraWorker(threading.Thread):\n",
    "    def __init__(self, name, src, detector):\n",
    "        super().__init__(daemon=True)\n",
    "        self.name = name\n",
    "        self.src = src\n",
    "        self.cap = cv2.VideoCapture(src)\n",
    "\n",
    "        try:\n",
    "            self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        except Exception:\n",
    "            pass\n",
    "        if isinstance(src, int):\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "            self.cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "        self.detector = detector\n",
    "        self.lock = threading.Lock()\n",
    "        self.latest_frame = None\n",
    "        self.latest_ts = 0.0\n",
    "        self.running = True\n",
    "        self.opened = self.cap.isOpened()\n",
    "        if not self.opened:\n",
    "            print(f\"[{self.name}] Error cannot open source {src}\")\n",
    "\n",
    "    def run(self):\n",
    "        while self.running and self.opened:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            ts = time.time()\n",
    "            with self.lock:\n",
    "                self.latest_frame = frame\n",
    "                self.latest_ts = ts\n",
    "            time.sleep(0.001)\n",
    "\n",
    "    def read_latest(self):\n",
    "        with self.lock:\n",
    "            if self.latest_frame is None:\n",
    "                return None, 0.0\n",
    "            return self.latest_frame.copy(), self.latest_ts\n",
    "    \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        try: self.cap.release()\n",
    "        except: pass\n",
    "\n",
    "# v4l2 control helper\n",
    "def v4l2_set(dev_idx, control, value):\n",
    "    dev = f\"/dev/video{dev_idx}\"\n",
    "    cmd = [\"v4l2-ctl\", \"-d\", dev, \"-c\", f\"{control}={value}\"]\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError:\n",
    "        return False\n",
    "\n",
    "def v4l2_get(dev_idx, control):\n",
    "    dev = f\"/dev/video{dev_idx}\"\n",
    "    cmd = [\"v4l2-ctl\", \"-d\", dev, \"--get-ctrl\", control]\n",
    "    try:\n",
    "        out = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode().strip()\n",
    "        return out\n",
    "    except subprocess.CalledProcessError:\n",
    "        return None\n",
    "    \n",
    "def evaluate_setting(worker, sample_duration=EVAL_SECONDS):\n",
    "    start = time.time()\n",
    "    end = start + sample_duration\n",
    "    tag_counts = []\n",
    "    frames = 0\n",
    "    t0 = time.time()\n",
    "    while time.time()<end:\n",
    "        frame, ts = worker.read_latest()\n",
    "        if frame is None:\n",
    "            time.sleep(SAMPLE_SLEEP)\n",
    "            continue\n",
    "        frames += 1\n",
    "        corners, ids, _ = worker.detector.detectMarkers(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "        n = 0 if ids is None else len(ids)\n",
    "        tag_counts.append(n)\n",
    "        time.sleep(SAMPLE_SLEEP)\n",
    "    elapsed = time.time()- t0\n",
    "    avg_tags = float(np.mean(tag_counts)) if tag_counts else 0.0\n",
    "    std_tags = float(np.std(tag_counts)) if tag_counts else 0.0\n",
    "    fps = frames / elapsed if elapsed>0 else 0.0\n",
    "    return { \"avg_tags\": avg_tags, \"std_tags\": std_tags, \"fps\": fps, \"samples\": len(tag_counts)}\n",
    "\n",
    "def tune_camera(dev_idx, worker, brief_name):\n",
    "    if not isinstance(worker.src, int):\n",
    "        print(f\"[{brief_name}] Skipping tuning for non-local source {worker.src}\")\n",
    "        return None\n",
    "    print(f\"[{brief_name}] Starting auto-tune (this may take a few minutes)...\")\n",
    "\n",
    "    try: \n",
    "        v4l2_set(dev_idx, \"focus_automatic_continuous\",0)\n",
    "        v4l2_set(dev_idx, \"auto_exposure\", 1)\n",
    "        v4l2_set(dev_idx, \"exposure_dynamic_framerate\",0)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    best = {\"score\": -1.0}\n",
    "    total_iters = len(EXPOSURES)*len(FOCUSES)*len(GAINS)*len(BRIGHTNESSES)\n",
    "    it = 0\n",
    "    for exp in EXPOSURES:\n",
    "        ok = v4l2_set(dev_idx, \"exposure_time_absolute\", int(exp))\n",
    "        if not ok:\n",
    "            pass\n",
    "        time.sleep(0.08)\n",
    "        for f in FOCUSES:\n",
    "            v4l2_set(dev_idx, \"focus_absolute\", int(f))\n",
    "            time.sleep(0.04)\n",
    "            for g in GAINS:\n",
    "                v4l2_set(dev_idx, \"gain\", int(g))\n",
    "                time.sleep(0.02)\n",
    "                for b in BRIGHTNESSES:\n",
    "                    v4l2_set(dev_idx, \"brightness\", int(b))\n",
    "                    time.sleep(0.06)  # let camera settle a little\n",
    "                    it += 1\n",
    "                    print(f\"[{brief_name}] Test {it}/{total_iters} exp={exp} focus={f} gain={g} bright={b} ...\", end=\"\\r\")\n",
    "                    stats = evaluate_setting(worker)\n",
    "                    # scoring: primary = average tags detected, secondary = fps, penalize variance\n",
    "                    score = stats[\"avg_tags\"] * 100.0 + stats[\"fps\"] * 0.2 - stats[\"std_tags\"]*10.0\n",
    "                    if score > best.get(\"score\", -1.0):\n",
    "                        best = {\n",
    "                            \"score\": score,\n",
    "                            \"exp\": int(exp),\n",
    "                            \"focus\": int(f),\n",
    "                            \"gain\": int(g),\n",
    "                            \"brightness\": int(b),\n",
    "                            \"stats\": stats.copy()\n",
    "                        }\n",
    "    print(\"\")  # newline after progress\n",
    "\n",
    "    if best.get(\"score\", -1.0) < 0:\n",
    "        print(f\"[{brief_name}] No valid tuning results found.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"[{brief_name}] Best found: exposure={best['exp']} focus={best['focus']} gain={best['gain']} brightness={best['brightness']}\")\n",
    "    print(f\"[{brief_name}] stats: avg_tags={best['stats']['avg_tags']:.2f}, fps={best['stats']['fps']:.1f}, std={best['stats']['std_tags']:.2f}\")\n",
    "\n",
    "    # Apply the best settings finally\n",
    "    v4l2_set(dev_idx, \"exposure_time_absolute\", int(best['exp']))\n",
    "    v4l2_set(dev_idx, \"focus_absolute\", int(best['focus']))\n",
    "    v4l2_set(dev_idx, \"gain\", int(best['gain']))\n",
    "    v4l2_set(dev_idx, \"brightness\", int(best['brightness']))\n",
    "\n",
    "    # Save to JSON\n",
    "    out_file = os.path.join(OUTPUT_DIR, f\"best_camera_settings_{brief_name}.json\")\n",
    "    with open(out_file, \"w\") as f:\n",
    "        json.dump(best, f, indent=2)\n",
    "    print(f\"[{brief_name}] Best settings saved -> {out_file}\")\n",
    "    return best\n",
    "\n",
    "def get_camera_selection():\n",
    "    print(\"\\n=== Multi-Camera Live View Setup ===\")\n",
    "    print(\"Select cameras to open (comma separated):\")\n",
    "    print(\"1. Kreo Webcam #1\")\n",
    "    print(\"2. Kreo Webcam #2\")\n",
    "    print(\"3. Mobile IP Webcam\")\n",
    "    print(\"Example: 1,2 or 1,3 or 1,2,3\")\n",
    "    user_in = input(\"Cameras to open: \").strip()\n",
    "    choices = [x.strip() for x in user_in.split(\",\") if x.strip()]\n",
    "    selected = []\n",
    "    for c in choices:\n",
    "        if c == \"1\":\n",
    "            selected.append((\"Kreo1\", CAM_SOURCES[\"Kreo1\"]))\n",
    "        elif c == \"2\":\n",
    "            selected.append((\"Kreo2\", CAM_SOURCES[\"Kreo2\"]))\n",
    "        elif c == \"3\":\n",
    "            selected.append((\"Mobile\", CAM_SOURCES[\"Mobile\"]))\n",
    "        else:\n",
    "            print(f\"[WARN] Ignoring invalid entry: {c}\")\n",
    "    if not selected:\n",
    "        print(\"[ERROR] No valid cameras selected. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    return selected\n",
    "\n",
    "# ==================== MAIN ====================\n",
    "if __name__ == \"__main__\":\n",
    "    selected = get_camera_selection()\n",
    "\n",
    "    workers = {}\n",
    "    for name, src in selected:\n",
    "        w = CameraWorker(name, src, create_detector())\n",
    "        w.start()\n",
    "        workers[name] = w\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    # small warmup\n",
    "    print(\"[INFO] Warmup for 1.2 seconds to let cameras settle...\")\n",
    "    time.sleep(1.2)\n",
    "    \n",
    "    for name, w in list(workers.items()):\n",
    "        if isinstance(w.src,int):\n",
    "            try:\n",
    "                dev_idx = int(w.src)\n",
    "            except Exception:\n",
    "                print(f\"[{name}] Invalid device index for tuning: {w.src}\")\n",
    "                continue\n",
    "            best = tune_camera(dev_idx, w, name)\n",
    "        else:\n",
    "            print(f\"[{name}] Not a local device; skipping tuning.\")\n",
    "\n",
    "    # After tuning show live preview with settings applied\n",
    "    print(\"[INFO] Tuning complete. Press ESC to exit preview windows.\")\n",
    "    last_ts = {name: 0.0 for name in workers}\n",
    "    fps_counter = {name: 0 for name in workers}\n",
    "    fps = {name: 0.0 for name in workers}\n",
    "    last_fps_update = time.time()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            now = time.time()\n",
    "            timestamps = {}\n",
    "\n",
    "            # --- Collect frames from all cameras ---\n",
    "            for name, w in workers.items():\n",
    "                frame, ts = w.read_latest()\n",
    "                if frame is None:\n",
    "                    continue\n",
    "                timestamps[name] = ts\n",
    "\n",
    "                # --- FPS update ---\n",
    "                if ts != last_ts[name]:\n",
    "                    fps_counter[name] += 1\n",
    "                    last_ts[name] = ts\n",
    "\n",
    "                if now - last_fps_update >= 1.0:\n",
    "                    fps[name] = fps_counter[name]\n",
    "                    fps_counter[name] = 0\n",
    "\n",
    "            if now - last_fps_update >= 1.0:\n",
    "                last_fps_update = now\n",
    "\n",
    "            # --- Drift calculation ---\n",
    "            if len(timestamps) > 1:\n",
    "                tvals = np.array(list(timestamps.values()))\n",
    "                drift_ms = (tvals.max() - tvals.min()) * 1000.0\n",
    "            else:\n",
    "                drift_ms = 0.0\n",
    "\n",
    "            # --- Draw every camera independently ---\n",
    "            for name, w in workers.items():\n",
    "                frame, ts = w.read_latest()\n",
    "                if frame is None:\n",
    "                    continue\n",
    "                # AprilTag overlay\n",
    "                corners, ids, _ = w.detector.detectMarkers(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "                if ids is not None and len(ids) > 0:\n",
    "                    cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "                # resolution text\n",
    "                h, wid = frame.shape[:2]\n",
    "                cv2.putText(frame, f\"{name} {wid}x{h}\", (10, 25),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200,200,0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"FPS: {fps[name]:.0f}\", (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200,200,0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"Drift: {drift_ms:.1f} ms\", (10, 75),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
    "\n",
    "                cv2.imshow(f\"Tuned - {name}\", frame)\n",
    "\n",
    "            # Exit on ESC\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "            time.sleep(0.001)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        for w in workers.values():\n",
    "            w.stop()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
