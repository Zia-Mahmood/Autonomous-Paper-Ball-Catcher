{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e313705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kreo1] AprilTagThread started\n",
      "[kreo1] BallThread started\n",
      "[kreo2] AprilTagThread started\n",
      "[kreo2] BallThread started\n",
      "[Subscriber] connected, waiting for frames... (Press ESC to exit)\n",
      "[DETECT-kreo1] AprilTag Detector thread stopped\n",
      "[kreo2] BallDetectorThread stopped\n",
      "[kreo1] BallDetectorThread stopped\n",
      "[DETECT-kreo2] AprilTag Detector thread stopped\n",
      "Exit clean.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# subscriber.py\n",
    "import cv2, zmq, numpy as np, time, threading, queue, traceback, sys\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ---------- Config ----------\n",
    "ZMQ_ADDR = \"tcp://localhost:5555\"\n",
    "SUB_TOPICS = [b\"kreo1\", b\"kreo2\"]\n",
    "FPS_WINDOW = 1.0        # seconds for fps moving window\n",
    "DISPLAY_FPS = 20\n",
    "VISUALIZE = True     # show tiled view window\n",
    "\n",
    "# ---------------- APRILTAG CONFIG ----------------\n",
    "DICT_TYPE = cv2.aruco.DICT_APRILTAG_36h11\n",
    "def create_april_detector():\n",
    "    \"\"\"Setup AprilTag detector with tuned parameters.\"\"\"\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(DICT_TYPE)\n",
    "    params = cv2.aruco.DetectorParameters()\n",
    "    params.adaptiveThreshWinSizeMin = 3\n",
    "    params.adaptiveThreshWinSizeMax = 35\n",
    "    params.adaptiveThreshWinSizeStep = 2\n",
    "    params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    params.cornerRefinementWinSize = 7\n",
    "    params.cornerRefinementMaxIterations = 100\n",
    "    params.cornerRefinementMinAccuracy = 0.01\n",
    "    params.minMarkerPerimeterRate = 0.02\n",
    "    params.maxMarkerPerimeterRate = 6.0\n",
    "    params.polygonalApproxAccuracyRate = 0.02\n",
    "    params.adaptiveThreshConstant = 7\n",
    "    return cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "\n",
    "# color thresholds (you gave these)\n",
    "orange_hsvVals = {'hmin': 0,  'smin': 94,  'vmin': 156, 'hmax': 12,  'smax': 255, 'vmax': 255}\n",
    "purple_hsvVals = {'hmin': 113,'smin': 78,  'vmin': 3,   'hmax': 129, 'smax': 255, 'vmax': 255}\n",
    "\n",
    "# detector parameters\n",
    "MIN_AREA = 150    # min contour area to accept (tune if needed)\n",
    "MAX_AREA = 20000  # max area (avoid very large blobs)\n",
    "CIRCULARITY_MIN = 0.25  # min circularity to accept (lower because paper balls can deform)\n",
    "ASPECT_RATIO_MAX = 2.0   # reject extremely elongated blobs\n",
    "MAX_DETECTIONS_PER_CAM = 12  # safety limit\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def fmt_ts(ts):\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(ts)) + f\".{int((ts%1)*1000):03d}\"\n",
    "\n",
    "def recv_latest(sub):\n",
    "    msg = None\n",
    "    while True:\n",
    "        try:\n",
    "            msg = sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        except zmq.Again:\n",
    "            break\n",
    "    return msg\n",
    "\n",
    "def update_fps(camera, cam_ts):\n",
    "    dq = fps_windows[camera]\n",
    "    dq.append(cam_ts)\n",
    "    # pop older than window\n",
    "    while dq and (cam_ts - dq[0]) > FPS_WINDOW:\n",
    "        dq.popleft()\n",
    "    fps = len(dq) / FPS_WINDOW\n",
    "    return fps\n",
    "\n",
    "# ---------- Color masking helpers ----------\n",
    "def hsv_mask_from_vals(bgr_img, hsvVals):\n",
    "    \"\"\"Return binary mask from HSV thresholds dict.\"\"\"\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([hsvVals['hmin'], hsvVals['smin'], hsvVals['vmin']], dtype=np.uint8)\n",
    "    upper = np.array([hsvVals['hmax'], hsvVals['smax'], hsvVals['vmax']], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    # small blur to reduce speckle\n",
    "    mask = cv2.medianBlur(mask, 5)\n",
    "    return mask\n",
    "\n",
    "def postprocess_mask(mask):\n",
    "    \"\"\"Morphological clean-up.\"\"\"\n",
    "    # open then close\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    m = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    return m\n",
    "\n",
    "def find_candidate_contours(mask):\n",
    "    \"\"\"Return list of contours filtered by area and shape heuristics.\"\"\"\n",
    "    if mask is None:\n",
    "        return []\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < MIN_AREA or area > MAX_AREA:\n",
    "            continue\n",
    "        perim = cv2.arcLength(c, True)\n",
    "        if perim <= 0:\n",
    "            continue\n",
    "        circularity = 4 * np.pi * area / (perim * perim)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect = float(w)/float(h) if h>0 else 0.0\n",
    "        # accept if roughly circular-ish or moderate area even if circularity low\n",
    "        if circularity >= CIRCULARITY_MIN or (0.5*min(w,h) > 5 and area > (MIN_AREA*2)):\n",
    "            if aspect <= ASPECT_RATIO_MAX:\n",
    "                candidates.append((c, area, (int(x),int(y),int(w),int(h))))\n",
    "    # sort by area desc\n",
    "    candidates.sort(key=lambda d: d[1], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# APRILTAG DETECTOR THREAD\n",
    "\n",
    "class AprilTagThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue, detect_cache, lock):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.detect_cache = detect_cache\n",
    "        self.lock = lock\n",
    "        self.detector = create_april_detector()\n",
    "        self.stop_flag = False\n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] AprilTagThread started\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                frame,ts = self.frame_queue.get(timeout=0.1)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                corners, ids, _ = self.detector.detectMarkers(gray)\n",
    "                det={\"corners\":corners,\"ids\":ids,\"ts\":ts,\"det_time\":time.time()}\n",
    "\n",
    "                with self.lock:\n",
    "                    if self.cam_name not in self.detect_cache:\n",
    "                        self.detect_cache[self.cam_name]={}\n",
    "                    self.detect_cache[self.cam_name][\"tags\"]=det\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR-{self.cam_name}] AprilTag Detection exception:\", e)\n",
    "                traceback.print_exc()\n",
    "\n",
    "        print(f\"[DETECT-{self.cam_name}] AprilTag Detector thread stopped\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "\n",
    "# BALL DETECTOR THREAD\n",
    "class BallThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue, detect_cache, lock):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.detect_cache = detect_cache\n",
    "        self.lock = lock\n",
    "        self.stop_flag = False\n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] BallThread started\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                frame,ts=self.frame_queue.get(timeout=0.1)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                mo=hsv_mask_from_vals(frame,orange_hsvVals)\n",
    "                mp=hsv_mask_from_vals(frame,purple_hsvVals)\n",
    "\n",
    "                mc = cv2.bitwise_or(mo,mp)\n",
    "                mc = postprocess_mask(mc)\n",
    "\n",
    "                cand = find_candidate_contours(mc)\n",
    "\n",
    "                dets = []\n",
    "                for c,area,(x,y,w,h) in cand[:MAX_DETECTIONS_PER_CAM]:\n",
    "                    M = cv2.moments(c)\n",
    "                    if M[\"m00\"] != 0:\n",
    "                        cx = int(M[\"m10\"]/M[\"m00\"]); cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "                    else:\n",
    "                        cx = x + w//2; cy = y + h//2\n",
    "                    \n",
    "                    s_or = int(np.count_nonzero(mo[y:y+h,x:x+w])) if mo is not None else 0\n",
    "                    s_pu = int(np.count_nonzero(mp[y:y+h,x:x+w])) if mp is not None else 0\n",
    "\n",
    "                    if s_or>s_pu and s_or>0:\n",
    "                        col=\"orange\"\n",
    "                    elif s_pu>s_or and s_pu>0:\n",
    "                        col=\"purple\"\n",
    "                    else:\n",
    "                        hsv_roi=cv2.cvtColor(frame[y:y+h,x:x+w],cv2.COLOR_BGR2HSV)\n",
    "                        mean_h=int(np.mean(hsv_roi[:,:,0]))\n",
    "                        if orange_hsvVals[\"hmin\"]<=mean_h<=orange_hsvVals[\"hmax\"]:\n",
    "                            col=\"orange\"\n",
    "                        elif purple_hsvVals[\"hmin\"]<=mean_h<=purple_hsvVals[\"hmax\"]:\n",
    "                            col=\"purple\"\n",
    "                        else:\n",
    "                            col=\"unknown\"\n",
    "\n",
    "                    dets.append({\n",
    "                        \"bbox\":(x,y,w,h),\n",
    "                        \"centroid\":(cx,cy),\n",
    "                        \"area\":float(area),\n",
    "                        \"color\":col,\n",
    "                        \"ts\":ts,\n",
    "                        \"det_time\":time.time()\n",
    "                    })\n",
    "                with self.lock:\n",
    "                    if self.cam_name not in self.detect_cache:\n",
    "                        self.detect_cache[self.cam_name]={}\n",
    "                    self.detect_cache[self.cam_name][\"balls\"] = dets\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR-{self.cam_name}] ball detection exception:\", e)\n",
    "                traceback.print_exc()\n",
    "\n",
    "        print(f\"[{self.cam_name}] BallDetectorThread stopped\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "\n",
    "# ---------- ZMQ subscriber ----------\n",
    "ctx = zmq.Context()\n",
    "sub = ctx.socket(zmq.SUB)\n",
    "sub.connect(ZMQ_ADDR)\n",
    "sub.setsockopt(zmq.RCVHWM, 1)\n",
    "sub.setsockopt(zmq.CONFLATE, 1)  # keep only last message\n",
    "sub.setsockopt(zmq.LINGER, 0)\n",
    "\n",
    "# ---- ACTIVE FLUSH ----\n",
    "flushed = 0\n",
    "while True:\n",
    "    try:\n",
    "        sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        flushed += 1\n",
    "    except zmq.Again:\n",
    "        break\n",
    "if flushed > 0:\n",
    "    print(f\"[Subscriber] Flushed {flushed} stale messages.\")\n",
    "for t in SUB_TOPICS:\n",
    "    sub.setsockopt(zmq.SUBSCRIBE, t)\n",
    "\n",
    "# per-camera structures\n",
    "frames = {}\n",
    "fps_windows = defaultdict(lambda: deque())\n",
    "frame_queues = {t.decode(): queue.Queue(maxsize=1) for t in SUB_TOPICS}\n",
    "detect_cache = {}        # cam -> detection dict\n",
    "detect_lock = threading.Lock()\n",
    "tag_threads={}\n",
    "ball_threads={}\n",
    "\n",
    "for t in SUB_TOPICS:\n",
    "    cam_name = t.decode()\n",
    "    tag_threads[cam_name] = AprilTagThread(cam_name,frame_queues[cam_name],detect_cache,detect_lock)\n",
    "    ball_threads[cam_name] = BallThread(cam_name,frame_queues[cam_name],detect_cache,detect_lock)\n",
    "\n",
    "    tag_threads[cam_name].start()\n",
    "    ball_threads[cam_name].start()\n",
    "\n",
    "print(\"[Subscriber] connected, waiting for frames... (Press ESC to exit)\")\n",
    "\n",
    "last_show = time.time()\n",
    "# ---------- Main loop ----------\n",
    "try:\n",
    "    while True:\n",
    "        parts=recv_latest(sub)\n",
    "        if parts is None: continue\n",
    "\n",
    "        topic=parts[0]; cam=topic.decode()\n",
    "        if len(parts)>=3:\n",
    "            ts_part=parts[1]; jpg_part=parts[2]\n",
    "        else:\n",
    "            ts_part=None; jpg_part=parts[1]\n",
    "\n",
    "        recv_t=time.time()\n",
    "        try: cam_ts=float(ts_part.decode()) if ts_part else recv_t\n",
    "        except: cam_ts=recv_t\n",
    "\n",
    "        img=cv2.imdecode(np.frombuffer(jpg_part,np.uint8),cv2.IMREAD_COLOR)\n",
    "        if img is None: continue\n",
    "\n",
    "        fps=update_fps(cam,cam_ts)\n",
    "        frames[cam]={\"img\":img,\"cam_ts\":cam_ts,\"fps\":fps}\n",
    "\n",
    "        # push frame to both detector queues\n",
    "        fq=frame_queues[cam]\n",
    "        try: fq.get_nowait()\n",
    "        except: pass\n",
    "        try: fq.put_nowait((img.copy(),cam_ts))\n",
    "        except: pass\n",
    "\n",
    "        # visual output if both cams available\n",
    "        if all(k in frames for k in [t.decode() for t in SUB_TOPICS]):\n",
    "            cams=[t.decode() for t in SUB_TOPICS]\n",
    "            L=frames[cams[0]]; R=frames[cams[1]]\n",
    "            drift_ms=abs(L[\"cam_ts\"]-R[\"cam_ts\"])*1000.0\n",
    "\n",
    "            def overlay(F,cam_name):\n",
    "                im=F[\"img\"].copy()\n",
    "                y=20\n",
    "                cv2.putText(im,f\"{cam_name}\",(10,y),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,32,20),2)\n",
    "                cv2.putText(im,f\"FPS:{F['fps']:.1f}\",(10,y+26),cv2.FONT_HERSHEY_SIMPLEX,0.6,(14,117,5),2)\n",
    "                cv2.putText(im,f\"cam_ts:{fmt_ts(F['cam_ts'])}\",(10,y+52),cv2.FONT_HERSHEY_SIMPLEX,0.5,(5,12,117),1)\n",
    "\n",
    "                with detect_lock:\n",
    "                    block=detect_cache.get(cam_name,{})\n",
    "\n",
    "                    # draw AprilTags\n",
    "                    if \"tags\" in block and block[\"tags\"][\"ids\"] is not None:\n",
    "                        cs=block[\"tags\"][\"corners\"]\n",
    "                        ids=block[\"tags\"][\"ids\"]\n",
    "                        cv2.aruco.drawDetectedMarkers(im,cs,ids)\n",
    "\n",
    "                    # draw balls\n",
    "                    if \"balls\" in block:\n",
    "                        for i,d in enumerate(block[\"balls\"]):\n",
    "                            x,y,w,h=d[\"bbox\"]\n",
    "                            cx,cy=d[\"centroid\"]\n",
    "                            color=d[\"color\"]\n",
    "                            if color==\"orange\": bc=(0,200,255)\n",
    "                            elif color==\"purple\": bc=(200,0,200)\n",
    "                            else: bc=(0,200,200)\n",
    "                            cv2.rectangle(im,(x,y),(x+w,y+h),bc,2)\n",
    "                            cv2.circle(im,(cx,cy),4,(0,0,255),-1)\n",
    "                            cv2.putText(im,f\"{color}:{i}\",(x,y-6),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX,0.5,bc,2)\n",
    "\n",
    "                return im\n",
    "\n",
    "            if VISUALIZE and (time.time()-last_show)>(1.0/DISPLAY_FPS):\n",
    "                last_show=time.time()\n",
    "                left_im=overlay(L,cams[0])\n",
    "                right_im=overlay(R,cams[1])\n",
    "\n",
    "                h=max(left_im.shape[0],right_im.shape[0])\n",
    "                right_res=cv2.resize(right_im,(left_im.shape[1],h))\n",
    "                tile=np.hstack([left_im,right_res])\n",
    "\n",
    "                cv2.putText(tile,f\"Drift:{drift_ms:.1f}ms\",(10,20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)\n",
    "                \n",
    "                cv2.putText(tile, f\"Host now: {fmt_ts(time.time())}\", (10, 44), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "                cv2.imshow(\"Combined Detection\",tile)\n",
    "            elif not VISUALIZE:\n",
    "                with detect_lock:\n",
    "                    tag_summary = []\n",
    "                    parts_status = []\n",
    "                    for c in cams:\n",
    "                        block = detect_cache.get(c,{})\n",
    "\n",
    "                        if \"tags\" in block and block[\"tags\"][\"ids\"] is not None:\n",
    "                            ids=block[\"tags\"][\"ids\"]\n",
    "                            tag_summary.append(f\"{c}: {ids.flatten().tolist()}\")\n",
    "                        elif \"tags\" in block:\n",
    "                            tag_summary.append(f\"{c}: No tags\")\n",
    "                        else:\n",
    "                            tag_summary.append(f\"{c}: No detection data\")\n",
    "                        if \"balls\" in block:\n",
    "                            counts = { \"orange\":0, \"purple\":0, \"unknown\":0 }\n",
    "                            for i,d in enumerate(block[\"balls\"]):\n",
    "                                counts[d.get(\"color\",\"unknown\")] = counts.get(d.get(\"color\",\"unknown\"),0) + 1\n",
    "                            parts_status.append(f\"{c}: Orange: {counts['orange']} Purple: {counts['purple']}\")\n",
    "                        else:\n",
    "                            parts_status.append(f\"{c}:NoBall\")    \n",
    "                status = (\n",
    "                    f\"Drift {drift_ms:.1f} ms | \"\n",
    "                    f\"{cams[0]} ts: {fmt_ts(L['cam_ts'])} | \"\n",
    "                    f\"{cams[1]} ts: {fmt_ts(R['cam_ts'])} | \"\n",
    "                    f\"Host now: {fmt_ts(time.time())} | \"\n",
    "                    f\"{cams[0]} FPS: {L['fps']:.1f} | \"\n",
    "                    f\"{cams[1]} FPS: {R['fps']:.1f} | \"\n",
    "                    f\"Tags:\" + \",\".join(tag_summary)\n",
    "                )\n",
    "                sys.stdout.write(\"\\r\" + status + \" \" * 20 + \" | \".join(parts_status) + \" \" * 20)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        if cv2.waitKey(1)&0xFF==27:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    for t in tag_threads.values(): t.stop()\n",
    "    for t in ball_threads.values(): t.stop()\n",
    "    time.sleep(0.1)\n",
    "    cv2.destroyAllWindows()\n",
    "    sub.close()\n",
    "    ctx.term()\n",
    "    print(\"Exit clean.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6871f0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kreo1] Ball Thread started.\n",
      "[kreo1] Tag Thread started.\n",
      "[kreo2] Ball Thread started.\n",
      "[kreo2] Tag Thread started.\n",
      "[System] Decoupled Detection Started. Logging to ../../data/detection_logs/log_1764422090.csv\n",
      "\n",
      "Clean exit.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import zmq\n",
    "import numpy as np\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import traceback\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ---------- Config ----------\n",
    "ZMQ_ADDR = \"tcp://localhost:5555\"\n",
    "SUB_TOPICS = [b\"kreo1\", b\"kreo2\"]\n",
    "\n",
    "FPS_WINDOW = 1.0        \n",
    "DISPLAY_FPS = 30        \n",
    "VISUALIZE = True        \n",
    "\n",
    "# SCALING CONFIG\n",
    "BALL_DETECTION_SCALE = 0.5  # Downscale for speed (Ball)\n",
    "TAG_DETECTION_SCALE = 1.0   # Full res for accuracy (Tags)\n",
    "\n",
    "LOG_DIR = \"../../data/detection_logs\"\n",
    "LOG_FILENAME = f\"{LOG_DIR}/log_{int(time.time())}.csv\"\n",
    "\n",
    "# HSV Config\n",
    "HSV_CONFIG = {\n",
    "    \"kreo1\": { \"orange\": {'hmin': 0, 'smin': 116, 'vmin': 160, 'hmax': 12, 'smax': 197, 'vmax': 255} },\n",
    "    \"kreo2\": { \"orange\": {'hmin': 0, 'smin': 79, 'vmin': 181, 'hmax': 12, 'smax': 255, 'vmax': 255} }\n",
    "}\n",
    "DEFAULT_HSV = {'hmin': 0, 'smin': 100, 'vmin': 100, 'hmax': 25, 'smax': 255, 'vmax': 255}\n",
    "\n",
    "# Detector parameters\n",
    "BASE_MIN_AREA = 100    \n",
    "BASE_MAX_AREA = 20000  \n",
    "CIRCULARITY_MIN = 0.5\n",
    "ASPECT_RATIO_MIN = 0.6 \n",
    "ASPECT_RATIO_MAX = 1.6   \n",
    "MAX_DETECTIONS_PER_CAM = 5 \n",
    "\n",
    "# AprilTag Config\n",
    "DICT_TYPE = cv2.aruco.DICT_APRILTAG_36h11\n",
    "def create_april_detector():\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(DICT_TYPE)\n",
    "    params = cv2.aruco.DetectorParameters()\n",
    "    params.adaptiveThreshWinSizeMin = 3\n",
    "    params.adaptiveThreshWinSizeMax = 35\n",
    "    params.adaptiveThreshWinSizeStep = 2\n",
    "    params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    params.cornerRefinementWinSize = 7\n",
    "    params.cornerRefinementMaxIterations = 50\n",
    "    params.cornerRefinementMinAccuracy = 0.01\n",
    "    params.minMarkerPerimeterRate = 0.02\n",
    "    params.maxMarkerPerimeterRate = 6.0\n",
    "    params.polygonalApproxAccuracyRate = 0.02\n",
    "    params.adaptiveThreshConstant = 7\n",
    "    return cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "\n",
    "# ---------- Logging Setup ----------\n",
    "if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)\n",
    "log_queue = queue.Queue()\n",
    "\n",
    "def logger_worker():\n",
    "    try:\n",
    "        with open(LOG_FILENAME, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                \"timestamp\", \"camera\", \n",
    "                \"ball_detected\", \"ball_x\", \"ball_y\", \"ball_area\",\n",
    "                \"tag4_detected\", \"tag4_x\", \"tag4_y\",\n",
    "                \"tag5_detected\", \"tag5_x\", \"tag5_y\"\n",
    "            ])\n",
    "            while True:\n",
    "                entry = log_queue.get()\n",
    "                if entry is None: break\n",
    "                writer.writerow(entry)\n",
    "                log_queue.task_done()\n",
    "    except Exception as e: print(f\"[LOGGER ERROR] {e}\")\n",
    "\n",
    "log_thread = threading.Thread(target=logger_worker, daemon=True)\n",
    "log_thread.start()\n",
    "\n",
    "# ---------- Shared Data (Thread Safe) ----------\n",
    "# Stores the latest tag detection result for each camera\n",
    "shared_tag_data = {\n",
    "    \"kreo1\": {\"tag4\": {\"detected\": False, \"x\":\"\", \"y\":\"\"}, \"tag5\": {\"detected\": False, \"x\":\"\", \"y\":\"\"}, \"viz\": []},\n",
    "    \"kreo2\": {\"tag4\": {\"detected\": False, \"x\":\"\", \"y\":\"\"}, \"tag5\": {\"detected\": False, \"x\":\"\", \"y\":\"\"}, \"viz\": []}\n",
    "}\n",
    "shared_data_lock = threading.Lock()\n",
    "\n",
    "# Stores the latest image/ball for visualization\n",
    "viz_cache = {}\n",
    "viz_lock = threading.Lock()\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def get_orange_mask(bgr_img, hsv_dict):\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([hsv_dict['hmin'], hsv_dict['smin'], hsv_dict['vmin']], dtype=np.uint8)\n",
    "    upper = np.array([hsv_dict['hmax'], hsv_dict['smax'], hsv_dict['vmax']], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    return cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "\n",
    "def find_ball_contours(mask, min_area, max_area):\n",
    "    if mask is None: return []\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < min_area or area > max_area: continue\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect = float(w)/float(h) if h > 0 else 0\n",
    "        if ASPECT_RATIO_MIN>aspect or aspect > ASPECT_RATIO_MAX: continue\n",
    "        perim = cv2.arcLength(c, True)\n",
    "        if perim == 0: continue\n",
    "        circularity = 4 * np.pi * area / (perim * perim)\n",
    "        if circularity >= CIRCULARITY_MIN:\n",
    "            candidates.append({\"bbox\": (x,y,w,h), \"area\": area, \"centroid\": (x+w//2, y+h//2)})\n",
    "    candidates.sort(key=lambda d: d[\"area\"], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "# ---------- THREAD 1: TAG DETECTOR (Slower, High Accuracy) ----------\n",
    "class TagDetectorThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.aruco_detector = create_april_detector()\n",
    "        self.stop_flag = False\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] Tag Thread started.\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                # Get raw bytes (Tag thread decodes independently to avoid blocking Ball thread)\n",
    "                jpg_bytes, cam_ts = self.frame_queue.get(timeout=0.1)\n",
    "                \n",
    "                # Decode\n",
    "                frame = cv2.imdecode(np.frombuffer(jpg_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "                if frame is None: continue\n",
    "\n",
    "                # Detect (Full Res)\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                corners, ids, _ = self.aruco_detector.detectMarkers(gray)\n",
    "                \n",
    "                tag4 = {\"detected\": False, \"x\": \"\", \"y\": \"\"}\n",
    "                tag5 = {\"detected\": False, \"x\": \"\", \"y\": \"\"}\n",
    "                viz_tags = []\n",
    "\n",
    "                if ids is not None:\n",
    "                    ids_flat = ids.flatten()\n",
    "                    for i, tag_id in enumerate(ids_flat):\n",
    "                        c = corners[i][0]\n",
    "                        cx = int(np.mean(c[:, 0]))\n",
    "                        cy = int(np.mean(c[:, 1]))\n",
    "                        \n",
    "                        viz_tags.append({\"id\": tag_id, \"corners\": corners[i]})\n",
    "\n",
    "                        if tag_id == 4:\n",
    "                            tag4 = {\"detected\": True, \"x\": cx, \"y\": cy}\n",
    "                        elif tag_id == 5:\n",
    "                            tag5 = {\"detected\": True, \"x\": cx, \"y\": cy}\n",
    "                \n",
    "                # Update Shared Memory\n",
    "                with shared_data_lock:\n",
    "                    shared_tag_data[self.cam_name] = {\n",
    "                        \"tag4\": tag4,\n",
    "                        \"tag5\": tag5,\n",
    "                        \"viz\": viz_tags\n",
    "                    }\n",
    "            except queue.Empty:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(f\"[TAG-ERR-{self.cam_name}]\", e)\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "# ---------- THREAD 2: BALL DETECTOR (Fast, Low Latency) ----------\n",
    "class BallDetectorThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.min_area_scaled = BASE_MIN_AREA * (BALL_DETECTION_SCALE**2)\n",
    "        self.max_area_scaled = BASE_MAX_AREA * (BALL_DETECTION_SCALE**2)\n",
    "        self.hsv_vals = HSV_CONFIG.get(cam_name, {}).get(\"orange\", DEFAULT_HSV)\n",
    "        self.stop_flag = False\n",
    "        self.fps_dq = deque()\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] Ball Thread started.\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                jpg_bytes, cam_ts = self.frame_queue.get(timeout=0.1)\n",
    "                \n",
    "                # Decode\n",
    "                frame = cv2.imdecode(np.frombuffer(jpg_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "                if frame is None: continue\n",
    "\n",
    "                # Resize for Speed\n",
    "                if BALL_DETECTION_SCALE != 1.0:\n",
    "                    frame_small = cv2.resize(frame, None, fx=BALL_DETECTION_SCALE, fy=BALL_DETECTION_SCALE, interpolation=cv2.INTER_NEAREST)\n",
    "                else:\n",
    "                    frame_small = frame\n",
    "\n",
    "                # Detect Ball\n",
    "                mask = get_orange_mask(frame_small, self.hsv_vals)\n",
    "                balls = find_ball_contours(mask, self.min_area_scaled, self.max_area_scaled)\n",
    "                \n",
    "                ball_data = {\"detected\": False, \"x\": \"\", \"y\": \"\", \"area\": \"\"}\n",
    "                viz_ball = None\n",
    "\n",
    "                if balls:\n",
    "                    b = balls[0] \n",
    "                    scale_inv = 1.0 / BALL_DETECTION_SCALE\n",
    "                    bx, by, bw, bh = b[\"bbox\"]\n",
    "                    real_x = int(bx * scale_inv); real_y = int(by * scale_inv)\n",
    "                    real_w = int(bw * scale_inv); real_h = int(bh * scale_inv)\n",
    "                    real_area = int(b[\"area\"] * (scale_inv**2))\n",
    "                    cx, cy = real_x + real_w//2, real_y + real_h//2\n",
    "                    \n",
    "                    ball_data = {\"detected\": True, \"x\": cx, \"y\": cy, \"area\": real_area}\n",
    "                    viz_ball = {\"bbox\": (real_x, real_y, real_w, real_h), \"centroid\": (cx, cy)}\n",
    "\n",
    "                # Read latest Tag Data (Non-blocking read)\n",
    "                with shared_data_lock:\n",
    "                    tags = shared_tag_data[self.cam_name]\n",
    "                \n",
    "                # LOGGING: Driven by the fast ball thread\n",
    "                log_queue.put([\n",
    "                    f\"{cam_ts:.3f}\", self.cam_name,\n",
    "                    ball_data[\"detected\"], ball_data[\"x\"], ball_data[\"y\"], ball_data[\"area\"],\n",
    "                    tags[\"tag4\"][\"detected\"], tags[\"tag4\"][\"x\"], tags[\"tag4\"][\"y\"],\n",
    "                    tags[\"tag5\"][\"detected\"], tags[\"tag5\"][\"x\"], tags[\"tag5\"][\"y\"]\n",
    "                ])\n",
    "\n",
    "                # FPS Calc\n",
    "                self.fps_dq.append(time.time())\n",
    "                while self.fps_dq and (self.fps_dq[-1] - self.fps_dq[0]) > FPS_WINDOW:\n",
    "                    self.fps_dq.popleft()\n",
    "                fps = len(self.fps_dq) / FPS_WINDOW\n",
    "\n",
    "                # Update Viz Cache\n",
    "                if VISUALIZE:\n",
    "                    with viz_lock:\n",
    "                        viz_cache[self.cam_name] = {\n",
    "                            \"img\": frame,\n",
    "                            \"ball\": viz_ball,\n",
    "                            \"tags\": tags[\"viz\"],\n",
    "                            \"fps\": fps\n",
    "                        }\n",
    "\n",
    "            except queue.Empty:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(f\"[BALL-ERR-{self.cam_name}]\", e)\n",
    "    \n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "# ---------- Main Execution ----------\n",
    "ctx = zmq.Context()\n",
    "sub = ctx.socket(zmq.SUB)\n",
    "sub.connect(ZMQ_ADDR)\n",
    "sub.setsockopt(zmq.RCVHWM, 4)\n",
    "sub.setsockopt(zmq.CONFLATE, 1) \n",
    "sub.setsockopt(zmq.LINGER, 0)\n",
    "for t in SUB_TOPICS: sub.setsockopt(zmq.SUBSCRIBE, t)\n",
    "\n",
    "# Init Queues (2 per camera: 1 for Ball, 1 for Tag)\n",
    "queues = {\n",
    "    \"kreo1\": {\"ball\": queue.Queue(maxsize=1), \"tag\": queue.Queue(maxsize=1)},\n",
    "    \"kreo2\": {\"ball\": queue.Queue(maxsize=1), \"tag\": queue.Queue(maxsize=1)}\n",
    "}\n",
    "\n",
    "threads = []\n",
    "# Spin up threads\n",
    "for cam in [\"kreo1\", \"kreo2\"]:\n",
    "    # Ball Thread\n",
    "    bt = BallDetectorThread(cam, queues[cam][\"ball\"])\n",
    "    bt.start()\n",
    "    threads.append(bt)\n",
    "    \n",
    "    # Tag Thread\n",
    "    tt = TagDetectorThread(cam, queues[cam][\"tag\"])\n",
    "    tt.start()\n",
    "    threads.append(tt)\n",
    "\n",
    "print(f\"[System] Decoupled Detection Started. Logging to {LOG_FILENAME}\")\n",
    "\n",
    "last_show = time.time()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # High Speed Ingestion Loop\n",
    "        try:\n",
    "            parts = sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "            topic = parts[0]\n",
    "            cam = topic.decode()\n",
    "            \n",
    "            ts_part = parts[1] if len(parts) >= 3 else None\n",
    "            jpg_part = parts[2] if len(parts) >= 3 else parts[1]\n",
    "            try:\n",
    "                cam_ts = float(ts_part.decode()) if ts_part else time.time()\n",
    "            except:\n",
    "                cam_ts = time.time()\n",
    "            \n",
    "            # Fan-out to both queues (LIFO logic)\n",
    "            qs = queues.get(cam)\n",
    "            if qs:\n",
    "                # Push to Ball Queue\n",
    "                try:\n",
    "                    qs[\"ball\"].put_nowait((jpg_part, cam_ts))\n",
    "                except queue.Full:\n",
    "                    try: qs[\"ball\"].get_nowait(); qs[\"ball\"].put_nowait((jpg_part, cam_ts))\n",
    "                    except: pass\n",
    "                \n",
    "                # Push to Tag Queue\n",
    "                try:\n",
    "                    qs[\"tag\"].put_nowait((jpg_part, cam_ts))\n",
    "                except queue.Full:\n",
    "                    try: qs[\"tag\"].get_nowait(); qs[\"tag\"].put_nowait((jpg_part, cam_ts))\n",
    "                    except: pass\n",
    "\n",
    "        except zmq.Again:\n",
    "            time.sleep(0.0001)\n",
    "\n",
    "        # Viz Loop\n",
    "        if VISUALIZE and (time.time() - last_show) > (1.0/DISPLAY_FPS):\n",
    "            with viz_lock:\n",
    "                has_data = all(c in viz_cache for c in [\"kreo1\", \"kreo2\"])\n",
    "                if has_data:\n",
    "                    def draw(cam_key):\n",
    "                        d = viz_cache[cam_key]\n",
    "                        im = d[\"img\"].copy()\n",
    "                        \n",
    "                        # Ball\n",
    "                        if d[\"ball\"]:\n",
    "                            bx,by,bw,bh = d[\"ball\"][\"bbox\"]\n",
    "                            cx,cy = d[\"ball\"][\"centroid\"]\n",
    "                            cv2.rectangle(im, (bx,by), (bx+bw, by+bh), (0,165,255), 2)\n",
    "                            cv2.circle(im, (cx,cy), 5, (0,0,255), -1)\n",
    "                        \n",
    "                        # Tags\n",
    "                        for tag in d[\"tags\"]:\n",
    "                             cv2.aruco.drawDetectedMarkers(im, [tag[\"corners\"].astype(int)], np.array([[tag[\"id\"]]]))\n",
    "                        \n",
    "                        cv2.putText(im, f\"FPS: {d['fps']:.1f}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                        return im\n",
    "\n",
    "                    l_im = draw(\"kreo1\")\n",
    "                    r_im = draw(\"kreo2\")\n",
    "                    \n",
    "                    # Stack\n",
    "                    h = min(l_im.shape[0], r_im.shape[0])\n",
    "                    if l_im.shape[0] != h: l_im = cv2.resize(l_im, (int(l_im.shape[1]*h/l_im.shape[0]), h))\n",
    "                    if r_im.shape[0] != h: r_im = cv2.resize(r_im, (int(r_im.shape[1]*h/r_im.shape[0]), h))\n",
    "                    \n",
    "                    cv2.imshow(\"Decoupled Tracking\", np.hstack([l_im, r_im]))\n",
    "                    last_show = time.time()\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    for t in threads: t.stop()\n",
    "    log_queue.put(None)\n",
    "    log_thread.join()\n",
    "    cv2.destroyAllWindows()\n",
    "    sub.close()\n",
    "    ctx.term()\n",
    "    print(\"\\nClean exit.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
