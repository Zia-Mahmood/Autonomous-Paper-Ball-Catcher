{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e313705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kreo1] AprilTagThread started\n",
      "[kreo1] BallThread started\n",
      "[kreo2] AprilTagThread started\n",
      "[kreo2] BallThread started\n",
      "[Subscriber] connected, waiting for frames... (Press ESC to exit)\n",
      "[DETECT-kreo1] AprilTag Detector thread stopped\n",
      "[kreo2] BallDetectorThread stopped\n",
      "[kreo1] BallDetectorThread stopped\n",
      "[DETECT-kreo2] AprilTag Detector thread stopped\n",
      "Exit clean.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# subscriber.py\n",
    "import cv2, zmq, numpy as np, time, threading, queue, traceback, sys\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ---------- Config ----------\n",
    "ZMQ_ADDR = \"tcp://localhost:5555\"\n",
    "SUB_TOPICS = [b\"kreo1\", b\"kreo2\"]\n",
    "FPS_WINDOW = 1.0        # seconds for fps moving window\n",
    "DISPLAY_FPS = 20\n",
    "VISUALIZE = True     # show tiled view window\n",
    "\n",
    "# ---------------- APRILTAG CONFIG ----------------\n",
    "DICT_TYPE = cv2.aruco.DICT_APRILTAG_36h11\n",
    "def create_april_detector():\n",
    "    \"\"\"Setup AprilTag detector with tuned parameters.\"\"\"\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(DICT_TYPE)\n",
    "    params = cv2.aruco.DetectorParameters()\n",
    "    params.adaptiveThreshWinSizeMin = 3\n",
    "    params.adaptiveThreshWinSizeMax = 35\n",
    "    params.adaptiveThreshWinSizeStep = 2\n",
    "    params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    params.cornerRefinementWinSize = 7\n",
    "    params.cornerRefinementMaxIterations = 100\n",
    "    params.cornerRefinementMinAccuracy = 0.01\n",
    "    params.minMarkerPerimeterRate = 0.02\n",
    "    params.maxMarkerPerimeterRate = 6.0\n",
    "    params.polygonalApproxAccuracyRate = 0.02\n",
    "    params.adaptiveThreshConstant = 7\n",
    "    return cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "\n",
    "# color thresholds (you gave these)\n",
    "orange_hsvVals = {'hmin': 0,  'smin': 94,  'vmin': 156, 'hmax': 12,  'smax': 255, 'vmax': 255}\n",
    "purple_hsvVals = {'hmin': 113,'smin': 78,  'vmin': 3,   'hmax': 129, 'smax': 255, 'vmax': 255}\n",
    "\n",
    "# detector parameters\n",
    "MIN_AREA = 150    # min contour area to accept (tune if needed)\n",
    "MAX_AREA = 20000  # max area (avoid very large blobs)\n",
    "CIRCULARITY_MIN = 0.25  # min circularity to accept (lower because paper balls can deform)\n",
    "ASPECT_RATIO_MAX = 2.0   # reject extremely elongated blobs\n",
    "MAX_DETECTIONS_PER_CAM = 12  # safety limit\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def fmt_ts(ts):\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(ts)) + f\".{int((ts%1)*1000):03d}\"\n",
    "\n",
    "def recv_latest(sub):\n",
    "    msg = None\n",
    "    while True:\n",
    "        try:\n",
    "            msg = sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        except zmq.Again:\n",
    "            break\n",
    "    return msg\n",
    "\n",
    "def update_fps(camera, cam_ts):\n",
    "    dq = fps_windows[camera]\n",
    "    dq.append(cam_ts)\n",
    "    # pop older than window\n",
    "    while dq and (cam_ts - dq[0]) > FPS_WINDOW:\n",
    "        dq.popleft()\n",
    "    fps = len(dq) / FPS_WINDOW\n",
    "    return fps\n",
    "\n",
    "# ---------- Color masking helpers ----------\n",
    "def hsv_mask_from_vals(bgr_img, hsvVals):\n",
    "    \"\"\"Return binary mask from HSV thresholds dict.\"\"\"\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([hsvVals['hmin'], hsvVals['smin'], hsvVals['vmin']], dtype=np.uint8)\n",
    "    upper = np.array([hsvVals['hmax'], hsvVals['smax'], hsvVals['vmax']], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    # small blur to reduce speckle\n",
    "    mask = cv2.medianBlur(mask, 5)\n",
    "    return mask\n",
    "\n",
    "def postprocess_mask(mask):\n",
    "    \"\"\"Morphological clean-up.\"\"\"\n",
    "    # open then close\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    m = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    return m\n",
    "\n",
    "def find_candidate_contours(mask):\n",
    "    \"\"\"Return list of contours filtered by area and shape heuristics.\"\"\"\n",
    "    if mask is None:\n",
    "        return []\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < MIN_AREA or area > MAX_AREA:\n",
    "            continue\n",
    "        perim = cv2.arcLength(c, True)\n",
    "        if perim <= 0:\n",
    "            continue\n",
    "        circularity = 4 * np.pi * area / (perim * perim)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect = float(w)/float(h) if h>0 else 0.0\n",
    "        # accept if roughly circular-ish or moderate area even if circularity low\n",
    "        if circularity >= CIRCULARITY_MIN or (0.5*min(w,h) > 5 and area > (MIN_AREA*2)):\n",
    "            if aspect <= ASPECT_RATIO_MAX:\n",
    "                candidates.append((c, area, (int(x),int(y),int(w),int(h))))\n",
    "    # sort by area desc\n",
    "    candidates.sort(key=lambda d: d[1], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# APRILTAG DETECTOR THREAD\n",
    "\n",
    "class AprilTagThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue, detect_cache, lock):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.detect_cache = detect_cache\n",
    "        self.lock = lock\n",
    "        self.detector = create_april_detector()\n",
    "        self.stop_flag = False\n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] AprilTagThread started\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                frame,ts = self.frame_queue.get(timeout=0.1)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                corners, ids, _ = self.detector.detectMarkers(gray)\n",
    "                det={\"corners\":corners,\"ids\":ids,\"ts\":ts,\"det_time\":time.time()}\n",
    "\n",
    "                with self.lock:\n",
    "                    if self.cam_name not in self.detect_cache:\n",
    "                        self.detect_cache[self.cam_name]={}\n",
    "                    self.detect_cache[self.cam_name][\"tags\"]=det\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR-{self.cam_name}] AprilTag Detection exception:\", e)\n",
    "                traceback.print_exc()\n",
    "\n",
    "        print(f\"[DETECT-{self.cam_name}] AprilTag Detector thread stopped\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "\n",
    "# BALL DETECTOR THREAD\n",
    "class BallThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue, detect_cache, lock):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.detect_cache = detect_cache\n",
    "        self.lock = lock\n",
    "        self.stop_flag = False\n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] BallThread started\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                frame,ts=self.frame_queue.get(timeout=0.1)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                mo=hsv_mask_from_vals(frame,orange_hsvVals)\n",
    "                mp=hsv_mask_from_vals(frame,purple_hsvVals)\n",
    "\n",
    "                mc = cv2.bitwise_or(mo,mp)\n",
    "                mc = postprocess_mask(mc)\n",
    "\n",
    "                cand = find_candidate_contours(mc)\n",
    "\n",
    "                dets = []\n",
    "                for c,area,(x,y,w,h) in cand[:MAX_DETECTIONS_PER_CAM]:\n",
    "                    M = cv2.moments(c)\n",
    "                    if M[\"m00\"] != 0:\n",
    "                        cx = int(M[\"m10\"]/M[\"m00\"]); cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "                    else:\n",
    "                        cx = x + w//2; cy = y + h//2\n",
    "                    \n",
    "                    s_or = int(np.count_nonzero(mo[y:y+h,x:x+w])) if mo is not None else 0\n",
    "                    s_pu = int(np.count_nonzero(mp[y:y+h,x:x+w])) if mp is not None else 0\n",
    "\n",
    "                    if s_or>s_pu and s_or>0:\n",
    "                        col=\"orange\"\n",
    "                    elif s_pu>s_or and s_pu>0:\n",
    "                        col=\"purple\"\n",
    "                    else:\n",
    "                        hsv_roi=cv2.cvtColor(frame[y:y+h,x:x+w],cv2.COLOR_BGR2HSV)\n",
    "                        mean_h=int(np.mean(hsv_roi[:,:,0]))\n",
    "                        if orange_hsvVals[\"hmin\"]<=mean_h<=orange_hsvVals[\"hmax\"]:\n",
    "                            col=\"orange\"\n",
    "                        elif purple_hsvVals[\"hmin\"]<=mean_h<=purple_hsvVals[\"hmax\"]:\n",
    "                            col=\"purple\"\n",
    "                        else:\n",
    "                            col=\"unknown\"\n",
    "\n",
    "                    dets.append({\n",
    "                        \"bbox\":(x,y,w,h),\n",
    "                        \"centroid\":(cx,cy),\n",
    "                        \"area\":float(area),\n",
    "                        \"color\":col,\n",
    "                        \"ts\":ts,\n",
    "                        \"det_time\":time.time()\n",
    "                    })\n",
    "                with self.lock:\n",
    "                    if self.cam_name not in self.detect_cache:\n",
    "                        self.detect_cache[self.cam_name]={}\n",
    "                    self.detect_cache[self.cam_name][\"balls\"] = dets\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR-{self.cam_name}] ball detection exception:\", e)\n",
    "                traceback.print_exc()\n",
    "\n",
    "        print(f\"[{self.cam_name}] BallDetectorThread stopped\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "\n",
    "# ---------- ZMQ subscriber ----------\n",
    "ctx = zmq.Context()\n",
    "sub = ctx.socket(zmq.SUB)\n",
    "sub.connect(ZMQ_ADDR)\n",
    "sub.setsockopt(zmq.RCVHWM, 1)\n",
    "sub.setsockopt(zmq.CONFLATE, 1)  # keep only last message\n",
    "sub.setsockopt(zmq.LINGER, 0)\n",
    "\n",
    "# ---- ACTIVE FLUSH ----\n",
    "flushed = 0\n",
    "while True:\n",
    "    try:\n",
    "        sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        flushed += 1\n",
    "    except zmq.Again:\n",
    "        break\n",
    "if flushed > 0:\n",
    "    print(f\"[Subscriber] Flushed {flushed} stale messages.\")\n",
    "for t in SUB_TOPICS:\n",
    "    sub.setsockopt(zmq.SUBSCRIBE, t)\n",
    "\n",
    "# per-camera structures\n",
    "frames = {}\n",
    "fps_windows = defaultdict(lambda: deque())\n",
    "frame_queues = {t.decode(): queue.Queue(maxsize=1) for t in SUB_TOPICS}\n",
    "detect_cache = {}        # cam -> detection dict\n",
    "detect_lock = threading.Lock()\n",
    "tag_threads={}\n",
    "ball_threads={}\n",
    "\n",
    "for t in SUB_TOPICS:\n",
    "    cam_name = t.decode()\n",
    "    tag_threads[cam_name] = AprilTagThread(cam_name,frame_queues[cam_name],detect_cache,detect_lock)\n",
    "    ball_threads[cam_name] = BallThread(cam_name,frame_queues[cam_name],detect_cache,detect_lock)\n",
    "\n",
    "    tag_threads[cam_name].start()\n",
    "    ball_threads[cam_name].start()\n",
    "\n",
    "print(\"[Subscriber] connected, waiting for frames... (Press ESC to exit)\")\n",
    "\n",
    "last_show = time.time()\n",
    "# ---------- Main loop ----------\n",
    "try:\n",
    "    while True:\n",
    "        parts=recv_latest(sub)\n",
    "        if parts is None: continue\n",
    "\n",
    "        topic=parts[0]; cam=topic.decode()\n",
    "        if len(parts)>=3:\n",
    "            ts_part=parts[1]; jpg_part=parts[2]\n",
    "        else:\n",
    "            ts_part=None; jpg_part=parts[1]\n",
    "\n",
    "        recv_t=time.time()\n",
    "        try: cam_ts=float(ts_part.decode()) if ts_part else recv_t\n",
    "        except: cam_ts=recv_t\n",
    "\n",
    "        img=cv2.imdecode(np.frombuffer(jpg_part,np.uint8),cv2.IMREAD_COLOR)\n",
    "        if img is None: continue\n",
    "\n",
    "        fps=update_fps(cam,cam_ts)\n",
    "        frames[cam]={\"img\":img,\"cam_ts\":cam_ts,\"fps\":fps}\n",
    "\n",
    "        # push frame to both detector queues\n",
    "        fq=frame_queues[cam]\n",
    "        try: fq.get_nowait()\n",
    "        except: pass\n",
    "        try: fq.put_nowait((img.copy(),cam_ts))\n",
    "        except: pass\n",
    "\n",
    "        # visual output if both cams available\n",
    "        if all(k in frames for k in [t.decode() for t in SUB_TOPICS]):\n",
    "            cams=[t.decode() for t in SUB_TOPICS]\n",
    "            L=frames[cams[0]]; R=frames[cams[1]]\n",
    "            drift_ms=abs(L[\"cam_ts\"]-R[\"cam_ts\"])*1000.0\n",
    "\n",
    "            def overlay(F,cam_name):\n",
    "                im=F[\"img\"].copy()\n",
    "                y=20\n",
    "                cv2.putText(im,f\"{cam_name}\",(10,y),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,32,20),2)\n",
    "                cv2.putText(im,f\"FPS:{F['fps']:.1f}\",(10,y+26),cv2.FONT_HERSHEY_SIMPLEX,0.6,(14,117,5),2)\n",
    "                cv2.putText(im,f\"cam_ts:{fmt_ts(F['cam_ts'])}\",(10,y+52),cv2.FONT_HERSHEY_SIMPLEX,0.5,(5,12,117),1)\n",
    "\n",
    "                with detect_lock:\n",
    "                    block=detect_cache.get(cam_name,{})\n",
    "\n",
    "                    # draw AprilTags\n",
    "                    if \"tags\" in block and block[\"tags\"][\"ids\"] is not None:\n",
    "                        cs=block[\"tags\"][\"corners\"]\n",
    "                        ids=block[\"tags\"][\"ids\"]\n",
    "                        cv2.aruco.drawDetectedMarkers(im,cs,ids)\n",
    "\n",
    "                    # draw balls\n",
    "                    if \"balls\" in block:\n",
    "                        for i,d in enumerate(block[\"balls\"]):\n",
    "                            x,y,w,h=d[\"bbox\"]\n",
    "                            cx,cy=d[\"centroid\"]\n",
    "                            color=d[\"color\"]\n",
    "                            if color==\"orange\": bc=(0,200,255)\n",
    "                            elif color==\"purple\": bc=(200,0,200)\n",
    "                            else: bc=(0,200,200)\n",
    "                            cv2.rectangle(im,(x,y),(x+w,y+h),bc,2)\n",
    "                            cv2.circle(im,(cx,cy),4,(0,0,255),-1)\n",
    "                            cv2.putText(im,f\"{color}:{i}\",(x,y-6),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX,0.5,bc,2)\n",
    "\n",
    "                return im\n",
    "\n",
    "            if VISUALIZE and (time.time()-last_show)>(1.0/DISPLAY_FPS):\n",
    "                last_show=time.time()\n",
    "                left_im=overlay(L,cams[0])\n",
    "                right_im=overlay(R,cams[1])\n",
    "\n",
    "                h=max(left_im.shape[0],right_im.shape[0])\n",
    "                right_res=cv2.resize(right_im,(left_im.shape[1],h))\n",
    "                tile=np.hstack([left_im,right_res])\n",
    "\n",
    "                cv2.putText(tile,f\"Drift:{drift_ms:.1f}ms\",(10,20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)\n",
    "                \n",
    "                cv2.putText(tile, f\"Host now: {fmt_ts(time.time())}\", (10, 44), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "                cv2.imshow(\"Combined Detection\",tile)\n",
    "            elif not VISUALIZE:\n",
    "                with detect_lock:\n",
    "                    tag_summary = []\n",
    "                    parts_status = []\n",
    "                    for c in cams:\n",
    "                        block = detect_cache.get(c,{})\n",
    "\n",
    "                        if \"tags\" in block and block[\"tags\"][\"ids\"] is not None:\n",
    "                            ids=block[\"tags\"][\"ids\"]\n",
    "                            tag_summary.append(f\"{c}: {ids.flatten().tolist()}\")\n",
    "                        elif \"tags\" in block:\n",
    "                            tag_summary.append(f\"{c}: No tags\")\n",
    "                        else:\n",
    "                            tag_summary.append(f\"{c}: No detection data\")\n",
    "                        if \"balls\" in block:\n",
    "                            counts = { \"orange\":0, \"purple\":0, \"unknown\":0 }\n",
    "                            for i,d in enumerate(block[\"balls\"]):\n",
    "                                counts[d.get(\"color\",\"unknown\")] = counts.get(d.get(\"color\",\"unknown\"),0) + 1\n",
    "                            parts_status.append(f\"{c}: Orange: {counts['orange']} Purple: {counts['purple']}\")\n",
    "                        else:\n",
    "                            parts_status.append(f\"{c}:NoBall\")    \n",
    "                status = (\n",
    "                    f\"Drift {drift_ms:.1f} ms | \"\n",
    "                    f\"{cams[0]} ts: {fmt_ts(L['cam_ts'])} | \"\n",
    "                    f\"{cams[1]} ts: {fmt_ts(R['cam_ts'])} | \"\n",
    "                    f\"Host now: {fmt_ts(time.time())} | \"\n",
    "                    f\"{cams[0]} FPS: {L['fps']:.1f} | \"\n",
    "                    f\"{cams[1]} FPS: {R['fps']:.1f} | \"\n",
    "                    f\"Tags:\" + \",\".join(tag_summary)\n",
    "                )\n",
    "                sys.stdout.write(\"\\r\" + status + \" \" * 20 + \" | \".join(parts_status) + \" \" * 20)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        if cv2.waitKey(1)&0xFF==27:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    for t in tag_threads.values(): t.stop()\n",
    "    for t in ball_threads.values(): t.stop()\n",
    "    time.sleep(0.1)\n",
    "    cv2.destroyAllWindows()\n",
    "    sub.close()\n",
    "    ctx.term()\n",
    "    print(\"Exit clean.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
