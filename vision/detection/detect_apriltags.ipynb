{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32054501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: {'cam0': 43, 'cam1': 43}\n",
      "FPS: {'cam0': 60, 'cam1': 60}\n",
      "FPS: {'cam0': 60, 'cam1': 60}\n",
      "FPS: {'cam0': 61, 'cam1': 61}\n",
      "FPS: {'cam0': 61, 'cam1': 61}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m i<\u001b[32m10\u001b[39m:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, cap \u001b[38;5;129;01min\u001b[39;00m caps.items():\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         ret, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m         \u001b[38;5;66;03m#cv2.imshow(\"testing\",frame)\u001b[39;00m\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2, time\n",
    "\n",
    "caps = {\n",
    "    \"cam0\": cv2.VideoCapture(0,cv2.CAP_V4L2),\n",
    "    \"cam1\": cv2.VideoCapture(4,cv2.CAP_V4L2)\n",
    "}\n",
    "\n",
    "for c in caps.values():\n",
    "    c.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "    c.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    c.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    c.set(cv2.CAP_PROP_FPS, 60)\n",
    "\n",
    "last = time.time()\n",
    "cnt = {\"cam0\":0, \"cam1\":0}\n",
    "i = 0\n",
    "while i<10:\n",
    "    for name, cap in caps.items():\n",
    "        ret, frame = cap.read()\n",
    "        #cv2.imshow(\"testing\",frame)\n",
    "        if ret:\n",
    "            cnt[name]+=1\n",
    "\n",
    "    now = time.time()\n",
    "    if now - last >= 1:\n",
    "        print(\"FPS:\", cnt)\n",
    "        cnt = {\"cam0\":0, \"cam1\":0}\n",
    "        i+=1\n",
    "        last = now\n",
    "for c in caps.values():\n",
    "    c.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e8cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time, json, os, threading, queue, numpy as np, sys\n",
    "import zmq, msgpack, msgpack_numpy as m\n",
    "m.patch()\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "DICT_TYPE = cv2.aruco.DICT_APRILTAG_36h11\n",
    "\n",
    "CAM_SOURCES = {\n",
    "    \"Mobile\":\"http://192.168.137.110:8080/video\",\n",
    "    \"Kreo1\": 0,\n",
    "    \"Kreo2\": 4\n",
    "}\n",
    "\n",
    "def get_camera_selection():\n",
    "    print(\"\\n=== Multi-Camera Live View Setup ===\")\n",
    "    print(\"Select cameras to open (comma separated):\")\n",
    "    print(\"1. Kreo Webcam #1\")\n",
    "    print(\"2. Kreo Webcam #2\")\n",
    "    print(\"3. Mobile IP Webcam\")\n",
    "    print(\"Example: 1,2 or 1,3 or 1,2,3\")\n",
    "    user_in = input(\"Cameras to open: \").strip()\n",
    "    choices = [x.strip() for x in user_in.split(\",\") if x.strip()]\n",
    "    selected = []\n",
    "    for c in choices:\n",
    "        if c == \"1\":\n",
    "            selected.append((\"kreo1\", CAM_SOURCES[\"Kreo1\"], 0.096))\n",
    "        elif c == \"2\":\n",
    "            selected.append((\"kreo2\", CAM_SOURCES[\"Kreo2\"], 0.096))\n",
    "        elif c == \"3\":\n",
    "            selected.append((\"mobile\", CAM_SOURCES[\"Mobile\"], 0.091))\n",
    "        else:\n",
    "            print(f\"[WARN] Ignoring invalid entry: {c}\")\n",
    "    if not selected:\n",
    "        print(\"[ERROR] No valid cameras selected. Exiting.\")\n",
    "        sys.exit(1)\n",
    "    return selected\n",
    "\n",
    "TAG4_MOBILE_ID = 4\n",
    "TAG4_HEIGHT_M = 0.075  # meters\n",
    "CAPTURE_TARGET_FPS = 60.0\n",
    "PROCESSING_TARGET_FPS = 40.0\n",
    "FRAME_QUEUE_MAX = 8\n",
    "PROCESS_QUEUE_MAX = 8\n",
    "DEBUG_PRINT_DETECTIONS = False\n",
    "APPLY_CAMERA_SETTINGS = True\n",
    "CALIB_DIR = '../calibration/'  # folder holding camera_calibration_{cam_name}.npz and best_camera_settings_{cam_name}.json\n",
    "SETTINGS_DIR = './camera_tune_results/'\n",
    "\n",
    "def load_camera_calib(cam_name):\n",
    "    path = os.path.join(CALIB_DIR, f'camera_calibration_{cam_name}.npz')\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    calib = np.load(path)\n",
    "    camera_matrix = calib[\"cameraMatrix\"]\n",
    "    dist_coeffs = calib['distCoeffs']\n",
    "    print(\"[INFO] Loaded calibrated camera parameters\")\n",
    "    return camera_matrix, dist_coeffs\n",
    "\n",
    "CAMPROP_MAP = {\n",
    "    'frame_width': cv2.CAP_PROP_FRAME_WIDTH,\n",
    "    'frame_height': cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "    'fps': cv2.CAP_PROP_FPS,\n",
    "    'exposure': cv2.CAP_PROP_EXPOSURE,\n",
    "    'gain': cv2.CAP_PROP_GAIN,\n",
    "    'focus': cv2.CAP_PROP_FOCUS,\n",
    "    'brightness': cv2.CAP_PROP_BRIGHTNESS,\n",
    "    'contrast': cv2.CAP_PROP_CONTRAST,\n",
    "    'saturation': cv2.CAP_PROP_SATURATION,\n",
    "}\n",
    "\n",
    "def apply_settings_to_capture(cap, settings):\n",
    "    for k, v in settings.items():\n",
    "        if k in CAMPROP_MAP:\n",
    "            try:\n",
    "                cap.set(CAMPROP_MAP[k], float(v))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "def create_detector():\n",
    "    \"\"\"Setup AprilTag detector with tuned parameters.\"\"\"\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(DICT_TYPE)\n",
    "    params = cv2.aruco.DetectorParameters()\n",
    "    params.adaptiveThreshWinSizeMin = 3\n",
    "    params.adaptiveThreshWinSizeMax = 35\n",
    "    params.adaptiveThreshWinSizeStep = 2\n",
    "    params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    params.cornerRefinementWinSize = 7\n",
    "    params.cornerRefinementMaxIterations = 50\n",
    "    params.cornerRefinementMinAccuracy = 0.01\n",
    "    params.minMarkerPerimeterRate = 0.02\n",
    "    params.maxMarkerPerimeterRate = 6.0\n",
    "    params.polygonalApproxAccuracyRate = 0.02\n",
    "    params.adaptiveThreshConstant = 7\n",
    "    return cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "\n",
    "def estimate_pose_apriltag(corners, tag_size, cam_mtx, cam_dist):\n",
    "    half = tag_size / 2.0\n",
    "    objp = np.array([\n",
    "        [-half,  half, 0.0],\n",
    "        [ half,  half, 0.0],\n",
    "        [ half, -half, 0.0],\n",
    "        [-half, -half, 0.0]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    imgp = corners.reshape(4,2).astype(np.float32)\n",
    "\n",
    "    ok, rvec, tvec = cv2.solvePnP(\n",
    "        objp, imgp, cam_mtx, cam_dist,\n",
    "        flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"solvePnP failed\")\n",
    "\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = tvec.reshape(3)\n",
    "\n",
    "    # debug\n",
    "    # reprojection\n",
    "    # imgpts, _ = cv2.projectPoints(objp, rvec, tvec, cam_mtx, cam_dist)\n",
    "    # imgpts = imgpts.reshape(-1,2)\n",
    "\n",
    "    # # compute reprojection error against detected corners 'img_corners' (4x2)\n",
    "    # reproj_err = np.linalg.norm(imgpts - corners, axis=1).mean()\n",
    "\n",
    "    # # compute camera-frame coords of each object corner\n",
    "    # # X_cam = R @ X_tag + t\n",
    "    # cam_pts = (R @ objp.T).T + tvec.reshape(1,3)\n",
    "\n",
    "    # print(\"=== REPROJ DEBUG ===\")\n",
    "    # print(\"rvec:\", rvec.ravel())\n",
    "    # print(\"tvec:\", tvec.ravel())\n",
    "    # print(\"R det:\", np.linalg.det(R))\n",
    "    # print(\"reproj_err px:\", reproj_err)\n",
    "    # print(\"camera-frame corners (x,y,z):\")\n",
    "    # for i,p in enumerate(cam_pts):\n",
    "    #     print(f\"  corner {i}: {p}\")\n",
    "    return T\n",
    "    \n",
    "\n",
    "class CameraWorker:\n",
    "    def __init__(self, name, device, tag_size):\n",
    "        self.name = name\n",
    "        self.device = device\n",
    "        self.tag_size = float(tag_size)\n",
    "        self.cap = None\n",
    "        self.running = threading.Event()\n",
    "        self.frame_queue = queue.Queue(maxsize=FRAME_QUEUE_MAX)\n",
    "        self.process_queue = queue.Queue(maxsize=PROCESS_QUEUE_MAX)\n",
    "        self.capture_thread = None\n",
    "        self.process_thread = None\n",
    "        self.detector = create_detector()\n",
    "        self.cam_mtx = None\n",
    "        self.cam_dist = None\n",
    "        self.settings = {}\n",
    "        self.stats = {'captured': 0, 'processed': 0, 'last_proc_time': 0.0}\n",
    "\n",
    "    def open_capture(self):\n",
    "        if isinstance(self.device, int):\n",
    "            cap = cv2.VideoCapture(self.device, cv2.CAP_V4L2)\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(int(self.device),cv2.CAP_V4L2)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            cap = cv2.VideoCapture(self.device)\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        cap.set(cv2.CAP_PROP_FPS, CAPTURE_TARGET_FPS)\n",
    "        return cap\n",
    "    \n",
    "    def load_calib_and_settings(self):\n",
    "        try:\n",
    "            self.cam_mtx, self.cam_dist = load_camera_calib(self.name)\n",
    "        except Exception as e:\n",
    "            print(f'[{self.name}] camera calibration load failed: {e}')\n",
    "            raise\n",
    "        sfile = os.path.join(SETTINGS_DIR, f'best_camera_settings_{self.name}.json')\n",
    "        if os.path.exists(sfile):\n",
    "            try:\n",
    "                with open(sfile, 'r') as f:\n",
    "                    self.settings = json.load(f)\n",
    "            except Exception:\n",
    "                self.settings = {}\n",
    "        else:\n",
    "            self.settings = {}\n",
    "\n",
    "    def start(self):\n",
    "        self.running.set()\n",
    "        self.load_calib_and_settings()\n",
    "        self.cap = self.open_capture()\n",
    "        if APPLY_CAMERA_SETTINGS and self.settings:\n",
    "            apply_settings_to_capture(self.cap, self.settings)\n",
    "        self.capture_thread = threading.Thread(target=self._capture_loop, name=f'cap-{self.name}', daemon=True)\n",
    "        self.process_thread = threading.Thread(target=self._process_loop, name=f'proc-{self.name}', daemon=True)\n",
    "        self.capture_thread.start()\n",
    "        self.process_thread.start()\n",
    "    \n",
    "    def stop(self):\n",
    "        self.running.clear()\n",
    "        if self.capture_thread:\n",
    "            self.capture_thread.join(timeout=1.0)\n",
    "        if self.process_thread:\n",
    "            self.process_thread.join(timeout=1.0)\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "\n",
    "    def _capture_loop(self):\n",
    "        target_dt = 1.0 / CAPTURE_TARGET_FPS\n",
    "        while self.running.is_set():\n",
    "            t0 = time.time()\n",
    "            ret, frame = self.cap.read()\n",
    "            t1 = time.time()\n",
    "            print(f\"[{self.name}] cap read time: {t1-t0:.3f}s\")\n",
    "            if not ret:\n",
    "                time.sleep(0.005)\n",
    "                continue\n",
    "            try:\n",
    "                self.frame_queue.put_nowait((time.time(), frame))\n",
    "                self.stats['captured'] += 1\n",
    "            except queue.Full:\n",
    "                try:\n",
    "                    self.frame_queue.get_nowait()\n",
    "                    self.frame_queue.put_nowait((time.time(), frame))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            dt = time.time() - t0\n",
    "            sl = max(0.0, target_dt - dt)\n",
    "            if sl > 0:\n",
    "                time.sleep(sl)\n",
    "\n",
    "    def _process_loop(self):\n",
    "        target_dt = 1.0 / PROCESSING_TARGET_FPS\n",
    "        while self.running.is_set():\n",
    "            try:\n",
    "                ts, frame = self.frame_queue.get(timeout=0.5)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            corners, ids, _ = self.detector.detectMarkers(gray)\n",
    "            results = []\n",
    "\n",
    "            if ids is not None:\n",
    "                for i, tid in enumerate(ids.flatten()):\n",
    "                    c = corners[i][0]  # 4x2\n",
    "\n",
    "                    if DEBUG_PRINT_DETECTIONS:\n",
    "                        print(f\"[{self.name}] tag {tid}, corners: {c}\")\n",
    "\n",
    "                    try:\n",
    "                        t_before = time.time()\n",
    "                        pose = estimate_pose_apriltag(c, self.tag_size, self.cam_mtx, self.cam_dist)\n",
    "                        t_after = time.time()\n",
    "                        print(\"tid: \",tid,\"pose time:\", t_after - t_before,\" Pose: \",pose[:,-1])\n",
    "                        results.append({'id': int(tid), 'pose_cam_tag': pose, 'timestamp': ts})\n",
    "                    except:\n",
    "                        continue\n",
    "            try:\n",
    "                self.process_queue.put_nowait((ts, frame, results))\n",
    "            except queue.Full:\n",
    "                _ = self.process_queue.get_nowait()\n",
    "                self.process_queue.put_nowait((ts, frame, results))\n",
    "\n",
    "            self.stats['processed'] += len(results)\n",
    "\n",
    "            time.sleep(max(0, target_dt - (time.time() - ts)))\n",
    "\n",
    "# central mapper\n",
    "class WorldMapper:\n",
    "    def __init__(self):\n",
    "        self.lock = threading.RLock()\n",
    "        self.tag_world_poses = {} # tag_id -> 4x4 pose in world (tag -> world)\n",
    "        self.camera_world_poses = {}  # cam_name -> 4x4 pose in world (camera -> world)\n",
    "        self.history = defaultdict(deque)\n",
    "\n",
    "    @staticmethod\n",
    "    def invert_pose(T):\n",
    "        R = T[:3, :3]\n",
    "        t = T[:3, 3]\n",
    "        Tinv = np.eye(4)\n",
    "        Tinv[:3, :3] = R.T\n",
    "        Tinv[:3, 3] = -R.T.dot(t)\n",
    "        return Tinv\n",
    "    \n",
    "    def reset(self):\n",
    "        with self.lock:\n",
    "            self.tag_world_poses.clear()\n",
    "            self.camera_world_poses.clear()\n",
    "            self.history.clear()\n",
    "\n",
    "    \n",
    "    def _recenter_on_tag1(self):\n",
    "        \"\"\"\n",
    "        If tag 1 exists, transform all stored poses so that tag1 becomes the world origin.\n",
    "        That is, compute S = inv(T_world_tag1) and replace every pose by S.dot(pose).\n",
    "        After this, T_world_tag1 will be identity.\n",
    "        \"\"\"\n",
    "        TAG1 = 1\n",
    "        if TAG1 not in self.tag_world_poses:\n",
    "            return\n",
    "\n",
    "        T_world_tag1 = self.tag_world_poses[TAG1]\n",
    "        S = self.invert_pose(T_world_tag1)  # S = inv(T_world_tag1)\n",
    "\n",
    "        # apply S to all tags and cameras\n",
    "        for tid in list(self.tag_world_poses.keys()):\n",
    "            self.tag_world_poses[tid] = S.dot(self.tag_world_poses[tid])\n",
    "\n",
    "        for cname in list(self.camera_world_poses.keys()):\n",
    "            self.camera_world_poses[cname] = S.dot(self.camera_world_poses[cname])\n",
    "\n",
    "    def add_observation(self, cam_name, cam_T_tag, tag_id, timestamp):\n",
    "        with self.lock:\n",
    "            cam_T_tag = np.array(cam_T_tag, dtype=float)\n",
    "            tag_T_cam = self.invert_pose(cam_T_tag)  # tag_T_cam maps camera -> tag\n",
    "\n",
    "            # Case A: we already know this tag's world pose -> compute camera world\n",
    "            if tag_id in self.tag_world_poses:\n",
    "                T_world_tag = self.tag_world_poses[tag_id]\n",
    "                # T_world_cam = T_world_tag . T_tag_cam\n",
    "                T_world_cam = T_world_tag.dot(tag_T_cam)\n",
    "                self.camera_world_poses[cam_name] = T_world_cam\n",
    "\n",
    "            # Case B: we know this camera's world pose -> compute tag world\n",
    "            elif cam_name in self.camera_world_poses:\n",
    "                T_world_cam = self.camera_world_poses[cam_name]\n",
    "                # T_world_tag = T_world_cam . T_cam_tag\n",
    "                T_world_tag = T_world_cam.dot(cam_T_tag)\n",
    "\n",
    "                # If this is TAG4 (mobile), force its height to TAG4_HEIGHT_M (z)\n",
    "                if tag_id == TAG4_MOBILE_ID:\n",
    "                    T_world_tag = np.array(T_world_tag, dtype=float)\n",
    "                    T_world_tag[2, 3] = TAG4_HEIGHT_M\n",
    "\n",
    "                self.tag_world_poses[tag_id] = T_world_tag\n",
    "\n",
    "            # Case C: neither tag nor camera is known yet\n",
    "            else:\n",
    "                # If this is tag 1, make it the world origin\n",
    "                if tag_id == 1:\n",
    "                    T_world_tag = np.eye(4)\n",
    "                    # camera world = T_world_tag . T_tag_cam = I . T_tag_cam = T_tag_cam\n",
    "                    T_world_cam = T_world_tag.dot(tag_T_cam)\n",
    "                    self.tag_world_poses[tag_id] = T_world_tag\n",
    "                    self.camera_world_poses[cam_name] = T_world_cam\n",
    "\n",
    "                # If this is TAG4 (mobile) and first observation, place tag relative to camera\n",
    "                # then set its z to TAG4_HEIGHT_M\n",
    "                elif tag_id == TAG4_MOBILE_ID:\n",
    "                    # choose camera as temporary world (i.e., set T_world_cam = I)\n",
    "                    # So tag_world = T_world_cam . T_cam_tag = I . T_cam_tag = cam_T_tag\n",
    "                    T_world_tag = cam_T_tag.copy()\n",
    "                    T_world_tag = np.array(T_world_tag, dtype=float)\n",
    "                    T_world_tag[2, 3] = TAG4_HEIGHT_M\n",
    "                    self.tag_world_poses[tag_id] = T_world_tag\n",
    "                    # camera world is then T_world_cam = T_world_tag . T_tag_cam\n",
    "                    T_world_cam = T_world_tag.dot(tag_T_cam)\n",
    "                    self.camera_world_poses[cam_name] = T_world_cam\n",
    "\n",
    "                else:\n",
    "                    # Default: choose camera as temporary world origin.\n",
    "                    # So T_world_cam = Identity, and T_world_tag = I . cam_T_tag = cam_T_tag\n",
    "                    T_world_cam = np.eye(4)\n",
    "                    T_world_tag = cam_T_tag.copy()\n",
    "                    # store both\n",
    "                    self.camera_world_poses[cam_name] = T_world_cam\n",
    "                    self.tag_world_poses[tag_id] = T_world_tag\n",
    "\n",
    "            # record history\n",
    "            self.history[tag_id].append((timestamp, cam_name))\n",
    "            # keep limited history\n",
    "            if len(self.history[tag_id]) > 200:\n",
    "                self.history[tag_id].popleft()\n",
    "\n",
    "            # IMPORTANT: if tag 1 appears at any time, recenter the whole map so tag1 is origin\n",
    "            if 1 in self.tag_world_poses:\n",
    "                # Recenter only if tag1 is not already identity\n",
    "                T_world_tag1 = self.tag_world_poses[1]\n",
    "                if not np.allclose(T_world_tag1, np.eye(4), atol=1e-6):\n",
    "                    self._recenter_on_tag1()\n",
    "\n",
    "    def get_map_snapshot(self):\n",
    "        with self.lock:\n",
    "            tags = {tid: T.copy() for tid, T in self.tag_world_poses.items()}\n",
    "            cams = {c: T.copy() for c, T in self.camera_world_poses.items()}\n",
    "        return {'tags': tags, 'cameras': cams}\n",
    "\n",
    "class SnapshotPublisher:\n",
    "    def __init__(self, port=5557):\n",
    "        ctx = zmq.Context()\n",
    "        self.sock = ctx.socket(zmq.PUB)\n",
    "        self.sock.bind(f\"tcp://*:{port}\")\n",
    "    \n",
    "    def send(self, snapshot):\n",
    "        # snapshot = {'tags': {tid: np.array(4x4)}, 'cameras': {name: np.array(4x4)}}\n",
    "        # convert to pure dict of lists\n",
    "        msg = {\n",
    "            \"tags\": {tid: snapshot['tags'][tid] for tid in snapshot['tags']},\n",
    "            \"cameras\": {c: snapshot['cameras'][c] for c in snapshot['cameras']}\n",
    "        }\n",
    "        if \"frames\" in snapshot:\n",
    "            msg[\"frames\"] = snapshot[\"frames\"] # dict of cam_name -> (jpg bytes)\n",
    "        packed = msgpack.packb(msg, default=m.encode)\n",
    "        self.sock.send(packed)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efda0419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Multi-Camera Live View Setup ===\n",
      "Select cameras to open (comma separated):\n",
      "1. Kreo Webcam #1\n",
      "2. Kreo Webcam #2\n",
      "3. Mobile IP Webcam\n",
      "Example: 1,2 or 1,3 or 1,2,3\n",
      "[INFO] Loaded calibrated camera parameters\n",
      "[kreo2] cap read time: 0.452s\n",
      "[kreo2] cap read time: 0.042s\n",
      "[kreo2] cap read time: 0.021s\n",
      "[kreo2] cap read time: 0.021s\n",
      "[kreo2] cap read time: 0.014s\n",
      "[kreo2] cap read time: 0.014s\n",
      "[kreo2] cap read time: 0.022s\n",
      "[kreo2] cap read time: 0.044s\n",
      "[kreo2] cap read time: 0.023s\n",
      "[kreo2] cap read time: 0.020s\n",
      "[kreo2] cap read time: 0.036s\n",
      "[kreo2] cap read time: 0.014s\n",
      "[kreo2] cap read time: 0.020s\n",
      "[kreo2] cap read time: 0.037s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.011s\n",
      "[kreo2] cap read time: 0.025s\n",
      "[kreo2] cap read time: 0.028s\n",
      "[kreo2] cap read time: 0.035s\n",
      "[kreo2] cap read time: 0.037s\n",
      "--- status ---\n",
      "kreo2: cap 14 proc 0\n",
      "tags known: []\n",
      "[kreo2] cap read time: 0.025s\n",
      "[kreo2] cap read time: 0.034s\n",
      "[kreo2] cap read time: 0.032s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.015s\n",
      "[kreo2] cap read time: 0.013s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.042s\n",
      "[kreo2] cap read time: 0.025s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.050s\n",
      "[kreo2] cap read time: 0.013s\n",
      "[kreo2] cap read time: 0.014s\n",
      "[kreo2] cap read time: 0.026s\n",
      "[kreo2] cap read time: 0.028s\n",
      "[kreo2] cap read time: 0.015s\n",
      "[kreo2] cap read time: 0.013s\n",
      "[kreo2] cap read time: 0.026s\n",
      "[kreo2] cap read time: 0.039s\n",
      "[kreo2] cap read time: 0.012s\n",
      "[kreo2] cap read time: 0.027s\n",
      "[kreo2] cap read time: 0.026s\n",
      "[kreo2] cap read time: 0.022s\n",
      "[kreo2] cap read time: 0.032s\n",
      "[kreo2] cap read time: 0.030s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.008s\n",
      "[kreo2] cap read time: 0.023s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.028s\n",
      "[kreo2] cap read time: 0.037s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.037s\n",
      "[kreo2] cap read time: 0.032s\n",
      "--- status ---\n",
      "kreo2: cap 41 proc 0\n",
      "tags known: []\n",
      "[kreo2] cap read time: 0.041s\n",
      "[kreo2] cap read time: 0.028s\n",
      "[kreo2] cap read time: 0.007s\n",
      "[kreo2] cap read time: 0.028s\n",
      "[kreo2] cap read time: 0.026s\n",
      "[kreo2] cap read time: 0.018s\n",
      "[kreo2] cap read time: 0.016s\n",
      "[kreo2] cap read time: 0.018s\n",
      "[kreo2] cap read time: 0.025s\n",
      "[kreo2] cap read time: 0.034s\n",
      "[kreo2] cap read time: 0.027s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.041s\n",
      "[kreo2] cap read time: 0.023s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.057s\n",
      "[kreo2] cap read time: 0.007s\n",
      "[kreo2] cap read time: 0.027s\n",
      "[kreo2] cap read time: 0.019s\n",
      "[kreo2] cap read time: 0.034s\n",
      "[kreo2] cap read time: 0.027s\n",
      "[kreo2] cap read time: 0.026s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.041s\n",
      "[kreo2] cap read time: 0.019s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.038s\n",
      "[kreo2] cap read time: 0.040s\n",
      "[kreo2] cap read time: 0.017s\n",
      "[kreo2] cap read time: 0.045s\n",
      "[kreo2] cap read time: 0.035s\n",
      "--- status ---\n",
      "kreo2: cap 70 proc 0\n",
      "tags known: []\n",
      "[kreo2] cap read time: 0.030s\n",
      "[kreo2] cap read time: 0.027s\n",
      "[kreo2] cap read time: 0.016s\n",
      "[kreo2] cap read time: 0.023s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.046s\n",
      "[kreo2] cap read time: 0.019s\n",
      "[kreo2] cap read time: 0.030s\n",
      "[kreo2] cap read time: 0.037s\n",
      "[kreo2] cap read time: 0.012s\n",
      "[kreo2] cap read time: 0.018s\n",
      "[kreo2] cap read time: 0.037s\n",
      "[kreo2] cap read time: 0.027s\n",
      "[kreo2] cap read time: 0.038s\n",
      "[kreo2] cap read time: 0.045s\n",
      "[kreo2] cap read time: 0.012s\n",
      "[kreo2] cap read time: 0.013s\n",
      "[kreo2] cap read time: 0.046s\n",
      "[kreo2] cap read time: 0.019s\n",
      "[kreo2] cap read time: 0.035s\n",
      "[kreo2] cap read time: 0.024s\n",
      "[kreo2] cap read time: 0.063s\n",
      "[kreo2] cap read time: 0.026s\n",
      "[kreo2] cap read time: 0.018s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.036s\n",
      "[kreo2] cap read time: 0.035s\n",
      "[kreo2] cap read time: 0.023s\n",
      "[kreo2] cap read time: 0.046s\n",
      "[kreo2] cap read time: 0.030s\n",
      "[kreo2] cap read time: 0.011s\n",
      "[kreo2] cap read time: 0.028s\n",
      "[kreo2] cap read time: 0.025s\n",
      "--- status ---\n",
      "kreo2: cap 98 proc 0\n",
      "tags known: []\n",
      "[kreo2] cap read time: 0.040s\n",
      "[kreo2] cap read time: 0.016s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.016s\n",
      "[kreo2] cap read time: 0.019s\n",
      "[kreo2] cap read time: 0.040s\n",
      "[kreo2] cap read time: 0.019s\n",
      "[kreo2] cap read time: 0.021s\n",
      "[kreo2] cap read time: 0.045s\n",
      "[kreo2] cap read time: 0.019s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.037s\n",
      "[kreo2] cap read time: 0.034s\n",
      "[kreo2] cap read time: 0.023s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.042s\n",
      "[kreo2] cap read time: 0.039s\n",
      "[kreo2] cap read time: 0.024s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.037s\n",
      "[kreo2] cap read time: 0.012s\n",
      "[kreo2] cap read time: 0.024s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.030s\n",
      "[kreo2] cap read time: 0.018s\n",
      "[kreo2] cap read time: 0.032s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.026s\n",
      "[kreo2] cap read time: 0.034s\n",
      "[kreo2] cap read time: 0.034s\n",
      "[kreo2] cap read time: 0.034s\n",
      "--- status ---\n",
      "kreo2: cap 127 proc 0\n",
      "tags known: []\n",
      "[kreo2] cap read time: 0.034s\n",
      "[kreo2] cap read time: 0.020s\n",
      "[kreo2] cap read time: 0.027s\n",
      "[kreo2] cap read time: 0.042s\n",
      "[kreo2] cap read time: 0.014s\n",
      "[kreo2] cap read time: 0.013s\n",
      "[kreo2] cap read time: 0.027s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.051s\n",
      "[kreo2] cap read time: 0.017s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.016s\n",
      "[kreo2] cap read time: 0.022s\n",
      "[kreo2] cap read time: 0.016s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.034s\n",
      "[kreo2] cap read time: 0.027s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.037s\n",
      "[kreo2] cap read time: 0.031s\n",
      "[kreo2] cap read time: 0.032s\n",
      "[kreo2] cap read time: 0.029s\n",
      "[kreo2] cap read time: 0.034s\n",
      "[kreo2] cap read time: 0.033s\n",
      "[kreo2] cap read time: 0.028s\n",
      "[kreo2] cap read time: 0.045s\n",
      "[kreo2] cap read time: 0.016s\n",
      "[kreo2] cap read time: 0.049s\n",
      "[kreo2] cap read time: 0.009s\n",
      "exiting main\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    workers = []\n",
    "    for name, dev, tag_size in get_camera_selection():\n",
    "        w = CameraWorker(name, dev, tag_size)\n",
    "        try:\n",
    "            w.start()\n",
    "        except Exception as e:\n",
    "            print(f'Failed to start camera {name}: {e}')\n",
    "            continue\n",
    "        workers.append(w)\n",
    "    \n",
    "    mapper = WorldMapper()\n",
    "    mapper.reset()\n",
    "    pub = SnapshotPublisher(port=5557)\n",
    "    map_thread_stop = threading.Event()\n",
    "\n",
    "    def mapper_loop():\n",
    "        while not map_thread_stop.is_set():\n",
    "            for w in workers:\n",
    "                try:\n",
    "                    ts, frame, dets = w.process_queue.get_nowait()\n",
    "                    ok, jpg = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
    "                    if ok:\n",
    "                        frame_jpg = jpg.tobytes()\n",
    "                    else:\n",
    "                        frame_jpg = None\n",
    "                except queue.Empty:\n",
    "                    continue\n",
    "\n",
    "                for d in dets:\n",
    "                    mapper.add_observation(w.name, d['pose_cam_tag'], d['id'], d['timestamp'])\n",
    "                    snapshot = mapper.get_map_snapshot()\n",
    "                    snapshot['frames'] = {w.name: frame_jpg} if frame_jpg is not None else {}\n",
    "                    pub.send(snapshot)\n",
    "            time.sleep(0.002)\n",
    "    \n",
    "    mt = threading.Thread(target=mapper_loop, name='mapper', daemon=True)\n",
    "    mt.start()\n",
    "\n",
    "    try:\n",
    "        last_print = time.time()\n",
    "        while True:\n",
    "            now = time.time()\n",
    "            if now - last_print > 1.0:\n",
    "                last_print = now\n",
    "                snap = mapper.get_map_snapshot()\n",
    "                print('--- status ---')\n",
    "                for w in workers:\n",
    "                    print(f'{w.name}: cap {w.stats[\"captured\"]} proc {w.stats[\"processed\"]}')\n",
    "                print('tags known:', list(snap['tags'].keys()))\n",
    "            # time.sleep(0.01)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        map_thread_stop.set()\n",
    "        for w in workers:\n",
    "            w.stop()\n",
    "        print('exiting main')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3e7f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kreo1] Detector thread started.\n",
      "[kreo2] Detector thread started.\n",
      "[Subscriber] connected, waiting for frames... (Press ESC to exit)\n"
     ]
    }
   ],
   "source": [
    "# subscriber.py\n",
    "import cv2, zmq, numpy as np, time, threading, queue, traceback, sys\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ---------- Config ----------\n",
    "ZMQ_ADDR = \"tcp://localhost:5555\"\n",
    "SUB_TOPICS = [b\"kreo1\", b\"kreo2\"]\n",
    "FPS_WINDOW = 1.0        # seconds for fps moving window\n",
    "DISPLAY_FPS = 20\n",
    "VISUALIZE = True     # show tiled view window\n",
    "\n",
    "DICT_TYPE = cv2.aruco.DICT_APRILTAG_36h11\n",
    "def create_detector():\n",
    "    \"\"\"Setup AprilTag detector with tuned parameters.\"\"\"\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(DICT_TYPE)\n",
    "    params = cv2.aruco.DetectorParameters()\n",
    "    params.adaptiveThreshWinSizeMin = 3\n",
    "    params.adaptiveThreshWinSizeMax = 35\n",
    "    params.adaptiveThreshWinSizeStep = 2\n",
    "    params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    params.cornerRefinementWinSize = 7\n",
    "    params.cornerRefinementMaxIterations = 50\n",
    "    params.cornerRefinementMinAccuracy = 0.01\n",
    "    params.minMarkerPerimeterRate = 0.02\n",
    "    params.maxMarkerPerimeterRate = 6.0\n",
    "    params.polygonalApproxAccuracyRate = 0.02\n",
    "    params.adaptiveThreshConstant = 7\n",
    "    return cv2.aruco.ArucoDetector(aruco_dict, params)\n",
    "\n",
    "class DetectorThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue, detect_cache, lock):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.detect_cache = detect_cache\n",
    "        self.lock = lock\n",
    "        self.detector = create_detector()\n",
    "        self.stop_flag = False\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] Detector thread started.\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                frame,ts = self.frame_queue.get(timeout=0.1)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                corners, ids, _ = self.detector.detectMarkers(gray)\n",
    "                with self.lock:\n",
    "                    self.detect_cache[self.cam_name] = {\n",
    "                        \"corners\": corners,\n",
    "                        \"ids\": ids,\n",
    "                        \"ts\": ts,\n",
    "                        \"det_time\": time.time(),\n",
    "                    }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR-{self.cam_name}] Detection exception:\", e)\n",
    "                traceback.print_exc()\n",
    "\n",
    "        print(f\"[DETECT-{self.cam_name}] Detector thread stopped\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def fmt_ts(ts):\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(ts)) + f\".{int((ts%1)*1000):03d}\"\n",
    "\n",
    "def recv_latest(sub):\n",
    "    msg = None\n",
    "    while True:\n",
    "        try:\n",
    "            msg = sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        except zmq.Again:\n",
    "            break\n",
    "    return msg\n",
    "\n",
    "def update_fps(camera, cam_ts):\n",
    "    dq = fps_windows[camera]\n",
    "    dq.append(cam_ts)\n",
    "    # pop older than window\n",
    "    while dq and (cam_ts - dq[0]) > FPS_WINDOW:\n",
    "        dq.popleft()\n",
    "    fps = len(dq) / FPS_WINDOW\n",
    "    return fps\n",
    "\n",
    "\n",
    "# ---------- ZMQ subscriber ----------\n",
    "ctx = zmq.Context()\n",
    "sub = ctx.socket(zmq.SUB)\n",
    "sub.connect(ZMQ_ADDR)\n",
    "sub.setsockopt(zmq.RCVHWM, 1)\n",
    "sub.setsockopt(zmq.CONFLATE, 1)  # keep only last message\n",
    "sub.setsockopt(zmq.LINGER, 0)\n",
    "\n",
    "# ---- ACTIVE FLUSH ----\n",
    "flushed = 0\n",
    "while True:\n",
    "    try:\n",
    "        sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        flushed += 1\n",
    "    except zmq.Again:\n",
    "        break\n",
    "if flushed > 0:\n",
    "    print(f\"[Subscriber] Flushed {flushed} stale messages.\")\n",
    "for t in SUB_TOPICS:\n",
    "    sub.setsockopt(zmq.SUBSCRIBE, t)\n",
    "\n",
    "# per-camera state\n",
    "frames = {}\n",
    "fps_windows = defaultdict(lambda: deque())   # deque of capture times\n",
    "frame_queues = {t.decode(): queue.Queue(maxsize=1) for t in SUB_TOPICS}\n",
    "detect_cache = {}\n",
    "detect_lock = threading.Lock()\n",
    "det_threads = {}\n",
    "\n",
    "for t in SUB_TOPICS:\n",
    "    cam_name = t.decode()\n",
    "    dt = DetectorThread(cam_name, frame_queues[cam_name], detect_cache, detect_lock)\n",
    "    dt.start()\n",
    "    det_threads[cam_name] = dt\n",
    "\n",
    "\n",
    "print(\"[Subscriber] connected, waiting for frames... (Press ESC to exit)\")\n",
    "\n",
    "last_show = time.time()\n",
    "# ---------- Main loop ----------\n",
    "try:\n",
    "    while True:\n",
    "        parts = recv_latest(sub)\n",
    "        if parts is None:\n",
    "            continue\n",
    "\n",
    "        # unpack message\n",
    "        topic = parts[0]\n",
    "        cam = topic.decode()\n",
    "\n",
    "        if len(parts) >= 3:\n",
    "            ts_part = parts[1]\n",
    "            jpg_part = parts[2]\n",
    "        else:\n",
    "            ts_part = None\n",
    "            jpg_part = parts[1]\n",
    "\n",
    "        recv_time = time.time()\n",
    "\n",
    "        try:\n",
    "            cam_ts = float(ts_part.decode()) if ts_part else recv_time\n",
    "        except:\n",
    "            cam_ts = recv_time\n",
    "\n",
    "        img = cv2.imdecode(np.frombuffer(jpg_part, np.uint8), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        fps = update_fps(cam, cam_ts)\n",
    "\n",
    "        frames[cam] = {\n",
    "            \"img\": img,\n",
    "            \"cam_ts\": cam_ts,\n",
    "            \"fps\": fps,\n",
    "        }\n",
    "\n",
    "        fq = frame_queues[cam]\n",
    "        try:\n",
    "            fq.get_nowait()  # clear old\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        try:\n",
    "            fq.put_nowait((img.copy(), cam_ts))\n",
    "        except queue.Full:\n",
    "            pass\n",
    "\n",
    "        # If we have at least 2 cameras, compute drift and show tiled view\n",
    "        if all(k in frames for k in [t.decode() for t in SUB_TOPICS]):\n",
    "            cams = [t.decode() for t in SUB_TOPICS]\n",
    "            left = frames[cams[0]]\n",
    "            right = frames[cams[1]]\n",
    "\n",
    "            # compute drift in ms between corrected timestamps\n",
    "            drift_s = abs(left[\"cam_ts\"] - right[\"cam_ts\"])\n",
    "            drift_ms = drift_s * 1000.0\n",
    "\n",
    "            # overlay text on each image\n",
    "            def overlay(frame_info, cam_name):\n",
    "                im = frame_info[\"img\"].copy()\n",
    "                y = 20\n",
    "                cv2.putText(im, f\"{cam_name}\", (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (199,32,20), 2)\n",
    "                cv2.putText(im, f\"FPS: {frame_info['fps']:.1f}\", (10, y+26), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (14,117,5), 2)\n",
    "                cv2.putText(im, f\"cam_ts: {fmt_ts(frame_info['cam_ts'])}\", (10, y+52), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (5,12,117), 1)\n",
    "\n",
    "                # Draw cached tags\n",
    "                with detect_lock:\n",
    "                    if cam_name in detect_cache:\n",
    "                        ct = detect_cache[cam_name]\n",
    "                        corners, ids = ct[\"corners\"], ct[\"ids\"]\n",
    "                        if ids is not None and len(ids) > 0:\n",
    "                            cv2.aruco.drawDetectedMarkers(im, corners, ids)\n",
    "\n",
    "                return im\n",
    "\n",
    "            if VISUALIZE and time.time()-last_show > 1.0/DISPLAY_FPS:\n",
    "                left_im = overlay(left, cams[0])\n",
    "                right_im = overlay(right, cams[1])\n",
    "\n",
    "                # resize to same height and tile horizontally\n",
    "                h = max(left_im.shape[0], right_im.shape[0])\n",
    "                right_resized = cv2.resize(right_im, (left_im.shape[1], h))\n",
    "                tile = np.hstack([left_im, right_resized])\n",
    "\n",
    "                # Draw drift and timestamp summary on top-left of tiled image\n",
    "                cv2.putText(tile, f\"Drift: {drift_ms:.1f} ms\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
    "                cv2.putText(tile, f\"Host now: {fmt_ts(time.time())}\", (10, 44), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "                last_show = time.time()\n",
    "                cv2.imshow(\"Both Cameras (tiled)\", tile)\n",
    "            elif not VISUALIZE:\n",
    "                with detect_lock:\n",
    "                    tag_summary = []\n",
    "                    for c in cams:\n",
    "                        if c in detect_cache:\n",
    "                            ids = detect_cache[c][\"ids\"]\n",
    "                            if ids is not None and len(ids) > 0:\n",
    "                                tag_summary.append(f\"{c}: {ids.flatten().tolist()}\")\n",
    "                            else:\n",
    "                                tag_summary.append(f\"{c}: No tags\")\n",
    "                        else:\n",
    "                            tag_summary.append(f\"{c}: No detection data\")\n",
    "                status = (\n",
    "                    f\"Drift {drift_ms:.1f} ms | \"\n",
    "                    f\"{cams[0]} ts: {fmt_ts(left['cam_ts'])} | \"\n",
    "                    f\"{cams[1]} ts: {fmt_ts(right['cam_ts'])} | \"\n",
    "                    f\"Host now: {fmt_ts(time.time())} | \"\n",
    "                    f\"{cams[0]} FPS: {left['fps']:.1f} | \"\n",
    "                    f\"{cams[1]} FPS: {right['fps']:.1f} | \"\n",
    "                    f\"Tags:\" + \",\".join(tag_summary)\n",
    "                )\n",
    "                sys.stdout.write(\"\\r\" + status + \" \" * 20)\n",
    "                sys.stdout.flush()\n",
    "            \n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    sub.close()\n",
    "    ctx.term()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
