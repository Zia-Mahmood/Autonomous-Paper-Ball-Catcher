{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f748ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m ret, img = cap.read()\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# img = cv2.imread('ball.png')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m imgColor, mask = \u001b[43mmyColorFinder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhsvVals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m imgContours, contours = cvzone.findContours(img,mask,minArea=\u001b[32m50\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m contours:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Autonomous-Paper-Ball-Catcher/.venv/lib/python3.11/site-packages/cvzone/ColorModule.py:75\u001b[39m, in \u001b[36mColorFinder.update\u001b[39m\u001b[34m(self, img, myColor)\u001b[39m\n\u001b[32m     72\u001b[39m     myColor = \u001b[38;5;28mself\u001b[39m.getColorHSV(myColor)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m myColor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     imgHSV = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOLOR_BGR2HSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     lower = np.array([myColor[\u001b[33m'\u001b[39m\u001b[33mhmin\u001b[39m\u001b[33m'\u001b[39m], myColor[\u001b[33m'\u001b[39m\u001b[33msmin\u001b[39m\u001b[33m'\u001b[39m], myColor[\u001b[33m'\u001b[39m\u001b[33mvmin\u001b[39m\u001b[33m'\u001b[39m]])\n\u001b[32m     77\u001b[39m     upper = np.array([myColor[\u001b[33m'\u001b[39m\u001b[33mhmax\u001b[39m\u001b[33m'\u001b[39m], myColor[\u001b[33m'\u001b[39m\u001b[33msmax\u001b[39m\u001b[33m'\u001b[39m], myColor[\u001b[33m'\u001b[39m\u001b[33mvmax\u001b[39m\u001b[33m'\u001b[39m]])\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2,cvzone\n",
    "from cvzone.ColorModule import ColorFinder\n",
    "\n",
    "cap = cv2.VideoCapture('./test.webm')\n",
    "myColorFinder = ColorFinder(trackBar=False)\n",
    "hsvVals = {'hmin': 0, 'smin': 140, 'vmin': 148, 'hmax': 7, 'smax': 255, 'vmax': 255}\n",
    "\n",
    "posList = []\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    # img = cv2.imread('ball.png')\n",
    "\n",
    "    imgColor, mask = myColorFinder.update(img, hsvVals)\n",
    "    imgContours, contours = cvzone.findContours(img,mask,minArea=50)\n",
    "\n",
    "    if contours:\n",
    "        posList.append(contours[0]['center'])\n",
    "    \n",
    "    for i,pos in enumerate(posList):\n",
    "        cv2.circle(imgContours,pos,5,(0,255,0),cv2.FILLED)\n",
    "        if i==0:\n",
    "            continue\n",
    "        cv2.line(imgContours,pos,posList[i-1],(255,0,0),2)\n",
    "\n",
    "    cv2.imshow(\"Color Filtered Image\", imgContours)\n",
    "\n",
    "    # CRITICAL: Use waitKey(1) to allow the GUI to update\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f87664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kreo1] Detector thread started.\n",
      "[kreo2] Detector thread started.\n",
      "[Subscriber] connected, waiting for frames... (Press ESC to exit)\n",
      "[kreo2] BallDetectorThread stopped\n",
      "[kreo1] BallDetectorThread stopped\n",
      "Exit clean.\n"
     ]
    }
   ],
   "source": [
    "import cv2, zmq, numpy as np, time, threading, queue, traceback, sys\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ---------- Config ----------\n",
    "ZMQ_ADDR = \"tcp://localhost:5555\"\n",
    "SUB_TOPICS = [b\"kreo1\", b\"kreo2\"]\n",
    "FPS_WINDOW = 1.0        # seconds for fps moving window\n",
    "DISPLAY_FPS = 20\n",
    "VISUALIZE = True     # show tiled view window\n",
    "\n",
    "# color thresholds (you gave these)\n",
    "orange_hsvVals = {'hmin': 0, 'smin': 100, 'vmin': 100, 'hmax': 25, 'smax': 255, 'vmax': 255}\n",
    "purple_hsvVals = {'hmin': 149, 'smin': 69, 'vmin': 82, 'hmax': 177, 'smax': 229, 'vmax': 252}\n",
    "\n",
    "# detector parameters\n",
    "MIN_AREA = 100    # min contour area to accept (tune if needed)\n",
    "MAX_AREA = 20000  # max area (avoid very large blobs)\n",
    "CIRCULARITY_MIN = 0.25  # min circularity to accept (lower because paper balls can deform)\n",
    "ASPECT_RATIO_MAX = 2.0   # reject extremely elongated blobs\n",
    "MAX_DETECTIONS_PER_CAM = 12  # safety limi\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def fmt_ts(ts):\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(ts)) + f\".{int((ts%1)*1000):03d}\"\n",
    "\n",
    "def recv_latest(sub):\n",
    "    msg = None\n",
    "    while True:\n",
    "        try:\n",
    "            msg = sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        except zmq.Again:\n",
    "            break\n",
    "    return msg\n",
    "\n",
    "def update_fps(camera, cam_ts):\n",
    "    dq = fps_windows[camera]\n",
    "    dq.append(cam_ts)\n",
    "    # pop older than window\n",
    "    while dq and (cam_ts - dq[0]) > FPS_WINDOW:\n",
    "        dq.popleft()\n",
    "    fps = len(dq) / FPS_WINDOW\n",
    "    return fps\n",
    "\n",
    "# ---------- Color masking helpers ----------\n",
    "def hsv_mask_from_vals(bgr_img, hsvVals):\n",
    "    \"\"\"Return binary mask from HSV thresholds dict.\"\"\"\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([hsvVals['hmin'], hsvVals['smin'], hsvVals['vmin']], dtype=np.uint8)\n",
    "    upper = np.array([hsvVals['hmax'], hsvVals['smax'], hsvVals['vmax']], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    # small blur to reduce speckle\n",
    "    mask = cv2.medianBlur(mask, 5)\n",
    "    return mask\n",
    "\n",
    "def postprocess_mask(mask):\n",
    "    \"\"\"Morphological clean-up.\"\"\"\n",
    "    # open then close\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    m = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    return m\n",
    "\n",
    "def find_candidate_contours(mask, min_area=MIN_AREA, max_area=MAX_AREA):\n",
    "    \"\"\"Return list of contours filtered by area and shape heuristics.\"\"\"\n",
    "    if mask is None:\n",
    "        return []\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < min_area or area > max_area:\n",
    "            continue\n",
    "        perim = cv2.arcLength(c, True)\n",
    "        if perim <= 0:\n",
    "            continue\n",
    "        circularity = 4 * np.pi * area / (perim * perim)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect = float(w)/float(h) if h>0 else 0.0\n",
    "        # accept if roughly circular-ish or moderate area even if circularity low\n",
    "        if circularity >= CIRCULARITY_MIN or (0.5*min(w,h) > 5 and area > (min_area*2)):\n",
    "            if aspect <= ASPECT_RATIO_MAX:\n",
    "                candidates.append({\n",
    "                    \"contour\": c,\n",
    "                    \"area\": area,\n",
    "                    \"perimeter\": perim,\n",
    "                    \"circularity\": circularity,\n",
    "                    \"bbox\": (int(x),int(y),int(w),int(h))\n",
    "                })\n",
    "    # sort by area desc\n",
    "    candidates.sort(key=lambda d: d[\"area\"], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# ---------- Detector thread (per-camera) ----------\n",
    "class BallDetectorThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue, detect_cache, lock):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.detect_cache = detect_cache\n",
    "        self.lock = lock\n",
    "        self.stop_flag = False\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] Detector thread started.\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                frame,cam_ts = self.frame_queue.get(timeout=0.1)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                # build masks for both colors\n",
    "                mask_orange = hsv_mask_from_vals(frame, orange_hsvVals)\n",
    "                mask_purple = hsv_mask_from_vals(frame, purple_hsvVals)\n",
    "\n",
    "                # combine & clean\n",
    "                combined_mask = cv2.bitwise_or(mask_orange, mask_purple)\n",
    "                combined_mask = postprocess_mask(combined_mask)\n",
    "\n",
    "                # find contours\n",
    "                candidates = find_candidate_contours(combined_mask)\n",
    "\n",
    "                detections = []\n",
    "                for cand in candidates[:MAX_DETECTIONS_PER_CAM]:\n",
    "                    c = cand[\"contour\"]\n",
    "                    x,y,w,h = cand[\"bbox\"]\n",
    "                    area = cand[\"area\"]\n",
    "                    circ = cand[\"circularity\"]\n",
    "\n",
    "                    # centroid\n",
    "                    M = cv2.moments(c)\n",
    "                    if M[\"m00\"] != 0:\n",
    "                        cx = int(M[\"m10\"]/M[\"m00\"]); cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "                    else:\n",
    "                        cx = x + w//2; cy = y + h//2\n",
    "\n",
    "                    # classify color by sampling the masks inside bbox\n",
    "                    s_orange = int(np.count_nonzero(mask_orange[y:y+h, x:x+w])) if mask_orange is not None else 0\n",
    "                    s_purple = int(np.count_nonzero(mask_purple[y:y+h, x:x+w])) if mask_purple is not None else 0\n",
    "\n",
    "                    # small area leads to ambiguity; prefer stronger mask\n",
    "                    color = \"unknown\"\n",
    "                    if s_orange > s_purple and s_orange > 0:\n",
    "                        color = \"orange\"\n",
    "                    elif s_purple > s_orange and s_purple > 0:\n",
    "                        color = \"purple\"\n",
    "                    else:\n",
    "                        # fallback: mean hue in bbox\n",
    "                        try:\n",
    "                            hsv_roi = cv2.cvtColor(frame[y:y+h, x:x+w], cv2.COLOR_BGR2HSV)\n",
    "                            mean_h = int(np.mean(hsv_roi[:,:,0]))\n",
    "                            if orange_hsvVals['hmin'] <= mean_h <= orange_hsvVals['hmax']:\n",
    "                                color = \"orange\"\n",
    "                            elif purple_hsvVals['hmin'] <= mean_h <= purple_hsvVals['hmax']:\n",
    "                                color = \"purple\"\n",
    "                        except Exception:\n",
    "                            color = \"unknown\"\n",
    "\n",
    "                    det = {\n",
    "                        \"bbox\": (int(x),int(y),int(w),int(h)),\n",
    "                        \"centroid\": (int(cx),int(cy)),\n",
    "                        \"area\": float(area),\n",
    "                        \"circularity\": float(circ),\n",
    "                        \"color\": color,\n",
    "                        \"ts\": float(cam_ts),\n",
    "                        \"det_time\": time.time()\n",
    "                    }\n",
    "                    detections.append(det)\n",
    "\n",
    "                with self.lock:\n",
    "                    self.detect_cache[self.cam_name] = detections\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR-{self.cam_name}] detection exception:\", e)\n",
    "                traceback.print_exc()\n",
    "\n",
    "        print(f\"[{self.cam_name}] BallDetectorThread stopped\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "# ---------- ZMQ subscriber ----------\n",
    "ctx = zmq.Context()\n",
    "sub = ctx.socket(zmq.SUB)\n",
    "sub.connect(ZMQ_ADDR)\n",
    "sub.setsockopt(zmq.RCVHWM, 1)\n",
    "sub.setsockopt(zmq.CONFLATE, 1)  # keep only last message\n",
    "sub.setsockopt(zmq.LINGER, 0)\n",
    "\n",
    "# ---- ACTIVE FLUSH ----\n",
    "flushed = 0\n",
    "while True:\n",
    "    try:\n",
    "        sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        flushed += 1\n",
    "    except zmq.Again:\n",
    "        break\n",
    "if flushed > 0:\n",
    "    print(f\"[Subscriber] Flushed {flushed} stale messages.\")\n",
    "for t in SUB_TOPICS:\n",
    "    sub.setsockopt(zmq.SUBSCRIBE, t)\n",
    "\n",
    "\n",
    "# per-camera structures\n",
    "frames = {}\n",
    "fps_windows = defaultdict(lambda: deque())\n",
    "frame_queues = {t.decode(): queue.Queue(maxsize=1) for t in SUB_TOPICS}\n",
    "detect_cache = {}        # cam -> detection dict\n",
    "detect_lock = threading.Lock()\n",
    "det_threads = {}\n",
    "\n",
    "for t in SUB_TOPICS:\n",
    "    cam_name = t.decode()\n",
    "    dt = BallDetectorThread(cam_name, frame_queues[cam_name], detect_cache, detect_lock)\n",
    "    dt.start()\n",
    "    det_threads[cam_name] = dt\n",
    "\n",
    "\n",
    "print(\"[Subscriber] connected, waiting for frames... (Press ESC to exit)\")\n",
    "\n",
    "last_show = time.time()\n",
    "try:\n",
    "    while True:\n",
    "        parts = recv_latest(sub)\n",
    "        if parts is None:\n",
    "            continue\n",
    "\n",
    "        # unpack message\n",
    "        topic = parts[0]; cam = topic.decode()\n",
    "        if len(parts) >= 3:\n",
    "            ts_part = parts[1]; jpg_part = parts[2]\n",
    "        else:\n",
    "            ts_part = None; jpg_part = parts[1]\n",
    "\n",
    "        recv_time = time.time()\n",
    "        try:\n",
    "            cam_ts = float(ts_part.decode()) if ts_part else recv_time\n",
    "        except:\n",
    "            cam_ts = recv_time\n",
    "\n",
    "        img = cv2.imdecode(np.frombuffer(jpg_part, np.uint8), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        fps = update_fps(cam, cam_ts)\n",
    "        frames[cam] = {\"img\": img, \"cam_ts\": cam_ts, \"fps\": fps}\n",
    "\n",
    "        # push latest frame to detector queue (maxsize=1)\n",
    "        fq = frame_queues[cam]\n",
    "        try:\n",
    "            fq.get_nowait()\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        try:\n",
    "            fq.put_nowait((img.copy(), cam_ts))\n",
    "        except queue.Full:\n",
    "            pass\n",
    "\n",
    "        # build tiled view if both cams available\n",
    "        if VISUALIZE and all(k in frames for k in [t.decode() for t in SUB_TOPICS]):\n",
    "            cams = [t.decode() for t in SUB_TOPICS]\n",
    "            left = frames[cams[0]]; right = frames[cams[1]]\n",
    "            drift_ms = abs(left[\"cam_ts\"] - right[\"cam_ts\"]) * 1000.0\n",
    "\n",
    "            def overlay(frame_info, cam_name):\n",
    "                im = frame_info[\"img\"].copy()\n",
    "                y = 20\n",
    "                cv2.putText(im, f\"{cam_name}\", (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,32,20), 2)\n",
    "                cv2.putText(im, f\"FPS: {frame_info['fps']:.1f}\", (10, y+26), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (14,117,5), 2)\n",
    "                cv2.putText(im, f\"cam_ts: {fmt_ts(frame_info['cam_ts'])}\", (10, y+52), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (5,12,117), 1)\n",
    "\n",
    "                # draw ALL cached detections for this camera\n",
    "                with detect_lock:\n",
    "                    dets = detect_cache.get(cam_name, [])\n",
    "                    for i, d in enumerate(dets):\n",
    "                        x,y,w,h = d[\"bbox\"]\n",
    "                        cx,cy = d[\"centroid\"]\n",
    "                        color = d.get(\"color\", \"unknown\")\n",
    "                        box_color = (0,200,200)  # default\n",
    "                        if color == \"orange\":\n",
    "                            box_color = (0,200,255)  # orange-ish\n",
    "                        elif color == \"purple\":\n",
    "                            box_color = (200,0,200)  # purple-ish\n",
    "                        # draw bounding box and centroid\n",
    "                        cv2.rectangle(im, (x,y), (x+w, y+h), box_color, 2)\n",
    "                        cv2.circle(im, (cx,cy), 4, (0,0,255), -1)\n",
    "                        cv2.putText(im, f\"{color}:{i}\", (x, y-6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 2)\n",
    "                return im\n",
    "\n",
    "            left_im = overlay(left, cams[0])\n",
    "            right_im = overlay(right, cams[1])\n",
    "\n",
    "            # tile horizontally\n",
    "            h = max(left_im.shape[0], right_im.shape[0])\n",
    "            right_resized = cv2.resize(right_im, (left_im.shape[1], h))\n",
    "            tile = np.hstack([left_im, right_resized])\n",
    "\n",
    "            # overlays\n",
    "            cv2.putText(tile, f\"Drift: {drift_ms:.1f} ms\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
    "            cv2.putText(tile, f\"Host now: {fmt_ts(time.time())}\", (10, 44), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "            # display throttled\n",
    "            if VISUALIZE and (time.time() - last_show) > (1.0/DISPLAY_FPS):\n",
    "                last_show = time.time()\n",
    "                cv2.imshow(\"Both Cameras (tiled)\", tile)\n",
    "        elif not VISUALIZE:\n",
    "            with detect_lock:\n",
    "                parts_status = []\n",
    "                for c in [t.decode() for t in SUB_TOPICS]:\n",
    "                    dets = detect_cache.get(c, [])\n",
    "                    if dets:\n",
    "                        counts = { \"orange\":0, \"purple\":0, \"unknown\":0 }\n",
    "                        for d in dets:\n",
    "                            counts[d.get(\"color\",\"unknown\")] = counts.get(d.get(\"color\",\"unknown\"),0) + 1\n",
    "                        parts_status.append(f\"{c}: Orange: {counts['orange']} Purple: {counts['purple']}\")\n",
    "                    else:\n",
    "                        parts_status.append(f\"{c}:NoBall\")\n",
    "                sys.stdout.write(\"\\r\" + \" | \".join(parts_status) + \" \" * 20)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    # stop threads\n",
    "    for d in det_threads.values():\n",
    "        d.stop()\n",
    "    # allow threads to exit\n",
    "    time.sleep(0.1)\n",
    "    cv2.destroyAllWindows()\n",
    "    sub.close()\n",
    "    ctx.term()\n",
    "    print(\"Exit clean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34210889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kreo1] Configured with HSV: {'hmin': 0, 'smin': 120, 'vmin': 175, 'hmax': 12, 'smax': 255, 'vmax': 255}\n",
      "[kreo1] Detector thread started. Scale: 0.5\n",
      "[kreo2] Configured with HSV: {'hmin': 0, 'smin': 150, 'vmin': 150, 'hmax': 12, 'smax': 255, 'vmax': 255}\n",
      "[kreo2] Detector thread started. Scale: 0.5\n",
      "[Subscriber] Connected. Logging to: ../../data/ball_detection_logs/data_log_1763878277.csv\n",
      "[Subscriber] Press ESC to exit.\n",
      "FPS: 40.0 | 40.0\n",
      "Log saved to: ../../data/ball_detection_logs/data_log_1763878277.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kreo1] BallDetectorThread stopped\n",
      "[kreo2] BallDetectorThread stopped\n"
     ]
    }
   ],
   "source": [
    "import cv2, zmq, numpy as np, time, threading, queue, traceback, sys, os, csv\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ---------- Config ----------\n",
    "ZMQ_ADDR = \"tcp://localhost:5555\"\n",
    "SUB_TOPICS = [b\"kreo1\", b\"kreo2\"]\n",
    "FPS_WINDOW = 1.0        # seconds for fps moving window\n",
    "DISPLAY_FPS = 60        # Limit display refresh to save CPU for detection\n",
    "VISUALIZE = False        # Set to False on headless systems to save even more FPS\n",
    "\n",
    "# OPTIMIZATION: Downscale frame for detection (0.5 = 360p, 4x faster than 720p)\n",
    "DETECTION_SCALE = 0.5 \n",
    "\n",
    "# LOGGING PATH (Updated as per request)\n",
    "LOG_DIR = \"../../data/ball_detection_logs\"\n",
    "LOG_FILENAME = f\"{LOG_DIR}/data_log_{int(time.time())}.csv\"\n",
    "\n",
    "# PER-CAMERA HSV CONFIG\n",
    "# Using specific values for kreo1 and kreo2 as requested.\n",
    "HSV_CONFIG = {\n",
    "    \"kreo1\": {\n",
    "        \"orange\": {'hmin': 0, 'smin': 120, 'vmin': 175, 'hmax': 12, 'smax': 255, 'vmax': 255},\n",
    "    },\n",
    "    \"kreo2\": {\n",
    "        \"orange\": {'hmin': 0, 'smin': 150, 'vmin': 150, 'hmax': 12, 'smax': 255, 'vmax': 255}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Fallback for unknown cameras\n",
    "DEFAULT_HSV = {'hmin': 0, 'smin': 100, 'vmin': 100, 'hmax': 25, 'smax': 255, 'vmax': 255}\n",
    "\n",
    "# Detector parameters (Adjusted for Scale in main logic)\n",
    "BASE_MIN_AREA = 100    \n",
    "BASE_MAX_AREA = 20000  \n",
    "CIRCULARITY_MIN = 0.5\n",
    "ASPECT_RATIO_MIN = 0.6 \n",
    "ASPECT_RATIO_MAX = 1.6   \n",
    "MAX_DETECTIONS_PER_CAM = 5 \n",
    "\n",
    "# ---------- Logging Setup ----------\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "\n",
    "# We use a thread-safe queue for logging to avoid blocking detection threads with file I/O\n",
    "log_queue = queue.Queue()\n",
    "\n",
    "def logger_worker():\n",
    "    \"\"\"Writes logs to CSV from a queue.\"\"\"\n",
    "    try:\n",
    "        with open(LOG_FILENAME, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            # Header\n",
    "            writer.writerow([\"timestamp\", \"camera\", \"status\", \"color\", \"x\", \"y\", \"w\", \"h\", \"area\"])\n",
    "            \n",
    "            while True:\n",
    "                entry = log_queue.get()\n",
    "                if entry is None: # Poison pill\n",
    "                    break\n",
    "                writer.writerow(entry)\n",
    "                log_queue.task_done()\n",
    "    except Exception as e:\n",
    "        print(f\"[LOGGER ERROR] {e}\")\n",
    "\n",
    "# Start logger thread\n",
    "log_thread = threading.Thread(target=logger_worker, daemon=True)\n",
    "log_thread.start()\n",
    "\n",
    "def log_frame_result(ts, cam, status, det_data=None):\n",
    "    \"\"\"\n",
    "    Helper to push data to log queue.\n",
    "    status: DETECTED, NOT_DETECTED, SKIPPED_TIMEOUT\n",
    "    \"\"\"\n",
    "    if det_data:\n",
    "        x, y, w, h = det_data['bbox']\n",
    "        color = det_data.get('color', 'unknown')\n",
    "        area = det_data.get('area', 0)\n",
    "        log_queue.put([f\"{ts:.3f}\", cam, status, color, x, y, w, h, int(area)])\n",
    "    else:\n",
    "        # No detection data (NOT_DETECTED or SKIPPED)\n",
    "        log_queue.put([f\"{ts:.3f}\", cam, status, \"N/A\", \"\", \"\", \"\", \"\", \"\"])\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def fmt_ts(ts):\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(ts)) + f\".{int((ts%1)*1000):03d}\"\n",
    "\n",
    "def recv_latest(sub):\n",
    "    msg = None\n",
    "    while True:\n",
    "        try:\n",
    "            msg = sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        except zmq.Again:\n",
    "            break\n",
    "    return msg\n",
    "\n",
    "def update_fps(camera, cam_ts):\n",
    "    dq = fps_windows[camera]\n",
    "    dq.append(cam_ts)\n",
    "    # pop older than window\n",
    "    while dq and (cam_ts - dq[0]) > FPS_WINDOW:\n",
    "        dq.popleft()\n",
    "    fps = len(dq) / FPS_WINDOW\n",
    "    return fps\n",
    "\n",
    "# ---------- Color masking helpers ----------\n",
    "def get_orange_mask(bgr_img, hsv_dict):\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "    lower_o = np.array([hsv_dict['hmin'], hsv_dict['smin'], hsv_dict['vmin']], dtype=np.uint8)\n",
    "    upper_o = np.array([hsv_dict['hmax'], hsv_dict['smax'], hsv_dict['vmax']], dtype=np.uint8)\n",
    "    mask_o = cv2.inRange(hsv, lower_o, upper_o)\n",
    "    \n",
    "    mask_o = cv2.GaussianBlur(mask_o, (5, 5), 0)\n",
    "    return mask_o\n",
    "\n",
    "def find_candidate_contours(mask, min_area, max_area):\n",
    "    if mask is None:\n",
    "        return []\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < min_area or area > max_area:\n",
    "            continue\n",
    "            \n",
    "        # Bounding rect\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect = float(w)/float(h) if h > 0 else 0\n",
    "        if ASPECT_RATIO_MIN>aspect or aspect > ASPECT_RATIO_MAX:\n",
    "            continue\n",
    "            \n",
    "        perim = cv2.arcLength(c, True)\n",
    "        if perim == 0: continue\n",
    "        \n",
    "        circularity = 4 * np.pi * area / (perim * perim)\n",
    "        \n",
    "        # Accept logic\n",
    "        if circularity >= CIRCULARITY_MIN:\n",
    "            candidates.append({\n",
    "                \"contour\": c,\n",
    "                \"area\": area,\n",
    "                \"circularity\": circularity,\n",
    "                \"bbox\": (x,y,w,h)\n",
    "            })\n",
    "            \n",
    "    # sort by area desc\n",
    "    candidates.sort(key=lambda d: d[\"area\"], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# ---------- Detector thread (per-camera) ----------\n",
    "class BallDetectorThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue, detect_cache, lock):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.detect_cache = detect_cache\n",
    "        self.lock = lock\n",
    "        self.stop_flag = False\n",
    "        \n",
    "        # Pre-calculate scaled area thresholds\n",
    "        self.min_area_scaled = BASE_MIN_AREA * (DETECTION_SCALE * DETECTION_SCALE)\n",
    "        self.max_area_scaled = BASE_MAX_AREA * (DETECTION_SCALE * DETECTION_SCALE)\n",
    "\n",
    "        # Get camera specific HSV\n",
    "        cam_config = HSV_CONFIG.get(cam_name, {})\n",
    "        self.hsv_vals = cam_config.get(\"orange\", DEFAULT_HSV)\n",
    "        print(f\"[{self.cam_name}] Configured with HSV: {self.hsv_vals}\")\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] Detector thread started. Scale: {DETECTION_SCALE}\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                # Wait for frame\n",
    "                frame_orig, cam_ts = self.frame_queue.get(timeout=0.1)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            \n",
    "            detection_found = False\n",
    "            \n",
    "            try:\n",
    "                # 1. Downscale for speed\n",
    "                if DETECTION_SCALE != 1.0:\n",
    "                    frame_proc = cv2.resize(frame_orig, None, fx=DETECTION_SCALE, fy=DETECTION_SCALE, interpolation=cv2.INTER_NEAREST)\n",
    "                else:\n",
    "                    frame_proc = frame_orig\n",
    "\n",
    "                # 2. Get Mask (Only Orange as requested)\n",
    "                mask_o = get_orange_mask(frame_proc, self.hsv_vals)\n",
    "\n",
    "                # 3. Find Contours\n",
    "                candidates = find_candidate_contours(mask_o, self.min_area_scaled, self.max_area_scaled)\n",
    "\n",
    "                detections = []\n",
    "                \n",
    "                # 4. Process Top Candidates\n",
    "                for cand in candidates[:MAX_DETECTIONS_PER_CAM]:\n",
    "                    x_s, y_s, w_s, h_s = cand[\"bbox\"] # scaled coords\n",
    "                    \n",
    "                    # Scale coords back to original resolution\n",
    "                    scale_inv = 1.0 / DETECTION_SCALE\n",
    "                    x = int(x_s * scale_inv)\n",
    "                    y = int(y_s * scale_inv)\n",
    "                    w = int(w_s * scale_inv)\n",
    "                    h = int(h_s * scale_inv)\n",
    "                    area_orig = cand[\"area\"] * (scale_inv * scale_inv)\n",
    "\n",
    "                    cx = x + w//2\n",
    "                    cy = y + h//2\n",
    "\n",
    "                    det = {\n",
    "                        \"bbox\": (x,y,w,h),\n",
    "                        \"centroid\": (cx,cy),\n",
    "                        \"area\": area_orig,\n",
    "                        \"color\": \"orange\", # We are only checking orange\n",
    "                        \"ts\": cam_ts\n",
    "                    }\n",
    "                    detections.append(det)\n",
    "                    \n",
    "                    # Log POSITIVE detection\n",
    "                    log_frame_result(cam_ts, self.cam_name, \"DETECTED\", det)\n",
    "                    detection_found = True\n",
    "                \n",
    "                # Update shared cache for visualization\n",
    "                with self.lock:\n",
    "                    self.detect_cache[self.cam_name] = detections\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR-{self.cam_name}] detection exception:\", e)\n",
    "                traceback.print_exc()\n",
    "            \n",
    "            # Log NEGATIVE detection (if nothing found in this frame)\n",
    "            if not detection_found:\n",
    "                log_frame_result(cam_ts, self.cam_name, \"NOT_DETECTED\")\n",
    "\n",
    "        print(f\"[{self.cam_name}] BallDetectorThread stopped\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "# ---------- ZMQ subscriber ----------\n",
    "ctx = zmq.Context()\n",
    "sub = ctx.socket(zmq.SUB)\n",
    "sub.connect(ZMQ_ADDR)\n",
    "sub.setsockopt(zmq.RCVHWM, 10)\n",
    "# sub.setsockopt(zmq.CONFLATE, 1) \n",
    "sub.setsockopt(zmq.LINGER, 0)\n",
    "for t in SUB_TOPICS:\n",
    "    sub.setsockopt(zmq.SUBSCRIBE, t)\n",
    "\n",
    "# ---- ACTIVE FLUSH ----\n",
    "flushed = 0\n",
    "while True:\n",
    "    try:\n",
    "        sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        flushed += 1\n",
    "    except zmq.Again:\n",
    "        break\n",
    "if flushed > 0:\n",
    "    print(f\"[Subscriber] Flushed {flushed} stale messages.\")\n",
    "\n",
    "\n",
    "# per-camera structures\n",
    "frames = {}\n",
    "fps_windows = defaultdict(lambda: deque())\n",
    "frame_queues = {t.decode(): queue.Queue(maxsize=1) for t in SUB_TOPICS}\n",
    "detect_cache = {}        \n",
    "detect_lock = threading.Lock()\n",
    "det_threads = {}\n",
    "\n",
    "# Start threads\n",
    "for t in SUB_TOPICS:\n",
    "    cam_name = t.decode()\n",
    "    # Verify we have config for this camera\n",
    "    if cam_name not in HSV_CONFIG:\n",
    "        print(f\"[WARNING] No specific HSV config found for {cam_name}, using defaults.\")\n",
    "    \n",
    "    dt = BallDetectorThread(cam_name, frame_queues[cam_name], detect_cache, detect_lock)\n",
    "    dt.start()\n",
    "    det_threads[cam_name] = dt\n",
    "\n",
    "\n",
    "print(f\"[Subscriber] Connected. Logging to: {LOG_FILENAME}\")\n",
    "print(f\"[Subscriber] Press ESC to exit.\")\n",
    "\n",
    "last_show = time.time()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        latest_msgs = {}\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                parts = sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "                topic = parts[0]\n",
    "                latest_msgs[topic] = parts # Overwrite with newer if multiple exist\n",
    "            except zmq.Again:\n",
    "                break\n",
    "        \n",
    "        # Process the unique latest frame for each camera found\n",
    "        if not latest_msgs:\n",
    "            # No data, brief sleep to yield CPU\n",
    "            time.sleep(0.001)\n",
    "        else:\n",
    "            for topic, parts in latest_msgs.items():\n",
    "                cam = topic.decode()\n",
    "                ts_part = parts[1] if len(parts) >= 3 else None\n",
    "                jpg_part = parts[2] if len(parts) >= 3 else parts[1]\n",
    "                \n",
    "                recv_time = time.time()\n",
    "                try:\n",
    "                    cam_ts = float(ts_part.decode()) if ts_part else recv_time\n",
    "                except:\n",
    "                    cam_ts = recv_time\n",
    "\n",
    "                # Decode\n",
    "                img = cv2.imdecode(np.frombuffer(jpg_part, np.uint8), cv2.IMREAD_COLOR)\n",
    "                if img is None: continue\n",
    "\n",
    "                fps = update_fps(cam, cam_ts)\n",
    "                frames[cam] = {\"img\": img, \"cam_ts\": cam_ts, \"fps\": fps}\n",
    "\n",
    "                # Push to detector\n",
    "                fq = frame_queues[cam]\n",
    "                try:\n",
    "                    fq.put_nowait((img, cam_ts))\n",
    "                except queue.Full:\n",
    "                    # Drop old, put new (LIFO)\n",
    "                    try:\n",
    "                        _dropped_frame, _dropped_ts = fq.get_nowait()\n",
    "                        log_frame_result(_dropped_ts, cam, \"SKIPPED_TIMEOUT\")\n",
    "                        fq.put_nowait((img, cam_ts))\n",
    "                    except queue.Empty:\n",
    "                        pass\n",
    "\n",
    "        # Visualization (Throttled)\n",
    "        if VISUALIZE and (time.time() - last_show) > (1.0/DISPLAY_FPS):\n",
    "            if all(k in frames for k in [t.decode() for t in SUB_TOPICS]):\n",
    "                cams = [t.decode() for t in SUB_TOPICS]\n",
    "                left, right = frames[cams[0]], frames[cams[1]]\n",
    "                \n",
    "                def overlay(frame_info, cam_name):\n",
    "                    im = frame_info[\"img\"].copy()\n",
    "                    cv2.putText(im, f\"{cam_name} FPS: {frame_info['fps']:.1f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                    with detect_lock:\n",
    "                        for d in detect_cache.get(cam_name, []):\n",
    "                            x,y,w,h = d[\"bbox\"]\n",
    "                            cv2.rectangle(im, (x,y), (x+w, y+h), (0,165,255), 2)\n",
    "                            cv2.circle(im, d[\"centroid\"], 5, (0,0,255), -1)\n",
    "                    return im\n",
    "\n",
    "                l_im = overlay(left, cams[0])\n",
    "                r_im = overlay(right, cams[1])\n",
    "                \n",
    "                h = min(l_im.shape[0], r_im.shape[0])\n",
    "                if l_im.shape[0] != h: l_im = cv2.resize(l_im, (int(l_im.shape[1]*h/l_im.shape[0]), h))\n",
    "                if r_im.shape[0] != h: r_im = cv2.resize(r_im, (int(r_im.shape[1]*h/r_im.shape[0]), h))\n",
    "                \n",
    "                cv2.imshow(\"Stereo View\", np.hstack([l_im, r_im]))\n",
    "                last_show = time.time()\n",
    "        \n",
    "        elif not VISUALIZE:\n",
    "            sys.stdout.write(f\"\\rFPS: {frames.get('kreo1',{}).get('fps',0):.1f} | {frames.get('kreo2',{}).get('fps',0):.1f}\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    for d in det_threads.values(): d.stop()\n",
    "    log_queue.put(None)\n",
    "    log_thread.join()\n",
    "    cv2.destroyAllWindows()\n",
    "    sub.close()\n",
    "    ctx.term()\n",
    "    print(\"\\nLog saved to:\", LOG_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
