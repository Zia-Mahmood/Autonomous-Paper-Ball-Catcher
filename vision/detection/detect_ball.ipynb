{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f748ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m ret, img = cap.read()\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# img = cv2.imread('ball.png')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m imgColor, mask = \u001b[43mmyColorFinder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhsvVals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m imgContours, contours = cvzone.findContours(img,mask,minArea=\u001b[32m50\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m contours:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Autonomous-Paper-Ball-Catcher/.venv/lib/python3.11/site-packages/cvzone/ColorModule.py:75\u001b[39m, in \u001b[36mColorFinder.update\u001b[39m\u001b[34m(self, img, myColor)\u001b[39m\n\u001b[32m     72\u001b[39m     myColor = \u001b[38;5;28mself\u001b[39m.getColorHSV(myColor)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m myColor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     imgHSV = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOLOR_BGR2HSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     lower = np.array([myColor[\u001b[33m'\u001b[39m\u001b[33mhmin\u001b[39m\u001b[33m'\u001b[39m], myColor[\u001b[33m'\u001b[39m\u001b[33msmin\u001b[39m\u001b[33m'\u001b[39m], myColor[\u001b[33m'\u001b[39m\u001b[33mvmin\u001b[39m\u001b[33m'\u001b[39m]])\n\u001b[32m     77\u001b[39m     upper = np.array([myColor[\u001b[33m'\u001b[39m\u001b[33mhmax\u001b[39m\u001b[33m'\u001b[39m], myColor[\u001b[33m'\u001b[39m\u001b[33msmax\u001b[39m\u001b[33m'\u001b[39m], myColor[\u001b[33m'\u001b[39m\u001b[33mvmax\u001b[39m\u001b[33m'\u001b[39m]])\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2,cvzone\n",
    "from cvzone.ColorModule import ColorFinder\n",
    "\n",
    "cap = cv2.VideoCapture('./test.webm')\n",
    "myColorFinder = ColorFinder(trackBar=False)\n",
    "hsvVals = {'hmin': 0, 'smin': 140, 'vmin': 148, 'hmax': 7, 'smax': 255, 'vmax': 255}\n",
    "\n",
    "posList = []\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    # img = cv2.imread('ball.png')\n",
    "\n",
    "    imgColor, mask = myColorFinder.update(img, hsvVals)\n",
    "    imgContours, contours = cvzone.findContours(img,mask,minArea=50)\n",
    "\n",
    "    if contours:\n",
    "        posList.append(contours[0]['center'])\n",
    "    \n",
    "    for i,pos in enumerate(posList):\n",
    "        cv2.circle(imgContours,pos,5,(0,255,0),cv2.FILLED)\n",
    "        if i==0:\n",
    "            continue\n",
    "        cv2.line(imgContours,pos,posList[i-1],(255,0,0),2)\n",
    "\n",
    "    cv2.imshow(\"Color Filtered Image\", imgContours)\n",
    "\n",
    "    # CRITICAL: Use waitKey(1) to allow the GUI to update\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f87664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kreo1] Detector thread started.\n",
      "[kreo2] Detector thread started.\n",
      "[Subscriber] connected, waiting for frames... (Press ESC to exit)\n",
      "[kreo2] BallDetectorThread stopped\n",
      "[kreo1] BallDetectorThread stopped\n",
      "Exit clean.\n"
     ]
    }
   ],
   "source": [
    "import cv2, zmq, numpy as np, time, threading, queue, traceback, sys\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# ---------- Config ----------\n",
    "ZMQ_ADDR = \"tcp://localhost:5555\"\n",
    "SUB_TOPICS = [b\"kreo1\", b\"kreo2\"]\n",
    "FPS_WINDOW = 1.0        # seconds for fps moving window\n",
    "DISPLAY_FPS = 20\n",
    "VISUALIZE = True     # show tiled view window\n",
    "\n",
    "# color thresholds (you gave these)\n",
    "orange_hsvVals = {'hmin': 0, 'smin': 100, 'vmin': 100, 'hmax': 25, 'smax': 255, 'vmax': 255}\n",
    "purple_hsvVals = {'hmin': 149, 'smin': 69, 'vmin': 82, 'hmax': 177, 'smax': 229, 'vmax': 252}\n",
    "\n",
    "# detector parameters\n",
    "MIN_AREA = 100    # min contour area to accept (tune if needed)\n",
    "MAX_AREA = 20000  # max area (avoid very large blobs)\n",
    "CIRCULARITY_MIN = 0.25  # min circularity to accept (lower because paper balls can deform)\n",
    "ASPECT_RATIO_MAX = 2.0   # reject extremely elongated blobs\n",
    "MAX_DETECTIONS_PER_CAM = 12  # safety limi\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def fmt_ts(ts):\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(ts)) + f\".{int((ts%1)*1000):03d}\"\n",
    "\n",
    "def recv_latest(sub):\n",
    "    msg = None\n",
    "    while True:\n",
    "        try:\n",
    "            msg = sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        except zmq.Again:\n",
    "            break\n",
    "    return msg\n",
    "\n",
    "def update_fps(camera, cam_ts):\n",
    "    dq = fps_windows[camera]\n",
    "    dq.append(cam_ts)\n",
    "    # pop older than window\n",
    "    while dq and (cam_ts - dq[0]) > FPS_WINDOW:\n",
    "        dq.popleft()\n",
    "    fps = len(dq) / FPS_WINDOW\n",
    "    return fps\n",
    "\n",
    "# ---------- Color masking helpers ----------\n",
    "def hsv_mask_from_vals(bgr_img, hsvVals):\n",
    "    \"\"\"Return binary mask from HSV thresholds dict.\"\"\"\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([hsvVals['hmin'], hsvVals['smin'], hsvVals['vmin']], dtype=np.uint8)\n",
    "    upper = np.array([hsvVals['hmax'], hsvVals['smax'], hsvVals['vmax']], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    # small blur to reduce speckle\n",
    "    mask = cv2.medianBlur(mask, 5)\n",
    "    return mask\n",
    "\n",
    "def postprocess_mask(mask):\n",
    "    \"\"\"Morphological clean-up.\"\"\"\n",
    "    # open then close\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    m = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    return m\n",
    "\n",
    "def find_candidate_contours(mask, min_area=MIN_AREA, max_area=MAX_AREA):\n",
    "    \"\"\"Return list of contours filtered by area and shape heuristics.\"\"\"\n",
    "    if mask is None:\n",
    "        return []\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < min_area or area > max_area:\n",
    "            continue\n",
    "        perim = cv2.arcLength(c, True)\n",
    "        if perim <= 0:\n",
    "            continue\n",
    "        circularity = 4 * np.pi * area / (perim * perim)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect = float(w)/float(h) if h>0 else 0.0\n",
    "        # accept if roughly circular-ish or moderate area even if circularity low\n",
    "        if circularity >= CIRCULARITY_MIN or (0.5*min(w,h) > 5 and area > (min_area*2)):\n",
    "            if aspect <= ASPECT_RATIO_MAX:\n",
    "                candidates.append({\n",
    "                    \"contour\": c,\n",
    "                    \"area\": area,\n",
    "                    \"perimeter\": perim,\n",
    "                    \"circularity\": circularity,\n",
    "                    \"bbox\": (int(x),int(y),int(w),int(h))\n",
    "                })\n",
    "    # sort by area desc\n",
    "    candidates.sort(key=lambda d: d[\"area\"], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# ---------- Detector thread (per-camera) ----------\n",
    "class BallDetectorThread(threading.Thread):\n",
    "    def __init__(self, cam_name, frame_queue, detect_cache, lock):\n",
    "        super().__init__(daemon=True)\n",
    "        self.cam_name = cam_name\n",
    "        self.frame_queue = frame_queue\n",
    "        self.detect_cache = detect_cache\n",
    "        self.lock = lock\n",
    "        self.stop_flag = False\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"[{self.cam_name}] Detector thread started.\")\n",
    "        while not self.stop_flag:\n",
    "            try:\n",
    "                frame,cam_ts = self.frame_queue.get(timeout=0.1)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                # build masks for both colors\n",
    "                mask_orange = hsv_mask_from_vals(frame, orange_hsvVals)\n",
    "                mask_purple = hsv_mask_from_vals(frame, purple_hsvVals)\n",
    "\n",
    "                # combine & clean\n",
    "                combined_mask = cv2.bitwise_or(mask_orange, mask_purple)\n",
    "                combined_mask = postprocess_mask(combined_mask)\n",
    "\n",
    "                # find contours\n",
    "                candidates = find_candidate_contours(combined_mask)\n",
    "\n",
    "                detections = []\n",
    "                for cand in candidates[:MAX_DETECTIONS_PER_CAM]:\n",
    "                    c = cand[\"contour\"]\n",
    "                    x,y,w,h = cand[\"bbox\"]\n",
    "                    area = cand[\"area\"]\n",
    "                    circ = cand[\"circularity\"]\n",
    "\n",
    "                    # centroid\n",
    "                    M = cv2.moments(c)\n",
    "                    if M[\"m00\"] != 0:\n",
    "                        cx = int(M[\"m10\"]/M[\"m00\"]); cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "                    else:\n",
    "                        cx = x + w//2; cy = y + h//2\n",
    "\n",
    "                    # classify color by sampling the masks inside bbox\n",
    "                    s_orange = int(np.count_nonzero(mask_orange[y:y+h, x:x+w])) if mask_orange is not None else 0\n",
    "                    s_purple = int(np.count_nonzero(mask_purple[y:y+h, x:x+w])) if mask_purple is not None else 0\n",
    "\n",
    "                    # small area leads to ambiguity; prefer stronger mask\n",
    "                    color = \"unknown\"\n",
    "                    if s_orange > s_purple and s_orange > 0:\n",
    "                        color = \"orange\"\n",
    "                    elif s_purple > s_orange and s_purple > 0:\n",
    "                        color = \"purple\"\n",
    "                    else:\n",
    "                        # fallback: mean hue in bbox\n",
    "                        try:\n",
    "                            hsv_roi = cv2.cvtColor(frame[y:y+h, x:x+w], cv2.COLOR_BGR2HSV)\n",
    "                            mean_h = int(np.mean(hsv_roi[:,:,0]))\n",
    "                            if orange_hsvVals['hmin'] <= mean_h <= orange_hsvVals['hmax']:\n",
    "                                color = \"orange\"\n",
    "                            elif purple_hsvVals['hmin'] <= mean_h <= purple_hsvVals['hmax']:\n",
    "                                color = \"purple\"\n",
    "                        except Exception:\n",
    "                            color = \"unknown\"\n",
    "\n",
    "                    det = {\n",
    "                        \"bbox\": (int(x),int(y),int(w),int(h)),\n",
    "                        \"centroid\": (int(cx),int(cy)),\n",
    "                        \"area\": float(area),\n",
    "                        \"circularity\": float(circ),\n",
    "                        \"color\": color,\n",
    "                        \"ts\": float(cam_ts),\n",
    "                        \"det_time\": time.time()\n",
    "                    }\n",
    "                    detections.append(det)\n",
    "\n",
    "                with self.lock:\n",
    "                    self.detect_cache[self.cam_name] = detections\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR-{self.cam_name}] detection exception:\", e)\n",
    "                traceback.print_exc()\n",
    "\n",
    "        print(f\"[{self.cam_name}] BallDetectorThread stopped\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "\n",
    "# ---------- ZMQ subscriber ----------\n",
    "ctx = zmq.Context()\n",
    "sub = ctx.socket(zmq.SUB)\n",
    "sub.connect(ZMQ_ADDR)\n",
    "sub.setsockopt(zmq.RCVHWM, 1)\n",
    "sub.setsockopt(zmq.CONFLATE, 1)  # keep only last message\n",
    "sub.setsockopt(zmq.LINGER, 0)\n",
    "\n",
    "# ---- ACTIVE FLUSH ----\n",
    "flushed = 0\n",
    "while True:\n",
    "    try:\n",
    "        sub.recv_multipart(flags=zmq.NOBLOCK)\n",
    "        flushed += 1\n",
    "    except zmq.Again:\n",
    "        break\n",
    "if flushed > 0:\n",
    "    print(f\"[Subscriber] Flushed {flushed} stale messages.\")\n",
    "for t in SUB_TOPICS:\n",
    "    sub.setsockopt(zmq.SUBSCRIBE, t)\n",
    "\n",
    "\n",
    "# per-camera structures\n",
    "frames = {}\n",
    "fps_windows = defaultdict(lambda: deque())\n",
    "frame_queues = {t.decode(): queue.Queue(maxsize=1) for t in SUB_TOPICS}\n",
    "detect_cache = {}        # cam -> detection dict\n",
    "detect_lock = threading.Lock()\n",
    "det_threads = {}\n",
    "\n",
    "for t in SUB_TOPICS:\n",
    "    cam_name = t.decode()\n",
    "    dt = BallDetectorThread(cam_name, frame_queues[cam_name], detect_cache, detect_lock)\n",
    "    dt.start()\n",
    "    det_threads[cam_name] = dt\n",
    "\n",
    "\n",
    "print(\"[Subscriber] connected, waiting for frames... (Press ESC to exit)\")\n",
    "\n",
    "last_show = time.time()\n",
    "try:\n",
    "    while True:\n",
    "        parts = recv_latest(sub)\n",
    "        if parts is None:\n",
    "            continue\n",
    "\n",
    "        # unpack message\n",
    "        topic = parts[0]; cam = topic.decode()\n",
    "        if len(parts) >= 3:\n",
    "            ts_part = parts[1]; jpg_part = parts[2]\n",
    "        else:\n",
    "            ts_part = None; jpg_part = parts[1]\n",
    "\n",
    "        recv_time = time.time()\n",
    "        try:\n",
    "            cam_ts = float(ts_part.decode()) if ts_part else recv_time\n",
    "        except:\n",
    "            cam_ts = recv_time\n",
    "\n",
    "        img = cv2.imdecode(np.frombuffer(jpg_part, np.uint8), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        fps = update_fps(cam, cam_ts)\n",
    "        frames[cam] = {\"img\": img, \"cam_ts\": cam_ts, \"fps\": fps}\n",
    "\n",
    "        # push latest frame to detector queue (maxsize=1)\n",
    "        fq = frame_queues[cam]\n",
    "        try:\n",
    "            fq.get_nowait()\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        try:\n",
    "            fq.put_nowait((img.copy(), cam_ts))\n",
    "        except queue.Full:\n",
    "            pass\n",
    "\n",
    "        # build tiled view if both cams available\n",
    "        if VISUALIZE and all(k in frames for k in [t.decode() for t in SUB_TOPICS]):\n",
    "            cams = [t.decode() for t in SUB_TOPICS]\n",
    "            left = frames[cams[0]]; right = frames[cams[1]]\n",
    "            drift_ms = abs(left[\"cam_ts\"] - right[\"cam_ts\"]) * 1000.0\n",
    "\n",
    "            def overlay(frame_info, cam_name):\n",
    "                im = frame_info[\"img\"].copy()\n",
    "                y = 20\n",
    "                cv2.putText(im, f\"{cam_name}\", (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,32,20), 2)\n",
    "                cv2.putText(im, f\"FPS: {frame_info['fps']:.1f}\", (10, y+26), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (14,117,5), 2)\n",
    "                cv2.putText(im, f\"cam_ts: {fmt_ts(frame_info['cam_ts'])}\", (10, y+52), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (5,12,117), 1)\n",
    "\n",
    "                # draw ALL cached detections for this camera\n",
    "                with detect_lock:\n",
    "                    dets = detect_cache.get(cam_name, [])\n",
    "                    for i, d in enumerate(dets):\n",
    "                        x,y,w,h = d[\"bbox\"]\n",
    "                        cx,cy = d[\"centroid\"]\n",
    "                        color = d.get(\"color\", \"unknown\")\n",
    "                        box_color = (0,200,200)  # default\n",
    "                        if color == \"orange\":\n",
    "                            box_color = (0,200,255)  # orange-ish\n",
    "                        elif color == \"purple\":\n",
    "                            box_color = (200,0,200)  # purple-ish\n",
    "                        # draw bounding box and centroid\n",
    "                        cv2.rectangle(im, (x,y), (x+w, y+h), box_color, 2)\n",
    "                        cv2.circle(im, (cx,cy), 4, (0,0,255), -1)\n",
    "                        cv2.putText(im, f\"{color}:{i}\", (x, y-6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 2)\n",
    "                return im\n",
    "\n",
    "            left_im = overlay(left, cams[0])\n",
    "            right_im = overlay(right, cams[1])\n",
    "\n",
    "            # tile horizontally\n",
    "            h = max(left_im.shape[0], right_im.shape[0])\n",
    "            right_resized = cv2.resize(right_im, (left_im.shape[1], h))\n",
    "            tile = np.hstack([left_im, right_resized])\n",
    "\n",
    "            # overlays\n",
    "            cv2.putText(tile, f\"Drift: {drift_ms:.1f} ms\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
    "            cv2.putText(tile, f\"Host now: {fmt_ts(time.time())}\", (10, 44), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "            # display throttled\n",
    "            if VISUALIZE and (time.time() - last_show) > (1.0/DISPLAY_FPS):\n",
    "                last_show = time.time()\n",
    "                cv2.imshow(\"Both Cameras (tiled)\", tile)\n",
    "        elif not VISUALIZE:\n",
    "            with detect_lock:\n",
    "                parts_status = []\n",
    "                for c in [t.decode() for t in SUB_TOPICS]:\n",
    "                    dets = detect_cache.get(c, [])\n",
    "                    if dets:\n",
    "                        counts = { \"orange\":0, \"purple\":0, \"unknown\":0 }\n",
    "                        for d in dets:\n",
    "                            counts[d.get(\"color\",\"unknown\")] = counts.get(d.get(\"color\",\"unknown\"),0) + 1\n",
    "                        parts_status.append(f\"{c}: Orange: {counts['orange']} Purple: {counts['purple']}\")\n",
    "                    else:\n",
    "                        parts_status.append(f\"{c}:NoBall\")\n",
    "                sys.stdout.write(\"\\r\" + \" | \".join(parts_status) + \" \" * 20)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    # stop threads\n",
    "    for d in det_threads.values():\n",
    "        d.stop()\n",
    "    # allow threads to exit\n",
    "    time.sleep(0.1)\n",
    "    cv2.destroyAllWindows()\n",
    "    sub.close()\n",
    "    ctx.term()\n",
    "    print(\"Exit clean.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
